{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 20240201"
      ],
      "metadata": {
        "id": "A2Ptqk6t7jvz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "딥러닝 프레임워크 주요 2가지\n",
        "- 텐서플로우의 케라스\n",
        "- pytorch\n",
        "\n",
        "요즘 점점 pytorch 를 많이 쓴다고 한다."
      ],
      "metadata": {
        "id": "z07yChMn8hT9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 텐서플로우(TensorFlow)의 케라스(Keras)\n",
        "- 머신러닝 모델을 쉽고 빠르게 개발할 수 있도록 도와주는 고수준의 신경망 API. 원래 케라스는 독립적인 딥러닝 라이브러리로 시작되었지만, 텐서플로우 1.0 버전부터는 텐서플로우의 공식 프론트엔드로 통합되었고, 텐서플로우 2.0 이후부터는 텐서플로우의 기본 API로 자리잡았다.\n",
        "- 케라스는 사용자 친화적이며 모듈식으로 구성되어 있어, 신경망의 레이어(layer), 활성화 함수(activation function), 손실 함수(loss function) 등을 마치 레고 블록을 조립하듯 쉽게 조합하여 모델을 구성할 수 있다. 이를 통해 컴퓨터 비전, 자연어 처리와 같은 다양한 머신러닝 애플리케이션을 신속하게 개발할 수 있다.\n",
        "\n",
        "주요 특징\n",
        "\n",
        "- 사용자 친화성: 케라스는 일관된 API를 제공하며, 일반적인 사용 사례에 대한 간결한 코드를 지향합니다. 이를 통해 사용자가 직관적으로 이해하고 사용할 수 있다.\n",
        "- 모듈성: 모델은 독립적인 모듈, 즉 레이어, 손실 함수, 활성화 함수, 최적화 알고리즘 등의 조합으로 구성됩니다. 이러한 모듈은 최소한의 제약으로 서로 연결될 수 있어, 매우 유연한 모델 설계가 가능.\n",
        "- 확장성: 케라스는 새로운 레이어나 기타 모듈을 만들어 추가하는 것이 상대적으로 쉽습니다. 따라서 연구 목적으로 새로운 아이디어를 실험하고자 할 때 매우 유용.\n",
        "- 파이썬 기반: 케라스는 순수 파이썬으로 작성되어 있으며, 딥러닝 모델을 파이썬 코드로 쉽게 작성할 수 있다.\n",
        "\n",
        "기본 구성 요소\n",
        "- 모델: Sequential 모델과 함수형 API를 통해 신경망을 구성할 수 있다. - Sequential 모델은 레이어를 순차적으로 쌓는 간단한 방식이며, 함수형 API는 더 복잡한 모델을 구성할 수 있는 유연성을 제공.\n",
        "- 레이어: 다양한 유형의 레이어(예: Dense(완전 연결 레이어), Conv2D(2D 컨볼루션 레이어), RNN(재귀 신경망 레이어))를 제공.\n",
        "- 손실 함수: 모델의 예측과 실제 값 사이의 차이를 측정하는 함수입니다. 예를 들어, 회귀 문제에는 mean_squared_error, 분류 문제에는 categorical_crossentropy가 자주 사용.\n",
        "- 옵티마이저: 경사하강법 알고리즘을 구현한 것으로, adam, sgd, rmsprop 등이 있다. 모델의 손실을 최소화하기 위해 모델 파라미터를 업데이트하는 방법을 정의.\n",
        "- 평가 지표: 학습과 테스트 단계에서 모델의 성능을 평가하기 위해 사용되는 지표들이다. 예를 들어, 정확도(accuracy), 정밀도(precision), 재현율(recall) 등이 있다.\n",
        "\n",
        "케라스는 이러한 구성 요소들을 사용하여 다양한 신경망 아키텍처를 구현하고, 이를 텐서플로우 백엔드를 통해 효율적으로 실행할 수 있게 해준다."
      ],
      "metadata": {
        "id": "U8N5ag9Y7iJV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 텐서플로우(TensorFlow) 모델 구축 방법\n",
        "Sequential API와 함수형(Functional) API. 이 두 방법은 신경망 모델을 정의, 구축 및 실험하는 데 사용되며, 사용자의 필요와 모델의 복잡성에 따라 적합한 방법을 선택할 수 있다.\n",
        "\n",
        "Sequential API\n",
        "- Sequential API는 가장 간단한 형태의 모델을 생성하는 방법 중 하나로, 레이어를 순차적으로 쌓아 올리는 방식으로 모델을 정의. 각 레이어는 바로 이전 레이어의 출력을 입력으로 받아 처리.\n",
        "- Sequential 모델은 단순한 순차적 구조를 가진 신경망에 적합하며, 복잡한 모델 구조(예: 다중 입력/출력, 모델 내 레이어 간 병렬 연결 등)를 표현하는 데는 한계가 있다.\n",
        "\n",
        "함수형(Functional) API\n",
        "- 함수형 API는 더 유연한 모델 설계를 가능하게 하는 API로, 복잡한 모델 아키텍처를 구성할 수 있다.\n",
        "- 함수형 API를 사용하면 다중 입력 및 출력, 공유 레이어(동일한 레이어를 여러 번 사용), 레이어 간 복잡한 연결 구조 등을 정의할 수 있다. 이는 각 레이어의 입출력을 명시적으로 정의함으로써 달성된다. 함수형 API는 고급 사용자에게 더 많은 유연성과 제어력을 제공한다."
      ],
      "metadata": {
        "id": "nhpNGRBf_Deq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### [ 활성화 함수 ]\n",
        "- ReLU(Rectified Linear Unit): 'f(x) = max(0, x)'로 정의되어 널리 사용되는 활성화 함수입니다. 계산 효율성이 높으면서도 비선형성이 도입되어 훈련 중에 모델이 빠르게 수렴될 수 있다. <- 은닉층이나 이런거는 이걸로 해준다.\n",
        "- 시그모이드: 이 활성화 함수는 0과 1 사이의 값을 출력하므로 이진 분류 문제에 적합.\n",
        "- 소프트맥스: 각 클래스에 대한 확률을 얻기 위해 분류기의 출력 레이어에서 자주 사용되는 소프트맥스 함수는 여러 클래스에 대한 확률 분포를 출력.\n",
        "- Tanh(하이퍼볼릭 탄젠트): 시그모이드와 비슷하지만 -1과 1 사이의 값을 출력."
      ],
      "metadata": {
        "id": "i6BwCyNx_wuu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Q. Sequential 모델을 사용하여 간단한 완전 연결 신경망(Feedforward Neural Network) 구성하기\n",
        "- 입력 레이어는 32개의 뉴런을 가지고 있고, ReLU 활성화 함수를 사용.\n",
        "- 은닉 레이어는 64개의 뉴런을 가지고 있고, ReLU 활성화 함수를 사용.\n",
        "- 출력 레이어는 10개의 뉴런을 가지고 있고, 소프트맥스 활성화 함수를 사용."
      ],
      "metadata": {
        "id": "jr_9_VidDxoh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-U7qwlv7dsA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(32, activation='relu', input_shape=(784,)), #입력\n",
        "    Dense(64, activation='relu'), #은닉 <- 은닉 레이어가 여러개일 수도 있음\n",
        "    Dense(10, activation='softmax') #출력\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### [옵티마이저]\n",
        "\n",
        "- 신경망 및 딥러닝의 맥락에서 옵티마이저는 손실을 줄이기 위해 가중치, 학습률 등 신경망의 속성을 변경하는 데 사용되는 알고리즘 또는 방법.\n",
        "- 옵티마이저는 학습 프로세스의 속도와 품질에 직접적인 영향을 미치므로 학습 프로세스에 매우 중요.\n",
        "- 최적화의 목표는 비용 함수(또는 손실 함수)를 최소화하는 모델에 대한 최상의 매개변수(가중치)를 찾는 것이다. 이 프로세스는 모델이 특정 작업에 대한 정확성과 성능을 향상시키는 데 필수적이다.\n",
        "\n",
        "[ 옵티마이저 유형 ]\n",
        "\n",
        "가중치를 조정하기 위한 자체 메커니즘과 전략을 가진 여러 가지 최적화 프로그램이 있습니다. 가장 일반적으로 사용되는 최적화 도구는 다음과 같다.\n",
        "\n",
        "- 확률적 경사하강법(SGD: Stochastic Gradient Descent): 이것은 가장 간단한 최적화 프로그램 중 하나. 각 훈련 예제를 개별적으로 사용하여 모델의 가중치를 업데이트. 여기에는 각 단계에서 훈련 데이터의 하위 집합을 사용하여 더 효율적으로 만드는 미니 배치 경사하강법(Mini-Batch Gradient Descent)과 같은 변형이 있다.\n",
        "- 모멘텀: 이 최적화 프로그램은 관련 방향을 따라 탐색하여 SGD를 가속화하고 현재 업데이트 벡터에 과거 단계의 업데이트 벡터의 일부를 추가하여 높은 곡률 방향의 진동을 완화.\n",
        "- Adagrad: 학습 속도를 매개변수에 맞게 조정하여 자주 발생하는 기능과 관련된 매개변수에 대해 더 작은 업데이트 (학습률)를 수행하고, 자주 발생하지 않는 기능과 관련된 매개변수에 대해 더 큰 업데이트 (학습률)를 수행.\n",
        "- RMSprop: 이 최적화 프로그램은 가중치에 대한 학습률을 해당 가중치에 대한 최근 기울기 크기의 이동 평균으로 나눈다. 이는 Geoff Hinton이 강의에서 제안한 미공개 적응형 학습률 방법.\n",
        "- Adam(Adaptive Moment Estimation): AdaGrad 및 RMSprop 알고리즘의 최상의 속성을 결합하여 노이즈 문제에 대한 희소 기울기를 처리할 수 있는 최적화 알고리즘을 제공.\n",
        "\n",
        "[ 옵티마이저 작동 방식 ]\n",
        "\n",
        "- 최적화 프로그램은 모델 매개변수에 대한 손실 함수의 기울기를 사용하여 조정. 이 기울기는 손실을 최소화하기 위해 가중치를 조정해야 하는 방향을 나타낸다. 가중치를 반복적으로 업데이트함으로써 최적화 프로그램은 모델의 최고 성능에 해당하는 손실 함수의 가장 낮은 지점에 도달하려고 한다.\n",
        "- 최적화 프로그램의 선택은 신경망의 성능에 큰 영향을 미칠 수 있으며, 최선의 선택은 특정 문제, 데이터의 성격, 신경망 아키텍처에 따라 달라질 수 있다. Adam은 다양한 문제에 대한 적응성과 성능으로 인해 기본적으로 좋은 선택이 되는 경우가 많지만, 특정 작업과 데이터 세트에는 다른 최적화 프로그램이 도움이 될 수 있다. 주어진 시나리오에 가장 효과적인 최적화 프로그램을 식별하려면 일반적으로 실험과 교차 검증이 필요하다."
      ],
      "metadata": {
        "id": "P3U2qIXMIUtV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### [ 손실 함수라고도 알려진 비용 함수 ]\n",
        "- 모델의 예측 출력과 실제 목표 값 간의 차이를 측정하는 수학적 함수입니다. 이는 모델의 오류를 정량화하여 훈련 중 최적화 프로세스에 대한 가이드 역할을 한다.\n",
        "- 신경망 훈련의 목표는 이 비용 함수를 최소화하는 것이다. 이는 모델이 예측하는 것과 실제로 관찰되는 것 사이의 오류를 효과적으로 줄이는 것을 의미.\n",
        "- 고급 신경망 API인 Keras는 다양한 유형의 문제에 대해 다양한 비용 함수를 내장하고 있으며 필요한 경우 사용자 정의 손실 함수를 생성할 수도 있다. 비용 함수의 선택은 분류, 회귀 등과 같이 해결되는 문제의 구체적인 성격에 따라 달라다.\n",
        "\n",
        "[ Keras의 일반적인 비용 함수 ]\n",
        "- 평균 제곱 오차(MSE): 회귀 문제에 사용됩니다. 예측값과 실제값 사이의 오차 제곱의 평균을 계산. keras.losses.MeanSquaredError()\n",
        "- 이진 교차엔트로피: 이진 분류 문제에 사용됩니다. 두 확률 분포, 즉 실제 레이블 분포와 예측 확률 사이의 거리를 측정. keras.losses.BinaryCrossentropy()\n",
        "- 범주형 교차엔트로피: 레이블이 원-핫 인코딩되는 다중 클래스 분류 문제에 사용. 이진 교차엔트로피와 유사하지만 여러 클래스에 적용. keras.losses.keras.losses.CategoricalCrossentropy()\n",
        "- 희소 범주형 교차엔트로피: 범주형 교차엔트로피와 유사하지만 레이블이 정수인 경우에 사용됩니다. 클래스가 많은 경우에는 메모리 효율성이 더 높다. keras.losses.SparseCategoricalCrossentropy()"
      ],
      "metadata": {
        "id": "y6GKl5pmLA0T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Q. 모델 컴파일하기 - 옵티마이저, 손실함수, 평가 지표 설정하기"
      ],
      "metadata": {
        "id": "RNUT2G2hLuER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "w2JMmUVyGQGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### [배치 크기, 에포크]\n",
        "[ 배치 크기 ]\n",
        "- 배치 크기는 기계 학습에 사용되는 용어로, 모델 학습 프로세스의 한 번의 반복에서 활용되는 학습 예제의 수를 나타낸다.\n",
        "- 신경망 훈련의 맥락에서 데이터 세트는 일반적으로 여러 배치로 나뉘며 모델의 가중치는 각 배치를 처리한 후 업데이트된다.\n",
        "- 배치 크기의 선택은 수렴 속도와 훈련 프로세스의 안정성을 포함한 훈련 역학에 큰 영향을 미칠 수 있다.\n",
        "\n",
        "- 작은 배치 크기: 각 업데이트 내에서 더 많은 노이즈로 더 빠른 업데이트가 가능. 이는 때때로 모델이 로컬 최소값을 벗어나는 데 도움이 될 수 있지만 훈련 과정을 더욱 불안정하게 만들 수도 있다.\n",
        "- 대형 배치 크기: 기울기에 대한 더 정확한 추정치를 제공하지만 업데이트 시 노이즈가 적다. 이는 더 안정적이지만 잠재적으로 더 느린 훈련으로 이어질 수 있습니다. 또한 대규모 배치에는 더 많은 메모리가 필요하므로 일부 하드웨어에서는 제한 요소가 될 수 있다.\n",
        "\n",
        "[ 에포크 ]\n",
        "- 에포크는 전체 훈련 데이터세트를 한 번 통과하는 것을 나타낸다. 한 epoch 동안 신경망은 모든 훈련 예제를 한 번 처리한다. 따라서 훈련의 에포크 수에 따라 학습 알고리즘이 전체 훈련 데이터 세트에서 작동하는 횟수가 결정된다.\n",
        "- 너무 적은 에포크를 실행하면 모델이 훈련 데이터에서 충분히 학습하지 못하는 과소적합이 발생할 수 있다.\n",
        "- 너무 많은 에포크를 실행하면 과적합이 발생할 수 있다. 즉, 모델이 노이즈를 포함하여 훈련 데이터에서 패턴을 너무 잘 학습하여 보이지 않는 데이터에 대한 성능이 저하될 수 있다.\n",
        "\n",
        "[ 배치 크기와 에포크 간의 관계 ]\n",
        "- 배치 크기 영향: 배치 크기는 가중치를 업데이트하기 전에 확인하는 예시 수를 결정. 배치가 작을수록 한 시대에 더 많은 업데이트가 이루어지며 잠재적으로 학습 속도가 빨라지지만 너무 작으면 불안정해질 수 있다. 배치가 클수록 더 안정적인 기울기 추정이 제공되지만 학습 속도가 느려지고 더 많은 메모리가 필요할 수 있다.\n",
        "- 에포크 영향: 에포크 수에 따라 학습 알고리즘이 전체 데이터 세트를 순환하는 횟수가 결정. Epoch가 많을수록 모델이 가중치를 학습하고 조정할 수 있는 기회가 더 많아지지만 숫자가 너무 높으면 과적합이 발생할 위험이 있다.\n",
        "- 요약하자면, 배치 크기와 에포크 수는 신중하게 균형을 맞춰야 하는 신경망 훈련의 두 가지 기본 하이퍼파라미터이다. 이러한 매개변수의 최적 설정은 특정 데이터세트와 문제는 물론 사용 가능한 계산 리소스에 따라 달라진다."
      ],
      "metadata": {
        "id": "WfXR1mE-NIML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#10000개 샘플에 100개 배치에 각 에포크의 스텝이 100이 되는 것"
      ],
      "metadata": {
        "id": "dBSgLJqILaOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Q. 모델을 간단한 데이터셋에 적용하여 학습하기\n",
        "- MNIST 데이터셋을 사용.\n",
        "- 배치 사이즈는 32, 에포크 수는 10으로 설정."
      ],
      "metadata": {
        "id": "-x1CBipzRzTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "60000/32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZtgnBNOTuh9",
        "outputId": "d14a0ab3-32e8-4461-9f44-3a4afbc0c7de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1875.0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 784)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 784)).astype('float32') / 255\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=10, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jxus7cXNMJki",
        "outputId": "6070180d-bb3d-4fbc-d04b-36a44cc6c814"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3285 - accuracy: 0.9060\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1538 - accuracy: 0.9544\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1170 - accuracy: 0.9649\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0978 - accuracy: 0.9709\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0846 - accuracy: 0.9732\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0730 - accuracy: 0.9774\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0658 - accuracy: 0.9796\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0583 - accuracy: 0.9815\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0529 - accuracy: 0.9832\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0490 - accuracy: 0.9841\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a31da56ef80>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels # 원 핫 인코딩 된 경우라서 categorical_crossentropy 을 쓴다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qq8gswK6p1eH",
        "outputId": "48a7bf0e-afbf-4304-c14a-c660cf3d0f59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Q. 모델 평가하기\n",
        "- 테스트 데이터셋을 사용하여 모델을 평가."
      ],
      "metadata": {
        "id": "XnvvNUU6WRl4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_SdKRkvWcvV",
        "outputId": "12d9ffba-2347-4096-db37-c94bc7156687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1233 - accuracy: 0.9676\n",
            "Test accuracy: 0.9675999879837036\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Q1_0201. MNIST 데이터셋에 대하여 Sequential 모델을 사용하여 간단한 완전 연결 신경망(Feedforward Neural Network) 구성하세요.\n",
        "- 입력 형태(input_shape): input_shape=(28, 28)로 설정. 이는 모델이 28x28 픽셀 크기의 이미지를 입력으로 받는다는 것을 의미이며 첫 번째 레이어인 Flatten은 이 2D 이미지를 784(28x28) 요소의 1D 배열로 평탄화. Flatten(input_shape=(28,28))\n",
        "\n",
        "- 레이어 구성: 모델은 평탄화 레이어(Flatten) 다음에 128개의 뉴런을 가진 완전 연결 레이어(Dense)를 가지고 있으며, 그 다음에는 10개의 출력 뉴런을 가진 또 다른 Dense 레이어가 있다. 출력 레이어는 소프트맥스 활성화 함수를 사용하여 다중 클래스 분류를 수행.\n",
        "\n",
        "- 컴파일:\n",
        "  - optimizer='adam',\n",
        "  - loss='sparse_categorical_crossentropy',\n",
        "  - metrics=['accuracy']\n",
        "\n",
        "- epochs=5"
      ],
      "metadata": {
        "id": "aHIO0r7GWkUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### 수정>노트설정> GPU 설정해서 하기\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# MNIST 데이터셋 로드\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# 데이터 정규화\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Sequential 모델 정의\n",
        "model_sequential = Sequential([\n",
        "    Flatten(input_shape=(28,28)), #입력\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax') #출력\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model_sequential.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습\n",
        "model_sequential.fit(train_images, train_labels, epochs=5, batch_size=32) # 여기서 가중치를 처음에 랜덤하게 곱해서, 그러고 역전파를 통해서 계속 가중치를 수정해가는 과정을 반복. 그리고 비용이 최소화가 되면 멈춤.\n",
        "# 그래서 그래프를 그래서 에포크의 accuracy와 실제 accuracy와 비교해서 학습용 accuracy는 더 좋아지는데 실제 accuracy는 더 안좋아진다는 것은 과대적합이라는 것.\n",
        "# 그래서 에포크 수를 그래프에서 안좋아지기전 시점으로 정하는 것이 좋음.\n",
        "\n",
        "\n",
        "# 모델 평가\n",
        "test_loss, test_acc = model_sequential.evaluate(test_images, test_labels)\n",
        "print('\\nTest accuracy (Sequential):', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8evvDYr0ZK-e",
        "outputId": "f2714525-c092-4c05-8d02-5377097fb84e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2373 - accuracy: 0.9306\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0985 - accuracy: 0.9700\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0690 - accuracy: 0.9788\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0544 - accuracy: 0.9822\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0441 - accuracy: 0.9854\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0746 - accuracy: 0.9756\n",
            "\n",
            "Test accuracy (Sequential): 0.975600004196167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels # 데이터 라벨이 정수형 (int) 그러므로 sparse_categorical_crossentropy를 쓴다. 그래서 원핫인코딩 안해줘도 됨."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urhQbQ2lpqIz",
        "outputId": "66fae051-52a0-46a7-8617-49c2fe2345a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 20240202"
      ],
      "metadata": {
        "id": "p_Hx6xs9RTVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 매개변수 = (입력단위*출력단위) + 출력단위(bias가 각 출력단위 마다 하나씩이라서) = (784*128) + 128 = 100,480. (128*64) + 64 = 8,256. (64*10) + 10 = 650\n",
        "model_sequential.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQDJyNVyO4kY",
        "outputId": "346ce337-eafc-483e-891c-54afdade4d30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               100480    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109386 (427.29 KB)\n",
            "Trainable params: 109386 (427.29 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### [ 완전신경망(완전연결신경망, Fully Connected Neural Network)에서 각 층의 파라미터 수 계산 ]\n",
        "\n",
        "- 각 연결에 하나의 가중치가 있으므로, 특정 층의 가중치 수는 이전 층의 뉴런 수와 해당 층의 뉴런 수를 곱한 값과 같다.\n",
        "- 각 뉴런에는 하나의 편향이 있으므로, 특정 층의 편향 수는 해당 층의 뉴런 수와 같다.\n",
        "- 특정 층의 총 파라미터 수는 가중치 수와 편향 수의 합이다.\n",
        "\n",
        "가중치의 의미\n",
        "- 이전 층의 뉴런 수: 각 뉴런은 이전 층의 모든 뉴런으로부터 입력 신호를 받는다. 이전 층에 더 많은 뉴런이 있을수록, 현재 층의 한 뉴런이 처리해야 할 입력 신호의 수가 더 많아진다.\n",
        "- 해당 층의 뉴런 수: 해당 층에 더 많은 뉴런이 있다는 것은, 이전 층의 각 뉴런으로부터 오는 신호를 받아들이는 더 많은 처리 단위가 있다는 것을 의미.\n",
        "- 가중치의 역할: 각 가중치는 입력 신호의 중요도를 조정. 즉, 특정 입력이 해당 뉴런의 활성화에 얼마나 영향을 미치는지 결정하는 역할을 한다. 가중치는 학습 과정에서 조정되며, 신경망이 훈련 데이터로부터 패턴을 학습하는 방식을 결정.\n",
        "\n",
        "가중치 수 계산\n",
        "- 신경망에서 정보가 전달되는 방식과 학습이 어떻게 이루어지는지를 나타낸다. 각 가중치는 이전 층의 특정 뉴런과 현재 층의 특정 뉴런 사이의 연결 강도를 나타내며 이전 층의 뉴런 수와 해당 층의 뉴런 수를 곱하는 것은 모든 가능한 연결을 고려하여 이들 간의 관계를 정량화하는 방법이다.\n",
        "- 계산 과정을 통해 각 연결마다 하나의 고유한 가중치가 할당\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "이러한 구조는 신경망이 복잡한 패턴과 관계를 모델링할 수 있도록 하며, 다양한 입력에 대한 반응을 조정하는 데 필요한 유연성을 제공합니다. 가중치의 조정은 신경망이 학습 과정에서 경험을 통해 얻은 지식을 내재화하는 방식입니다."
      ],
      "metadata": {
        "id": "xxqGZszdREVV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### [ 픽셀(pixel) ]\n",
        "- 디지털 이미지를 구성하는 기본 단위. 단어 \"픽셀\"은 \"Picture Element\"의 줄임말로, 이미지를 구성하는 가장 작은 단일 색상의 점을 의미. 각 픽셀은 특정 색상과 밝기 값을 가지며, 이러한 픽셀들이 모여 전체 이미지를 형성\n",
        "- 색상과 밝기: 컬러 이미지에서 각 픽셀은 일반적으로 빨강(Red), 초록(Green), 파랑(Blue)의 세 가지 색상 채널 값을 가지며, 이를 RGB 값이라고 한다. 각 채널의 값은 보통 0에서 255 사이의 정수로 표현되며, 이 값들의 조합을 통해 다양한 색상을 나타낸다. 그레이스케일 이미지에서는 단일 채널만 사용하여 밝기를 표현하며, 0은 검은색, 255는 흰색을 의미하고, 그 사이의 값은 다양한 회색 음영을 나타낸다.\n",
        "- 해상도: 이미지의 해상도는 이미지의 세부 사항과 선명도를 결정하는 중요한 요소입니다. 해상도가 높은 이미지는 더 많은 픽셀을 가지며, 따라서 더 세밀한 디테일을 표현할 수 있다. 예를 들어, 1920x1080 해상도의 이미지는 가로 1920픽셀, 세로 1080픽셀로 구성되어 있다.\n",
        "- 디지털 표현: 디지털 이미지 처리, 컴퓨터 그래픽, 디지털 카메라 촬영과 같은 분야에서 픽셀은 기본적인 작업 단위로 사용되며 이미지의 품질, 색상 처리, 이미지 분석 등은 모두 픽셀 데이터를 기반으로 한다."
      ],
      "metadata": {
        "id": "cSXwZbsvRgCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images[1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikmMjKh4Vr0G",
        "outputId": "651be649-0710-4cad-e916-26cd39db101c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p44jgPGaWdo9",
        "outputId": "a2f95ba3-3764-4bb0-8a72-69f5d5e10eff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  51, 159, 253, 159,  50,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  48, 238, 252, 252, 252, 237,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         54, 227, 253, 252, 239, 233, 252,  57,   6,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  10,  60,\n",
              "        224, 252, 253, 252, 202,  84, 252, 253, 122,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 163, 252,\n",
              "        252, 252, 253, 252, 252,  96, 189, 253, 167,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  51, 238, 253,\n",
              "        253, 190, 114, 253, 228,  47,  79, 255, 168,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  48, 238, 252, 252,\n",
              "        179,  12,  75, 121,  21,   0,   0, 253, 243,  50,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  38, 165, 253, 233, 208,\n",
              "         84,   0,   0,   0,   0,   0,   0, 253, 252, 165,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   7, 178, 252, 240,  71,  19,\n",
              "         28,   0,   0,   0,   0,   0,   0, 253, 252, 195,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  57, 252, 252,  63,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0, 253, 252, 195,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0, 198, 253, 190,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0, 255, 253, 196,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  76, 246, 252, 112,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0, 253, 252, 148,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  85, 252, 230,  25,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   7, 135, 253, 186,  12,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  85, 252, 223,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   7, 131, 252, 225,  71,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  85, 252, 145,   0,   0,   0,   0,\n",
              "          0,   0,   0,  48, 165, 252, 173,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  86, 253, 225,   0,   0,   0,   0,\n",
              "          0,   0, 114, 238, 253, 162,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  85, 252, 249, 146,  48,  29,  85,\n",
              "        178, 225, 253, 223, 167,  56,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  85, 252, 252, 252, 229, 215, 252,\n",
              "        252, 252, 196, 130,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  28, 199, 252, 252, 253, 252, 252,\n",
              "        233, 145,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  25, 128, 252, 253, 252, 141,\n",
              "         37,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "image_data = train_images[1] # Reshape back to 2D format if necessary\n",
        "\n",
        "plt.figure(figsize = (1,1))\n",
        "plt.imshow(image_data, cmap='gray') # Display the image\n",
        "plt.axis('off') # Turn off the axis numbers/labels\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "id": "2K2amYanWjoh",
        "outputId": "002d4c80-89fb-43cc-90f7-69ec34835422"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 100x100 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images[1].reshape(784,).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clszwmalYMHH",
        "outputId": "3abab8f7-720f-414e-8f05-38fedd1cb795"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784,)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### MNIST 데이터세트의 모양을 (60000, 28, 28)에서 (60000, 784)로 변경하는 이유\n",
        "- 기계 학습의 일반적인 전처리 단계이며, 특히 완전히 연결된(밀집된) 신경망의 맥락에서 필요하며 이 프로세스를 이미지 \"평탄화\"라고 한다.\n",
        "\n",
        "[ 주요 이유 ]\n",
        "- 신경망의 입력 형식: 신경망의 완전 연결된 레이어에서는 입력이 1D 벡터일 것으로 예상. 각 입력 뉴런은 다음 레이어의 모든 출력 뉴런에 연결.\n",
        "- 이미지의 원래 2D 구조(28x28픽셀)는 공간 정보를 2차원으로 표현하기 때문에 이러한 기대에 맞지 않다. 이미지를 1D 벡터(이 경우 784개 요소)로 평면화하면 각 픽셀이 네트워크에 제공될 수 있는 개별 특징이 된다.\n",
        "- 단순화: 평면화는 정보 손실 없이 데이터 구조를 단순화. 각 픽셀 값은 여전히 ​​전체 입력에 기여하지만 네트워크 계층에서 수행되는 수학적 연산(예: 내적)과 호환되는 형식.\n",
        "- 네트워크 아키텍처와의 호환성: 대부분의 기본 신경망 아키텍처, 특히 입문 목적이나 간단한 작업에 사용되는 아키텍처는 다차원 데이터가 아닌 기능 벡터로 작동하도록 설계. CNN(컨벌루션 신경망)은 다차원 데이터를 직접 처리할 수 있지만(픽셀 간 공간 계층 보존) 완전 연결된 네트워크는 본질적으로 이러한 데이터를 처리하지 않는다.\n",
        "- 효율성: 평면화된 이미지로 작업하는 것은 때때로 특정 작업에 대해 계산적으로 더 효율적일 수 있다. 특히 신경망에서 데이터 배치를 처리하기 위해 행렬 곱셈을 사용할 때 더욱 그렇다.\n",
        "- 그러나 병합하면 픽셀 간의 공간적 관계가 삭제된다는 점에 유의하는 것이 중요. 이는 이미지 인식이나 객체 위치 파악과 같이 픽셀의 공간적 배열이 중요한 작업에는 적합하지 않다. 이러한 작업의 경우 CNN(컨벌루션 신경망)이 공간 계층을 유지하면서 2D 이미지를 처리할 수 있어 네트워크가 픽셀 배열을 기반으로 더 복잡한 패턴을 학습할 수 있으므로 더 적합하다."
      ],
      "metadata": {
        "id": "EZikaT86XsuW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[ 레이블이 원-핫 인코딩되지 않은 이유 ]\n",
        "\n",
        "모델의 손실 함수(loss function)로 'sparse_categorical_crossentropy'가 사용되기 때문. TensorFlow와 Keras에서 두 가지 유형의 크로스엔트로피 손실 함수를 제공하며, 각각은 다음과 같은 경우에 사용된다:\n",
        "\n",
        "- 'sparse_categorical_crossentropy': 이 손실 함수는 레이블이 정수 형태로 제공될 때 사용. 즉, 각 샘플에 대해 단일 정수로 클래스 레이블이 지정되며, 이 경우 원-핫 인코딩을 할 필요가 없다. 이 함수는 내부적으로 정수 레이블을 적절한 원-핫 인코딩 형태로 변환하여 처리.\n",
        "- 'categorical_crossentropy': 이 손실 함수는 레이블이 원-핫 인코딩된 형태로 제공될 때 사용. 각 샘플의 레이블이 벡터이며, 벡터의 각 원소는 해당 클래스의 소속 여부를 나타낸다(클래스에 속하면 1, 아니면 0)."
      ],
      "metadata": {
        "id": "pZk8jdmmZkpS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Convolutional Neural Network (CNN)\n",
        "CNN은 컨벌루션 레이어와 풀링 레이어를 사용하여 이미지의 공간 계층 구조를 캡처할 수 있기 때문에 이미지 처리 작업에 특히 적합\n",
        "\n",
        "[ CNN 아키텍처 ]\n",
        "- 컨볼루션 레이어(Conv2D): 이 레이어는 컨볼루션 작업을 수행하여 이미지에서 공간 특징을 캡처.\n",
        "- 풀링 레이어 (MaxPooling2D): 이 레이어는 다음 컨벌루션 레이어에 대한 입력 볼륨의 공간 크기(높이 및 너비)를 줄인다. 이는 계산 부하와 메모리 사용량을 줄이고 표현의 추상화된 형식을 제공하여 과적합을 줄이는 데 사용.\n",
        "- 밀집 레이어(완전 연결 레이어): 여러 컨볼루션 및 풀링 레이어 이후 신경망의 상위 수준 추론은 컨볼루션 레이어에서 추출하고 평면화한 특징을 기반으로 분류를 수행하는 Dense 레이어를 통해 수행.\n",
        "- 모델은 컨벌루션 레이어와 밀집 레이어에 'relu' 활성화를 사용(10자리 클래스에 대한 확률을 출력하기 위해 'softmax'를 사용하는 출력 레이어 제외). 다중 클래스 분류 작업에 적합한 adam 최적화 프로그램과 categorical_crossentropy 손실 함수로 컴파일.\n",
        "\n",
        "이 CNN 아키텍처를 사용하면 MNIST와 같은 이미지 분류 작업에서 높은 정확도를 달성하는 데 중요한 이미지 내 공간 관계를 활용할 수 있다."
      ],
      "metadata": {
        "id": "h4PQ6Rl2bwbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load and prepare the MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Reshape the images to have a single color channel and normalize pixel values\n",
        "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255 # 마지막에 1이 붙은 것은 채널. 채널 안 쓰면 1이 기본이 된다. 1은 흑백. 255 나누는 것은 정규화. 그래서 0에서 1의 숫자로 바꿔준다.\n",
        "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
        "\n",
        "# Convert the labels to one-hot encoded vectors\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "# Define the model architecture\n",
        "model = models.Sequential()\n",
        "# 32개의 필터, 각 필터의 크기는 3x3, 28x28 픽셀의 흑백 이미지 (채널 수 1)\n",
        "model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)))\n",
        "model.add(layers.Conv2D(64,(3,3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2,2))) # 입력 이미지의 크기를 줄이는 데 사용되며, 주요 특징을 유지하면서 계산량을 줄인다.\n",
        "model.add(layers.Conv2D(64,(3,3), activation='relu'))\n",
        "\n",
        "# Add Dense layers on top\n",
        "model.add(layers.Flatten()) # Flatten the 3D outputs to 1D before adding the dense layers\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax')) # 10 classes for digits 0-9\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=64)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f\"Test accuracy: {test_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQdA9pqUb-er",
        "outputId": "a8612d19-7e8d-4e08-ca77-2719be685b25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "938/938 [==============================] - 10s 6ms/step - loss: 0.1317 - accuracy: 0.9607\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0380 - accuracy: 0.9884\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0244 - accuracy: 0.9923\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0176 - accuracy: 0.9944\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0143 - accuracy: 0.9952\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0302 - accuracy: 0.9914\n",
            "Test accuracy: 0.9914000034332275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 데이터 셋 : Fashion MNIST\n",
        "\n",
        "기존의 MNIST 데이터셋과 같은 형식을 가지고 있지만, 손으로 쓴 숫자 대신에 10가지 범주의 패션 아이템(예: 티셔츠, 바지, 신발 등)의 이미지로 구성"
      ],
      "metadata": {
        "id": "TccbSR6Ajk8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Fashion MNIST 데이터셋 로드\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sB0qa00jrL4",
        "outputId": "197a3cac-deda-4bd3-cd61-943106f2b4fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images.shape # 60000개 데이터 28x28 픽셀"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnXIZXV8j61N",
        "outputId": "d53e284f-ec14-48ae-cffe-244dfb334ece"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "image_data = train_images[0] # Reshape back to 2D format if necessary\n",
        "\n",
        "plt.figure(figsize = (1,1))\n",
        "plt.imshow(image_data, cmap='gray') # Display the image\n",
        "plt.axis('off') # Turn off the axis numbers/labels\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "id": "naVnWnjKkXEz",
        "outputId": "6facef84-9de3-4c5b-eadf-9065c79d3a19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 100x100 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGEAAABhCAYAAADGBs+jAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAATZElEQVR4nO1dSXMbVRc9Pam71YNm23JEjINJKizBK1hQWfLP2UEVm1CVFOBgx7GtwRp6Hr5F6r5cPbcTK+Ag5dOtUsnR0Op+547n3tdRyrIssZX/VNT/+gS2sgVhLWQLwhrIFoQ1kC0IayBbENZAtiCsgWxBWAPZgrAGot/1g4qi3Od5fJZyVzJiawlrIFsQ1kC2IKyBbEFYA9mCsAayBWEN5M4p6iYIpdGqqkLXdaiqiizLkGXZndPF/0I+GxAURYGu69A0DbZto9frwbIsjMdjnJ+fI03TW79H4JVl+Z+A9dmAAACapkHXdQGC53kAgMvLy1tBAJYL0S0IHxCusSS6rotHq9WC4zhwXRetVgu2bcPzPPi+j1qtJjS9LEvEcYwsy8TxFEX5z1zWRoEALAOhKArq9Tpc14Xruvjmm28wGAygqio0TROxIc9zRFGELMtQFAWSJMHl5SWur6/v5IK4y6J/l2WJoig++Nm7yEaBQBcoW4JlWajX6+j1ehgMBiiKAmmaoigK+L4vLCHLMuR5jjiOMR6P76T9fFHviz/bSBBo8RRFgeu62NnZQavVwt7eHvr9PrIsE5pPVhDHMYC3FpQkCVzXxWQyQRRFuLq6QhRFyPP8Ruy4DSRKBOTPfUxw3xgQOAA8FW21Wjg8PES73cZXX32FR48eIU1TTKdTJEkC27ZhmibSNBXZU57nmM1miKIIl5eX+PXXX5eAkN0MX2ASXddhGIZQCHqQy1tFNgaEKlEUBYZhwHEc1Ot18UiSBEmSQFEU4arSNIWmadA0DUVRiPfiOEa9Xodt2wAgrIcvLF98VX1b3+q6DtM0oSgKiqJYeuR5vtJ1bAwIPBDSoiiKAs/zsLu7i1arhXa7jUajgSRJhNtRVVX8PZ1OcX19DQCwLAu2bUPXdSiKgsVigdlshqurK6RpisVigcVigTzPEQQBoiiCaZrwfR+maYoMTFVVTKdTYXnj8Rjz+Xyla9sYEADcMHOKCTII3L9rmgYASJIEs9kMk8kEqqrCcRz4vo9Go4H9/X0AwGg0wunpqXBTo9EIcRzj6uoK0+kUrutiMBjAcRx0Oh08ePAAqqri/Pwcr1+/RhAEIilYRTYKBBJelNHDsixomoayLEWKWhSFcBsAYNs2XNeFqqqo1WoCIH5cqifq9TqiKIKu68Ki6vW6qEPIFamqKiyEzol+766ykSCQC3JdFwcHB0I7DcNAHMcoikIsML1eFAUcx8FgMBDZU5IkSNMU8/kcaZoiiiJomgbTNNFut+E4jsjCgLcg1et1aJqGNE1FndFsNnFwcIAgCKBpGgzDWOl6NhIEoiUajQZ2dnbQbrdhWRZ0XRdknaqqIo2s1WoAAN/3AQBxHOP09BTD4RBlWSIMQ0RRhKIooKoqVFWFYRhwXRe6rsN1XViWJeJSURQYDocYDocoigL7+/s4PDxEEAS4uLjAdDpd6Xo2AgS5qCKNpjhgmqZwL5S98NSRgjPwNqjrui4yJtM0BY1RlqXIjNI0FW5IURTxOj2bpomdnR0oioJutwvf96EoikgAVqkVNgIELoqiYH9/Hz/++CN2d3fR7/fRbDYFAHJVS9rLtVhVVWFBnNIAID4zHo8xGo2QZRnm8zkWi8XSsVqtFp48eQLTNNHr9dDtdnF+fo7FYoEXL158fiDIF+Q4Dvb399Hv90XKKHM7/LuyJSmKIuoCCsI8/aWCLY5jxHEsUlUOQq1WQ6/XQ71eR6PRgOu6sG1bFIqfHQiyEAkXxzHSNEWWZVBVdSmFJauQF58CNrkqCuLksjgdQm6JMiVeuHU6HXS7XdRqNeR5jtFohPF4LD63imwkCORCoihCmqZCc6na5Swq0RzEqFIaS/SCTArSQrfbbTSbTWEZeZ4vWRjVGYqi4O+//8bp6amoFVaVjQShilLgmg28c0kEAC34bQQbB4KyKjoGuSDOW1mWJYK6oij/qI26kSCQVpNmV5F7pL0UaLmvVxQFtVoNhmFU8kPAMoXNA34VW1qr1eC6rqghVpWNBIE01TCMG2kpb7iQT6cagFyYpmloNptwHAfATToEwJIrMwxD/AYP4BwEz/PgeZ6oSVaRjQKBFoVoCx5k+TMXnprmeS5SUToe/66c3nJQ5WNzjkgu8shN3VXWEoSqxjtppKZpsCwLrusKzeOFFNHI3J1Q0M6yTCwcHYeCPIFAsYAWlb5PhRuN0sRxjPl8LsAlDomIvVV6CmsHQlWPlhaILMA0TUHaydVslmU3MiPZEuh9asqoqirAo8WnDIuOm6bp0uezLMN0OkWe5zAMA7VaTVAc7XZ7sy1BzkLoYgzDQLPZhGmaaDQagqqgBQYgFk4u3GgxCUC5I8Y1/7YgzQcHiMCbTCZIkkQ0kyj20HfuKmsHAgnne4C3efnXX38t2pjtdhue54n+MX2WXIjsxsgyTNMUHTayIFpcoDodJasxDAO2bcMwDJyenuLFixdYLBbodDpot9uYTqci8K8iawkCz/FJYw3DQKPREGQZaTRvoFS5Me7byTXRa1ULXpWy3jZeeX19jdlsBsMwYFmWsIRVZ5jWCgS+EHIrM8syzGYzmKaJxWKx1FCXtR/A0ntUD/DATZbAf5uDSHUI/TbFFNL0Wq2GwWCAxWKBNE3x+vVrTKdTvHnzBldXV5sJAvll4B2JxiVNU8Fqki/mvQPgHRjAOxCoyUJVLRVsRHnweEAP3oegxaeag+gLy7Lw5MkTxHGM3377DS9fvsRkMsGff/6JV69ebSYIXG67ANLq2wIosOw6yPVUBevbAifnmqoSBJ5F1et1cT5hGIrmEM043VX+NRDkC6vyz7ctHL0vuyAu3W4Xz549w6NHj3BwcCDiAeX/AJYyHDoO115eSXNGteo3+QgLz6I4d2RZlmgMpWkqWquryr8Cgszd8MAqXxRwu6a/z4Tb7TaePXuG4+NjsZgcBJ6K8uPwGSLOAZHL4d0y+fdl7olfq2VZaLfbyLIMhmGIfvWqM0fAPbgjfrK8ofI+KwCWMw/DMMTf9Nzr9eA4jpgppXjAF0hmVYGb4PO4QVKlNNwyq4QrHBWPYRgujUbeVT4KBPlkq7ib29zRbeK6Lnq9HkzTRL/fx97enuheeZ6Hvb09dLtd0fsNw3CpMJKtkN6jKpmaN1U+X44ZPDGQ6XH+WRo6brfbePr0KS4uLnBycrLyeq4MQlWwkv+u+veHxLIsdDodOI6Do6MjPH78GI7j4OHDh+j1eqjVavB9X1hBkiQ3Ai+5I/p9WkDubujceQFXRVXzWCArF1kTuSvP8/DgwQMxQLCqrAxCFdsoCy0KXyDKuzkFYBiGyDC63S4ePnwI27YxGAzQ6XTEHCm5J74gXCMp8MpAAMu+n7sdPpfKiyxOXxMtzYM5tyCZyl4sFp/OHb3PV9LwFPE09Xoduq6LHTOapsFxHDG1dnR0BN/30Ww2sbu7i1qtJhouqqrCsiyR5/OmjG3bKMsSURQhDEMAEL1m7nKomqVqmbOluq4jCAKMRqOlwS1N07Czs4Nms7kU0ygZINDpeL7v44svvoCqqnBd99OAwEW2Ch5YTdMUE3DNZhOtVguGYcDzPFiWhW63i8ePH6PT6cD3fXS7XVHJckoaWJ6CIDaVhAdn7qJ4wUbHJRB5RRxFEYIgELt66PVarbZUk9D35YSDLMFxnE9jCXxhe70eer3eUquR5jGp4qQZUZrh5HOg1BPgFS2npAkE0jpaBKKWy7IUFkVWwQe2OD9ElDO5QnqmkRW6Bk7wBUGwRIXz+ML5KIoFZPX3zh3RzI/rujg+Psbx8bEYM+duiM9jch9clqXIqek1KrJoAbkl0Pf5FqjZbIbRaAQAODw8xGAwQJ7nePPmDebz+VKgJkBJKTzPu1HLdLtduK4r4gCBN5vNbhR8tMi8+UOKOZlMPk17k2Y0fd9Hp9PB3t6eCKAEAp+Q5ukdXRzxNrxQ4hUtz+2rMrEsy26MoVfREjIzyoXHNbJgvvuGuCnelSML40Wh3HD6UNJSJSvddEpRFPT7ffzwww/odDo4Ojq64Y5kEo4vMjdT8rW8kKLKV85GeFalKAqGwyFOTk4QRREACOrA9308fPhQLByvkvM8x2QywXg8RlEUCMNQ7Obhaatt21BVVVTjVRtTZCCTJEGe5wjDcKmHfS8gqKqKfr+P77//Hv1+X2Q8clXMNbpqDxf55CpOh4Q3WyjQO44jtPDk5ATT6VSMuTebTXz33Xd48OAB0jTFbDYTzR46B9pRk6YpxuMxFouF6AtbliVYU+4SeVoqW6dcjdPmlHsDgYKq67pwHEd0mOSCpqqwqcqgZMKPAyE/+GfK8l2Dh44xm80AvN1p4/s+0jQVWsn5nzAMhYZzF8LjEhfu1njN877AW1WrfEjuDMK3334LRVFwdHSEbrcr9obRLD6/EO4+5JSNA8OzlDiOEQSBaJykaXpjdJGyld3dXfz0008IggDPnz/H8+fPoShvxxGpFqEsh7sx2iCo6zra7baoRyiWAVg6NxI+OCD3LDhQ1OhvNBr3A8Lh4SEAYH9/H57niV2SNHtJ0waU8fDKmJ84XxQexAkAooT5kC8fbVcUBc1mE4PBAEmS4PT0FGdnZ4iiCK9evRIFHm0coS6YruvY3d3F7u6u2DbVbrdv8E08BeVVeBXxx+MEXScVqPcCAgUcItD4tiTuivI8F6kmzxh4SghA+F36LB/w5cGtis3UNE0Ew1arhcePHwsuqSgKAQKlygRCq9VCq9VCrVa7MU5PvyVzT7L288/KbokKVdu272fuaDabQVEUTKdTTCYTcSKcXyH/G4YhyrIUQVVuH9KipGmKIAhQliVms5kItLwQ4oUZaSn5ekVR8PTpUxweHor252KxgGVZaLVaYiyGMh6yUr6QdO5ViQUtrDxOT8IViizG9330er37sQTKx+M4Fpu1+UXx/J5rJZ0k9//0zAuwJElEdsHJMx6wKe3kqWur1YLrusiyDOfn55hMJksgENfPMx6qVWi/820A8Gc5QSArkOsTAv1eQCDfT1pJlWSSJOLESHjVyMGgE+XazhdYDtZypU21BdUlBCS5RhoM43OqWZYtEXx0/jxz4koj78gBIH4LeDdMQGQfgUtrQQpwLyBMp1MoiiKaKZQXR1EkgiznjmhKjS6Q+3p5fxlvynMQ5LgiM6TkrsIwFMyq7/tLi0lZF+eW6DdJIYIgWBprkZWHF4+c3XUcZ+mc4jiG67ro9/v3A0Icx6KSpAWtugdEFT3AiTcS7lbkIazbHvyCeUZDVsJH2GlRecEoDwRzxlY+R86YcvaWANQ0Tcy1cpKRx5B/HYTLy0soioJXr17h5cuXGI1GYvyPNIrIMiqe6N5CcjDjKV3VJg85gPJWo5xl8cqWFIXHD06d8IXl4NA50CLKAZs6eUSPk+IQmDR5AUC0Xu/FEi4vLwEAZ2dnePnyJTqdDmzbxpdffimqVn5TJ045AxCznDIA5G9lQHiNQPWBLLRActNf5qTowV2gzE/RiH0Vp0WJCL1HYHAXSrtBabfnKnJnEOikoijCeDwGALFjkfw/sNyDlTWLFoNvwuO8E/2bv8ZBkHNzWbtlAOh4/Lg856fj8R6A7BopC+OuRlYgAMJNh2GI+Xx+P5ZAcn5+jp9//hm2bePs7Ax//PEHPM/Do0ePsLOzA03T4HmeiB8UyHmjhigJbhVVliCLTBlUvc8rXDl+8L/lIovcGaXMZB0AxE1H+DlQZayqb6fvhsMhrq6u8Pvvv+OXX35ZaU1XBuH6+hrX19fQdR1hGGI6nYpb3PR6PWGauq4vsZh0gbK28ZTvtpEUmeyjReQg8vc5oDxQVrk0/jq5NdlCZIq+LEtBfVDGSLfxOTs7w19//XW/lkBSFAWCIMB4PEae53jx4gWyLFuiDHh7kwg1ftEcBL5YfGHlYoh+m2csXLu5O6JgK7dKbxOiQuQRGYoVlM7meS7cUVmWuLi4wMXFhbgv0ioAAIBS3vEbXBNIaC8vTVPU63V4noeDgwN4noejoyMcHx/DdV0xRcFpC35c/sxJPzle0GJRZ42E7tAlD+OSG+R+/jYhLotiDZ9xpeTj5OQE8/lceIE4jsVNp6IownA4FNnhXcH4qOEvOjgVawAwHA4BAI1GA1mWiVthUiVMxBaldJQp3WYVckVNnwGwlN9zX02aT98DIFzh+8g4ngnR71EtxMGj8ZjJZILpdIrLy0tx256zs7OVSDsuHzX89T5JkgTD4RBhGOL58+diEoHcE3HuxOdQgcUrVLIaqngp8yKrCIJAbNqj14k4rLIEvpunCgQSnmXJwwYAEIYhzs/PEQQBgiAQaTlV5B8rd3ZH7zNj+XOk5RQTeCak6zq63S48z1tqWVIfoSxL0b0rikLcu5RTEfP5HOPx+MZtDGSiDVh9HFMm6rjwAo/3OaoAW+W3/3UQPiQEAt0zrl6vo1ariUoTgLjtclG8ve9QGIZLbcrFYoHRaPRR/dxPKfcWE/6pFEUh7jnHxw6527i+voZpmqL65swtuah/Yv7rJp/cEuRj8b+rqmb+uvy5dZe1tQTg/X73ttc+Z9n+nzprIFsQ1kC2IKyB3Dkm/L/56U8pW0tYA9mCsAayBWENZAvCGsgWhDWQLQhrIFsQ1kC2IKyBbEFYA/kfvw61tHcuGwAAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axYT-CngkbHv",
        "outputId": "df7ac872-a649-4a1f-e85d-c1e9a83de8bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 0, 0, 3, 0, 2, 7, 2, 5, 5], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Q1_0202. 다음 사항을 준수하여 Fashion MNIST 데이터셋에 대하여 Sequential 방식으로 모델 생성 및 평가를 수행하세요.\n",
        "- 입력 계층 및 첫 번째 Dense 계층 : 출력 512, activation='relu'\n",
        "- 두 번째 Dense 계층 : 출력 256, activation='relu'\n",
        "- 출력 계층 : 출력 10, activation='softmax'\n",
        "- 모델 컴파일 : optimizer='adam', loss='categorical_crossentropy',         metrics=['accuracy']\n",
        "- 모델 학습 : epochs=10, batch_size=64"
      ],
      "metadata": {
        "id": "atxLHhfokpxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# fashion MNIST 데이터셋 로드\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# 이미지 데이터를 0과 1사이의 값으로 데이터 정규화\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# # 이미지 데이터를 1D 벡터로 변환 (28x28 이미지를 784 크기의 벡터로 평탄화)\n",
        "train_images = train_images.reshape((-1,28*28))\n",
        "test_images = test_images.reshape((-1,28*28))\n",
        "\n",
        "\n",
        "# 레이블을 원핫인코딩\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "# Sequential 모델 정의\n",
        "model_sequential = Sequential([\n",
        "    # Flatten(input_shape=(28,28)),#입력\n",
        "    Dense(512, activation='relu'), # 첫번째 Dense 계층\n",
        "    # Dense(512, activation='relu', input_shape=(28*28,))\n",
        "    Dense(256, activation='relu'), # 두번째 Dense 계층\n",
        "    Dense(10, activation='softmax') #출력\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model_sequential.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습\n",
        "model_sequential.fit(train_images, train_labels, epochs=10, batch_size=64)\n",
        "\n",
        "\n",
        "# 모델 평가\n",
        "test_loss, test_acc = model_sequential.evaluate(test_images, test_labels)\n",
        "print('\\nTest accuracy (Sequential):', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCjk5Uwylpbv",
        "outputId": "3f000649-7222-4ee6-9324-b4d83bfeb5f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 1us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 2s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 1s 0us/step\n",
            "Epoch 1/10\n",
            "938/938 [==============================] - 5s 3ms/step - loss: 0.4730 - accuracy: 0.8298\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.3538 - accuracy: 0.8701\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.3172 - accuracy: 0.8825\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.2945 - accuracy: 0.8904\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.2775 - accuracy: 0.8956\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.2615 - accuracy: 0.9021\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.2480 - accuracy: 0.9062\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.2355 - accuracy: 0.9120\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.2264 - accuracy: 0.9138\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.2150 - accuracy: 0.9175\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3195 - accuracy: 0.8942\n",
            "\n",
            "Test accuracy (Sequential): 0.8942000269889832\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##함수형 API\n",
        "\n",
        "Keras 내장 데이터셋인 Fashion MNIST를 사용하여 분류 모델을 학습하고 평가하세요.\n",
        "- Fashion MNIST는 기존의 MNIST 데이터셋과 같은 형식을 가지고 있지만, 손으로 쓴 숫자 대신에 10가지 범주의 패션 아이템(예: 티셔츠, 바지, 신발 등)의 이미지로 구성\n",
        "- 입력층, 두 개의 은닉층, 그리고 Softmax 활성화 함수를 사용하는 출력층으로 구성\n",
        "- 모델은 Adam 최적화 알고리즘과 categorical_crossentropy 손실 함수를 사용하여 컴파일\n",
        "- 학습 과정에서 정확도를 평가 지표로 사용"
      ],
      "metadata": {
        "id": "87vGb_Eo-p2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Fashion MNIST 데이터셋 로드\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# 데이터 전처리\n",
        "# 이미지를 0~1 범위로 스케일링\n",
        "train_images = train_images.reshape((60000, 28 * 28)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28)).astype('float32') / 255\n",
        "\n",
        "# 레이블을 원-핫 인코딩\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "# 입력 데이터의 차원\n",
        "input_shape = (784,)\n",
        "# 입력층 정의\n",
        "input_layer = Input(shape=input_shape, name='input_layer')\n",
        "\n",
        "# 완전연결 층 추가\n",
        "hidden1 = Dense(512, activation='relu', name='hidden_layer_1')(input_layer)\n",
        "hidden2 = Dense(256, activation='relu', name='hidden_layer_2')(hidden1)\n",
        "\n",
        "# 출력층 추가\n",
        "output_layer = Dense(10, activation='softmax', name='output_layer')(hidden2)\n",
        "\n",
        "# 모델 정의\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 모델 요약 출력\n",
        "model.summary()\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(train_images, train_labels, epochs=10, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# 모델 평가\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('\\n테스트 손실:', test_loss)\n",
        "print('테스트 정확도:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMvfTWKW_A2u",
        "outputId": "ce5905b7-749a-4888-ed80-34a3f67e8753"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_layer (InputLayer)    [(None, 784)]             0         \n",
            "                                                                 \n",
            " hidden_layer_1 (Dense)      (None, 512)               401920    \n",
            "                                                                 \n",
            " hidden_layer_2 (Dense)      (None, 256)               131328    \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 535818 (2.04 MB)\n",
            "Trainable params: 535818 (2.04 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "375/375 [==============================] - 3s 4ms/step - loss: 0.5102 - accuracy: 0.8183 - val_loss: 0.4331 - val_accuracy: 0.8394\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3616 - accuracy: 0.8686 - val_loss: 0.3906 - val_accuracy: 0.8524\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3244 - accuracy: 0.8818 - val_loss: 0.3798 - val_accuracy: 0.8555\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3032 - accuracy: 0.8866 - val_loss: 0.3213 - val_accuracy: 0.8845\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2793 - accuracy: 0.8958 - val_loss: 0.3209 - val_accuracy: 0.8828\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2678 - accuracy: 0.8994 - val_loss: 0.3380 - val_accuracy: 0.8808\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2571 - accuracy: 0.9042 - val_loss: 0.3134 - val_accuracy: 0.8880\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2410 - accuracy: 0.9092 - val_loss: 0.3245 - val_accuracy: 0.8842\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2330 - accuracy: 0.9123 - val_loss: 0.2931 - val_accuracy: 0.8974\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2192 - accuracy: 0.9163 - val_loss: 0.2939 - val_accuracy: 0.8952\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3173 - accuracy: 0.8897\n",
            "\n",
            "테스트 손실: 0.3172720968723297\n",
            "테스트 정확도: 0.8896999955177307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Q. MNIST 데이터셋에 대하여 함수형 API를 사용하여 같은 아키텍처의 신경망을 구성하세요"
      ],
      "metadata": {
        "id": "RphuLfPMEBBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# MNIST 데이터셋 로드\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# 데이터 전처리\n",
        "# 이미지를 0~1 범위로 스케일링\n",
        "train_images = train_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "# 입력 데이터의 차원을 (28,28)에서 모델에 적합한 형태로 조정\n",
        "# 입력층 정의 시 Flatten 층을 사용하여 입력 이미지를 평탄화\n",
        "input_layer = Input(shape=(28,28), name='input_layer')\n",
        "x = Flatten()(input_layer)\n",
        "\n",
        "# 완전연결 층 추가\n",
        "hidden1 = Dense(128, activation='relu', name='hidden_layer_1')(x)\n",
        "hidden2 = Dense(64, activation='relu', name='hidden_layer_2')(hidden1)\n",
        "\n",
        "# 출력층 추가\n",
        "output_layer = Dense(10, activation='softmax', name='output_layer')(hidden2)\n",
        "\n",
        "# 모델 정의\n",
        "model_functional = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# 모델 컴파일\n",
        "model_functional.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 모델 요약 출력\n",
        "model_functional.summary()\n",
        "\n",
        "# 모델 학습\n",
        "model_functional.fit(train_images, train_labels, epochs=5, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# 모델 평가\n",
        "test_loss, test_acc = model_functional.evaluate(test_images, test_labels)\n",
        "print('\\n테스트 손실 (functional):', test_loss)\n",
        "print('테스트 정확도 (functional):', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3McEc16EANf",
        "outputId": "54d319a0-9149-4fae-8a80-ceb65ad6f503"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_layer (InputLayer)    [(None, 28, 28)]          0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " hidden_layer_1 (Dense)      (None, 128)               100480    \n",
            "                                                                 \n",
            " hidden_layer_2 (Dense)      (None, 64)                8256      \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109386 (427.29 KB)\n",
            "Trainable params: 109386 (427.29 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2661 - accuracy: 0.9225 - val_loss: 0.1398 - val_accuracy: 0.9583\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1134 - accuracy: 0.9649 - val_loss: 0.1068 - val_accuracy: 0.9692\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0790 - accuracy: 0.9754 - val_loss: 0.1112 - val_accuracy: 0.9675\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0586 - accuracy: 0.9814 - val_loss: 0.0900 - val_accuracy: 0.9731\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0477 - accuracy: 0.9848 - val_loss: 0.0944 - val_accuracy: 0.9709\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0807 - accuracy: 0.9767\n",
            "\n",
            "테스트 손실 (functional): 0.0806957334280014\n",
            "테스트 정확도 (functional): 0.9767000079154968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 변형 1: 배치 크기를 1로 해서 다시 해보기\n",
        "import numpy as np\n",
        "\n",
        "# 새로운 이미지 데이터 예시 (여기서는 실제 새로운 이미지 대신 테스트 이미지 중 하나를 사용)\n",
        "# 실제 사용 시에는 새로운 이미지 데이터를 여기에 로드하고 전처리해야 합니다.\n",
        "# 예를 들어, 새로운 이미지가 하나만 있는 경우, 이미지를 (28, 28) 형태로 리사이징하고 정규화해야 합니다.\n",
        "new_image = test_images[0] # 실제로는 새로운 이미지 데이터를 사용해야 합니다.\n",
        "# [배치 크기, 이미지 높이, 이미지 너비, 채널 수]\n",
        "new_image = np.expand_dims(new_image, axis=0) # 모델 입력을 위해 배치 차원 추가. (28,28)에서 (1,28,28) <- 1이 배치 1 즉 개별 샘플로 돌리는 것\n",
        "\n",
        "# 모델을 사용하여 예측 수행\n",
        "predictions = model_functional.predict(new_image)\n",
        "\n",
        "# 예측 결과 출력\n",
        "predicted_class = np.argmax(predictions, axis=1)\n",
        "print(\"Predicted class:\", predicted_class[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9DVcvBacMkL",
        "outputId": "8252c470-54b7-40b4-d143-dcbac0b7cc7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 51ms/step\n",
            "Predicted class: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "image_data = test_images[0] # Reshape back to 2D format if necessary\n",
        "\n",
        "plt.figure(figsize=(1,1))\n",
        "plt.imshow(image_data, cmap='gray') # Display the image\n",
        "plt.axis('off') # Turn off the axis numbers/labels\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "id": "3Kd0U8Upc_QZ",
        "outputId": "fbb27507-c6c8-444e-a436-c205377824ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 100x100 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 변형 2: ConvNet 넣기\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# MNIST 데이터셋 로드 및 사전 처리\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.reshape((-1, 28, 28, 1))  # 모델에 맞게 차원 재조정\n",
        "test_images = test_images.reshape((-1, 28, 28, 1))\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0  # 정규화\n",
        "\n",
        "# 입력 레이어 정의 (이제 이미지가 (28, 28, 1)의 형태로 입력됨)\n",
        "inputs = Input(shape=(28, 28, 1))\n",
        "\n",
        "# ConvNet 레이어 추가\n",
        "x = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
        "\n",
        "# 이전에 정의된 Dense 레이어로 연결\n",
        "x = Flatten()(x)\n",
        "hidden1 = Dense(128, activation='relu')(x)\n",
        "hidden2 = Dense(64, activation='relu', name='hidden_layer2')(hidden1)\n",
        "outputs = Dense(10, activation='softmax')(hidden2)\n",
        "\n",
        "# 모델 생성\n",
        "model_functional = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# 모델 컴파일\n",
        "model_functional.compile(optimizer='adam',\n",
        "                         loss='sparse_categorical_crossentropy',\n",
        "                         metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습\n",
        "model_functional.fit(train_images, train_labels, epochs=5, batch_size=64)\n",
        "\n",
        "# 모델 평가\n",
        "test_loss, test_acc = model_functional.evaluate(test_images, test_labels)\n",
        "print('\\nTest accuracy (Functional with ConvNet):', test_acc)\n",
        "print('\\nTest loss (Functional with ConvNet):', test_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVbGrnLVUqKJ",
        "outputId": "ca0f1bfc-c152-4df9-9a90-e7981c8f4e69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "938/938 [==============================] - 8s 5ms/step - loss: 0.1825 - accuracy: 0.9432\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0502 - accuracy: 0.9845\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0362 - accuracy: 0.9883\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0272 - accuracy: 0.9910\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0227 - accuracy: 0.9926\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0350 - accuracy: 0.9890\n",
            "\n",
            "Test accuracy (Functional with ConvNet): 0.9890000224113464\n",
            "\n",
            "Test loss (Functional with ConvNet): 0.034998029470443726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### [ 선형 회귀 활성화 함수 ]\n",
        "- 선형 회귀 모델의 출력 레이어는 보통 단일 뉴런으로 구성되며 활성화 함수가 없는  형태를 취하며 이는 모델이 어떠한 범위의 값을 직접 출력할 수 있게 하기 위함이다.\n",
        "- 활성화 함수는 신경망에서 비선형성을 도입하기 위해 사용. 비선형 활성화 함수(예: ReLU, 시그모이드, 탄젠트 등)를 사용하면 신경망은 복잡한 패턴과 비선형 관계를 학습할 수 있다. 그러나 선형 회귀에서는 모델 출력이 입력 변수의 선형 조합으로 표현되어야 하므로, 비선형 활성화 함수를 사용할 필요가 없다.\n",
        "- 따라서 선형 회귀 모델의 경우, 출력 계층에 \"linear\" 활성화 함수를 명시적으로 설정하거나 (이는 입력에 대한 아무런 변환도 적용하지 않는 것과 동일), 아예 활성화 함수를 지정하지 않는 것이 일반적. Keras에서 Dense 계층을 추가할 때 activation 매개변수를 설정하지 않으면 기본적으로 \"linear\" 활성화 함수가 사용된다. 즉, 출력 뉴런의 값은 입력에 대한 선형 변환 결과이다."
      ],
      "metadata": {
        "id": "BKRiHznoU4yK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서플로/케라스에서 실행하는 선형 회귀 모델\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#텐서플로의 케라스 API에서 필요한 함수들을 불러 옵니다.\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "x = np.array([2, 4, 6, 8])\n",
        "y = np.array([81, 93, 91, 97])\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# 출력 값, 입력 변수, 분석 방법에 맞게끔 모델을 설정합니다.\n",
        "# model.add(Dense(1, input_dim=1, activation='linear'))\n",
        "model.add(Dense(1, input_dim=1))\n",
        "\n",
        "# 오차 수정을 위해 경사 하강법(sgd)을, 오차의 정도를 판단하기 위해 평균 제곱 오차(mse)를 사용합니다.\n",
        "model.compile(optimizer='sgd', loss='mse')\n",
        "\n",
        "# 오차를 최소화하는 과정을 2000번 반복합니다.\n",
        "model.fit(x, y, epochs=2000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "327hlrDpVl-D",
        "outputId": "8fff636b-eb3b-4a9e-fe5d-2a1f9ee2f1da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "1/1 [==============================] - 1s 919ms/step - loss: 7776.7837\n",
            "Epoch 2/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1976.2419\n",
            "Epoch 3/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1118.9326\n",
            "Epoch 4/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 987.6955\n",
            "Epoch 5/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 963.1346\n",
            "Epoch 6/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 954.2762\n",
            "Epoch 7/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 947.7579\n",
            "Epoch 8/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 941.6172\n",
            "Epoch 9/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 935.5655\n",
            "Epoch 10/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 929.5602\n",
            "Epoch 11/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 923.5948\n",
            "Epoch 12/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 917.6682\n",
            "Epoch 13/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 911.7800\n",
            "Epoch 14/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 905.9300\n",
            "Epoch 15/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 900.1179\n",
            "Epoch 16/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 894.3433\n",
            "Epoch 17/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 888.6060\n",
            "Epoch 18/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 882.9061\n",
            "Epoch 19/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 877.2430\n",
            "Epoch 20/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 871.6167\n",
            "Epoch 21/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 866.0266\n",
            "Epoch 22/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 860.4728\n",
            "Epoch 23/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 854.9550\n",
            "Epoch 24/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 849.4728\n",
            "Epoch 25/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 844.0263\n",
            "Epoch 26/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 838.6150\n",
            "Epoch 27/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 833.2386\n",
            "Epoch 28/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 827.8972\n",
            "Epoch 29/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 822.5902\n",
            "Epoch 30/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 817.3176\n",
            "Epoch 31/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 812.0792\n",
            "Epoch 32/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 806.8749\n",
            "Epoch 33/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 801.7040\n",
            "Epoch 34/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 796.5667\n",
            "Epoch 35/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 791.4626\n",
            "Epoch 36/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 786.3917\n",
            "Epoch 37/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 781.3535\n",
            "Epoch 38/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 776.3480\n",
            "Epoch 39/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 771.3749\n",
            "Epoch 40/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 766.4340\n",
            "Epoch 41/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 761.5250\n",
            "Epoch 42/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 756.6478\n",
            "Epoch 43/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 751.8023\n",
            "Epoch 44/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 746.9880\n",
            "Epoch 45/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 742.2051\n",
            "Epoch 46/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 737.4530\n",
            "Epoch 47/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 732.7317\n",
            "Epoch 48/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 728.0411\n",
            "Epoch 49/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 723.3807\n",
            "Epoch 50/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 718.7506\n",
            "Epoch 51/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 714.1504\n",
            "Epoch 52/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 709.5800\n",
            "Epoch 53/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 705.0392\n",
            "Epoch 54/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 700.5278\n",
            "Epoch 55/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 696.0456\n",
            "Epoch 56/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 691.5924\n",
            "Epoch 57/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 687.1681\n",
            "Epoch 58/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 682.7725\n",
            "Epoch 59/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 678.4052\n",
            "Epoch 60/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 674.0662\n",
            "Epoch 61/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 669.7555\n",
            "Epoch 62/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 665.4724\n",
            "Epoch 63/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 661.2173\n",
            "Epoch 64/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 656.9896\n",
            "Epoch 65/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 652.7893\n",
            "Epoch 66/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 648.6163\n",
            "Epoch 67/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 644.4702\n",
            "Epoch 68/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 640.3510\n",
            "Epoch 69/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 636.2584\n",
            "Epoch 70/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 632.1924\n",
            "Epoch 71/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 628.1527\n",
            "Epoch 72/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 624.1392\n",
            "Epoch 73/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 620.1516\n",
            "Epoch 74/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 616.1898\n",
            "Epoch 75/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 612.2536\n",
            "Epoch 76/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 608.3430\n",
            "Epoch 77/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 604.4579\n",
            "Epoch 78/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 600.5977\n",
            "Epoch 79/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 596.7626\n",
            "Epoch 80/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 592.9521\n",
            "Epoch 81/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 589.1666\n",
            "Epoch 82/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 585.4053\n",
            "Epoch 83/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 581.6686\n",
            "Epoch 84/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 577.9560\n",
            "Epoch 85/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 574.2676\n",
            "Epoch 86/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 570.6029\n",
            "Epoch 87/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 566.9619\n",
            "Epoch 88/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 563.3447\n",
            "Epoch 89/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 559.7507\n",
            "Epoch 90/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 556.1801\n",
            "Epoch 91/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 552.6324\n",
            "Epoch 92/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 549.1079\n",
            "Epoch 93/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 545.6062\n",
            "Epoch 94/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 542.1273\n",
            "Epoch 95/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 538.6707\n",
            "Epoch 96/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 535.2365\n",
            "Epoch 97/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 531.8246\n",
            "Epoch 98/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 528.4348\n",
            "Epoch 99/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 525.0669\n",
            "Epoch 100/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 521.7207\n",
            "Epoch 101/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 518.3964\n",
            "Epoch 102/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 515.0935\n",
            "Epoch 103/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 511.8120\n",
            "Epoch 104/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 508.5517\n",
            "Epoch 105/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 505.3127\n",
            "Epoch 106/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 502.0944\n",
            "Epoch 107/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 498.8972\n",
            "Epoch 108/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 495.7205\n",
            "Epoch 109/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 492.5645\n",
            "Epoch 110/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 489.4289\n",
            "Epoch 111/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 486.3136\n",
            "Epoch 112/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 483.2185\n",
            "Epoch 113/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 480.1433\n",
            "Epoch 114/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 477.0882\n",
            "Epoch 115/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 474.0527\n",
            "Epoch 116/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 471.0369\n",
            "Epoch 117/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 468.0407\n",
            "Epoch 118/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 465.0639\n",
            "Epoch 119/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 462.1063\n",
            "Epoch 120/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 459.1679\n",
            "Epoch 121/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 456.2485\n",
            "Epoch 122/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 453.3481\n",
            "Epoch 123/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 450.4664\n",
            "Epoch 124/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 447.6033\n",
            "Epoch 125/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 444.7589\n",
            "Epoch 126/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 441.9328\n",
            "Epoch 127/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 439.1251\n",
            "Epoch 128/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 436.3354\n",
            "Epoch 129/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 433.5638\n",
            "Epoch 130/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 430.8104\n",
            "Epoch 131/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 428.0746\n",
            "Epoch 132/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 425.3566\n",
            "Epoch 133/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 422.6561\n",
            "Epoch 134/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 419.9731\n",
            "Epoch 135/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 417.3075\n",
            "Epoch 136/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 414.6592\n",
            "Epoch 137/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 412.0279\n",
            "Epoch 138/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 409.4139\n",
            "Epoch 139/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 406.8167\n",
            "Epoch 140/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 404.2362\n",
            "Epoch 141/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 401.6725\n",
            "Epoch 142/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 399.1255\n",
            "Epoch 143/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 396.5948\n",
            "Epoch 144/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 394.0806\n",
            "Epoch 145/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 391.5827\n",
            "Epoch 146/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 389.1009\n",
            "Epoch 147/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 386.6353\n",
            "Epoch 148/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 384.1855\n",
            "Epoch 149/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 381.7517\n",
            "Epoch 150/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 379.3334\n",
            "Epoch 151/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 376.9311\n",
            "Epoch 152/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 374.5441\n",
            "Epoch 153/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 372.1728\n",
            "Epoch 154/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 369.8167\n",
            "Epoch 155/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 367.4758\n",
            "Epoch 156/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 365.1501\n",
            "Epoch 157/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 362.8394\n",
            "Epoch 158/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 360.5439\n",
            "Epoch 159/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 358.2631\n",
            "Epoch 160/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 355.9971\n",
            "Epoch 161/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 353.7457\n",
            "Epoch 162/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 351.5089\n",
            "Epoch 163/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 349.2867\n",
            "Epoch 164/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 347.0788\n",
            "Epoch 165/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 344.8853\n",
            "Epoch 166/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 342.7057\n",
            "Epoch 167/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 340.5405\n",
            "Epoch 168/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 338.3892\n",
            "Epoch 169/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 336.2519\n",
            "Epoch 170/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 334.1284\n",
            "Epoch 171/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 332.0187\n",
            "Epoch 172/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 329.9226\n",
            "Epoch 173/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 327.8401\n",
            "Epoch 174/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 325.7711\n",
            "Epoch 175/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 323.7154\n",
            "Epoch 176/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 321.6732\n",
            "Epoch 177/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 319.6439\n",
            "Epoch 178/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 317.6281\n",
            "Epoch 179/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 315.6251\n",
            "Epoch 180/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 313.6353\n",
            "Epoch 181/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 311.6582\n",
            "Epoch 182/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 309.6940\n",
            "Epoch 183/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 307.7424\n",
            "Epoch 184/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 305.8035\n",
            "Epoch 185/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 303.8772\n",
            "Epoch 186/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 301.9633\n",
            "Epoch 187/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 300.0619\n",
            "Epoch 188/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 298.1727\n",
            "Epoch 189/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 296.2957\n",
            "Epoch 190/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 294.4310\n",
            "Epoch 191/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 292.5784\n",
            "Epoch 192/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 290.7377\n",
            "Epoch 193/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 288.9088\n",
            "Epoch 194/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 287.0919\n",
            "Epoch 195/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 285.2867\n",
            "Epoch 196/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 283.4931\n",
            "Epoch 197/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 281.7112\n",
            "Epoch 198/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 279.9409\n",
            "Epoch 199/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 278.1821\n",
            "Epoch 200/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 276.4345\n",
            "Epoch 201/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 274.6984\n",
            "Epoch 202/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 272.9734\n",
            "Epoch 203/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 271.2597\n",
            "Epoch 204/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 269.5570\n",
            "Epoch 205/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 267.8654\n",
            "Epoch 206/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 266.1846\n",
            "Epoch 207/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 264.5149\n",
            "Epoch 208/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 262.8558\n",
            "Epoch 209/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 261.2076\n",
            "Epoch 210/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 259.5700\n",
            "Epoch 211/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 257.9431\n",
            "Epoch 212/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 256.3266\n",
            "Epoch 213/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 254.7206\n",
            "Epoch 214/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 253.1251\n",
            "Epoch 215/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 251.5399\n",
            "Epoch 216/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 249.9649\n",
            "Epoch 217/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 248.4001\n",
            "Epoch 218/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 246.8454\n",
            "Epoch 219/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 245.3008\n",
            "Epoch 220/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 243.7663\n",
            "Epoch 221/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 242.2416\n",
            "Epoch 222/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 240.7268\n",
            "Epoch 223/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 239.2218\n",
            "Epoch 224/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 237.7265\n",
            "Epoch 225/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 236.2411\n",
            "Epoch 226/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 234.7651\n",
            "Epoch 227/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 233.2988\n",
            "Epoch 228/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 231.8419\n",
            "Epoch 229/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 230.3944\n",
            "Epoch 230/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 228.9564\n",
            "Epoch 231/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 227.5276\n",
            "Epoch 232/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 226.1082\n",
            "Epoch 233/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 224.6978\n",
            "Epoch 234/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 223.2967\n",
            "Epoch 235/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 221.9046\n",
            "Epoch 236/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 220.5215\n",
            "Epoch 237/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 219.1474\n",
            "Epoch 238/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 217.7821\n",
            "Epoch 239/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 216.4258\n",
            "Epoch 240/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 215.0781\n",
            "Epoch 241/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 213.7392\n",
            "Epoch 242/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 212.4089\n",
            "Epoch 243/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 211.0874\n",
            "Epoch 244/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 209.7743\n",
            "Epoch 245/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 208.4698\n",
            "Epoch 246/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 207.1736\n",
            "Epoch 247/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 205.8860\n",
            "Epoch 248/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 204.6066\n",
            "Epoch 249/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 203.3356\n",
            "Epoch 250/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 202.0727\n",
            "Epoch 251/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 200.8180\n",
            "Epoch 252/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 199.5714\n",
            "Epoch 253/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 198.3330\n",
            "Epoch 254/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 197.1026\n",
            "Epoch 255/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 195.8800\n",
            "Epoch 256/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 194.6654\n",
            "Epoch 257/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 193.4587\n",
            "Epoch 258/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 192.2598\n",
            "Epoch 259/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 191.0686\n",
            "Epoch 260/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 189.8852\n",
            "Epoch 261/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 188.7094\n",
            "Epoch 262/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 187.5413\n",
            "Epoch 263/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 186.3808\n",
            "Epoch 264/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 185.2276\n",
            "Epoch 265/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 184.0820\n",
            "Epoch 266/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 182.9438\n",
            "Epoch 267/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 181.8130\n",
            "Epoch 268/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 180.6895\n",
            "Epoch 269/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 179.5733\n",
            "Epoch 270/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 178.4643\n",
            "Epoch 271/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 177.3624\n",
            "Epoch 272/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 176.2677\n",
            "Epoch 273/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 175.1803\n",
            "Epoch 274/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 174.0997\n",
            "Epoch 275/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 173.0261\n",
            "Epoch 276/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 171.9595\n",
            "Epoch 277/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 170.8998\n",
            "Epoch 278/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 169.8469\n",
            "Epoch 279/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 168.8008\n",
            "Epoch 280/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 167.7616\n",
            "Epoch 281/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 166.7291\n",
            "Epoch 282/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 165.7033\n",
            "Epoch 283/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 164.6841\n",
            "Epoch 284/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 163.6715\n",
            "Epoch 285/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 162.6655\n",
            "Epoch 286/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 161.6660\n",
            "Epoch 287/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 160.6729\n",
            "Epoch 288/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 159.6863\n",
            "Epoch 289/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 158.7060\n",
            "Epoch 290/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 157.7322\n",
            "Epoch 291/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 156.7646\n",
            "Epoch 292/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 155.8033\n",
            "Epoch 293/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 154.8482\n",
            "Epoch 294/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 153.8993\n",
            "Epoch 295/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 152.9566\n",
            "Epoch 296/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 152.0199\n",
            "Epoch 297/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 151.0893\n",
            "Epoch 298/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 150.1647\n",
            "Epoch 299/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 149.2462\n",
            "Epoch 300/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 148.3336\n",
            "Epoch 301/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 147.4268\n",
            "Epoch 302/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 146.5259\n",
            "Epoch 303/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 145.6309\n",
            "Epoch 304/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 144.7416\n",
            "Epoch 305/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 143.8582\n",
            "Epoch 306/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 142.9804\n",
            "Epoch 307/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 142.1084\n",
            "Epoch 308/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 141.2419\n",
            "Epoch 309/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 140.3811\n",
            "Epoch 310/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 139.5259\n",
            "Epoch 311/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 138.6762\n",
            "Epoch 312/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 137.8320\n",
            "Epoch 313/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 136.9933\n",
            "Epoch 314/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 136.1600\n",
            "Epoch 315/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 135.3321\n",
            "Epoch 316/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 134.5096\n",
            "Epoch 317/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 133.6924\n",
            "Epoch 318/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 132.8804\n",
            "Epoch 319/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 132.0738\n",
            "Epoch 320/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 131.2723\n",
            "Epoch 321/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 130.4761\n",
            "Epoch 322/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 129.6851\n",
            "Epoch 323/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 128.8991\n",
            "Epoch 324/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 128.1182\n",
            "Epoch 325/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 127.3424\n",
            "Epoch 326/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 126.5716\n",
            "Epoch 327/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 125.8058\n",
            "Epoch 328/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 125.0449\n",
            "Epoch 329/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 124.2889\n",
            "Epoch 330/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 123.5379\n",
            "Epoch 331/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 122.7918\n",
            "Epoch 332/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 122.0504\n",
            "Epoch 333/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 121.3139\n",
            "Epoch 334/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 120.5822\n",
            "Epoch 335/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 119.8551\n",
            "Epoch 336/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 119.1328\n",
            "Epoch 337/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 118.4151\n",
            "Epoch 338/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 117.7021\n",
            "Epoch 339/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 116.9937\n",
            "Epoch 340/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 116.2900\n",
            "Epoch 341/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 115.5907\n",
            "Epoch 342/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 114.8959\n",
            "Epoch 343/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 114.2057\n",
            "Epoch 344/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 113.5200\n",
            "Epoch 345/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 112.8387\n",
            "Epoch 346/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 112.1618\n",
            "Epoch 347/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 111.4893\n",
            "Epoch 348/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 110.8212\n",
            "Epoch 349/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 110.1573\n",
            "Epoch 350/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 109.4978\n",
            "Epoch 351/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 108.8425\n",
            "Epoch 352/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 108.1916\n",
            "Epoch 353/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 107.5447\n",
            "Epoch 354/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 106.9021\n",
            "Epoch 355/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 106.2636\n",
            "Epoch 356/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 105.6294\n",
            "Epoch 357/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 104.9992\n",
            "Epoch 358/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 104.3730\n",
            "Epoch 359/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 103.7510\n",
            "Epoch 360/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 103.1329\n",
            "Epoch 361/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 102.5189\n",
            "Epoch 362/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 101.9088\n",
            "Epoch 363/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 101.3027\n",
            "Epoch 364/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 100.7005\n",
            "Epoch 365/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 100.1022\n",
            "Epoch 366/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 99.5077\n",
            "Epoch 367/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 98.9172\n",
            "Epoch 368/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 98.3304\n",
            "Epoch 369/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 97.7475\n",
            "Epoch 370/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 97.1683\n",
            "Epoch 371/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 96.5929\n",
            "Epoch 372/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 96.0212\n",
            "Epoch 373/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 95.4532\n",
            "Epoch 374/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 94.8889\n",
            "Epoch 375/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 94.3282\n",
            "Epoch 376/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 93.7711\n",
            "Epoch 377/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 93.2177\n",
            "Epoch 378/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 92.6679\n",
            "Epoch 379/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 92.1216\n",
            "Epoch 380/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 91.5788\n",
            "Epoch 381/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 91.0396\n",
            "Epoch 382/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 90.5039\n",
            "Epoch 383/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 89.9716\n",
            "Epoch 384/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 89.4428\n",
            "Epoch 385/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 88.9174\n",
            "Epoch 386/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 88.3954\n",
            "Epoch 387/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 87.8768\n",
            "Epoch 388/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 87.3615\n",
            "Epoch 389/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 86.8496\n",
            "Epoch 390/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 86.3410\n",
            "Epoch 391/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 85.8357\n",
            "Epoch 392/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 85.3336\n",
            "Epoch 393/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 84.8348\n",
            "Epoch 394/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 84.3393\n",
            "Epoch 395/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 83.8469\n",
            "Epoch 396/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 83.3578\n",
            "Epoch 397/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 82.8718\n",
            "Epoch 398/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 82.3889\n",
            "Epoch 399/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 81.9091\n",
            "Epoch 400/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 81.4325\n",
            "Epoch 401/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 80.9590\n",
            "Epoch 402/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 80.4885\n",
            "Epoch 403/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 80.0211\n",
            "Epoch 404/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 79.5567\n",
            "Epoch 405/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 79.0953\n",
            "Epoch 406/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 78.6369\n",
            "Epoch 407/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 78.1815\n",
            "Epoch 408/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 77.7290\n",
            "Epoch 409/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 77.2794\n",
            "Epoch 410/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 76.8328\n",
            "Epoch 411/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 76.3891\n",
            "Epoch 412/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 75.9482\n",
            "Epoch 413/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 75.5102\n",
            "Epoch 414/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 75.0749\n",
            "Epoch 415/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 74.6426\n",
            "Epoch 416/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 74.2130\n",
            "Epoch 417/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 73.7862\n",
            "Epoch 418/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 73.3622\n",
            "Epoch 419/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 72.9409\n",
            "Epoch 420/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 72.5224\n",
            "Epoch 421/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 72.1065\n",
            "Epoch 422/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 71.6934\n",
            "Epoch 423/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 71.2829\n",
            "Epoch 424/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 70.8751\n",
            "Epoch 425/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 70.4699\n",
            "Epoch 426/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 70.0673\n",
            "Epoch 427/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 69.6674\n",
            "Epoch 428/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 69.2700\n",
            "Epoch 429/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 68.8752\n",
            "Epoch 430/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 68.4830\n",
            "Epoch 431/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 68.0933\n",
            "Epoch 432/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 67.7061\n",
            "Epoch 433/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 67.3215\n",
            "Epoch 434/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 66.9394\n",
            "Epoch 435/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 66.5596\n",
            "Epoch 436/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 66.1824\n",
            "Epoch 437/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 65.8076\n",
            "Epoch 438/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 65.4352\n",
            "Epoch 439/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 65.0653\n",
            "Epoch 440/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 64.6977\n",
            "Epoch 441/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 64.3326\n",
            "Epoch 442/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 63.9698\n",
            "Epoch 443/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 63.6093\n",
            "Epoch 444/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 63.2512\n",
            "Epoch 445/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 62.8954\n",
            "Epoch 446/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 62.5418\n",
            "Epoch 447/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 62.1907\n",
            "Epoch 448/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 61.8417\n",
            "Epoch 449/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 61.4950\n",
            "Epoch 450/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 61.1506\n",
            "Epoch 451/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 60.8083\n",
            "Epoch 452/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 60.4684\n",
            "Epoch 453/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 60.1306\n",
            "Epoch 454/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 59.7950\n",
            "Epoch 455/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 59.4616\n",
            "Epoch 456/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 59.1303\n",
            "Epoch 457/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 58.8012\n",
            "Epoch 458/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 58.4742\n",
            "Epoch 459/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 58.1493\n",
            "Epoch 460/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 57.8265\n",
            "Epoch 461/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 57.5058\n",
            "Epoch 462/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 57.1872\n",
            "Epoch 463/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 56.8707\n",
            "Epoch 464/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 56.5562\n",
            "Epoch 465/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 56.2437\n",
            "Epoch 466/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 55.9333\n",
            "Epoch 467/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 55.6248\n",
            "Epoch 468/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 55.3185\n",
            "Epoch 469/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 55.0140\n",
            "Epoch 470/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 54.7115\n",
            "Epoch 471/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 54.4110\n",
            "Epoch 472/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 54.1124\n",
            "Epoch 473/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 53.8158\n",
            "Epoch 474/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 53.5211\n",
            "Epoch 475/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 53.2283\n",
            "Epoch 476/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 52.9374\n",
            "Epoch 477/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 52.6483\n",
            "Epoch 478/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 52.3612\n",
            "Epoch 479/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 52.0758\n",
            "Epoch 480/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 51.7924\n",
            "Epoch 481/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 51.5108\n",
            "Epoch 482/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 51.2310\n",
            "Epoch 483/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 50.9530\n",
            "Epoch 484/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 50.6769\n",
            "Epoch 485/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 50.4024\n",
            "Epoch 486/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 50.1298\n",
            "Epoch 487/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 49.8590\n",
            "Epoch 488/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 49.5899\n",
            "Epoch 489/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 49.3225\n",
            "Epoch 490/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 49.0569\n",
            "Epoch 491/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 48.7930\n",
            "Epoch 492/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 48.5308\n",
            "Epoch 493/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 48.2703\n",
            "Epoch 494/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 48.0115\n",
            "Epoch 495/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 47.7544\n",
            "Epoch 496/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 47.4990\n",
            "Epoch 497/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 47.2451\n",
            "Epoch 498/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 46.9929\n",
            "Epoch 499/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 46.7424\n",
            "Epoch 500/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 46.4935\n",
            "Epoch 501/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 46.2462\n",
            "Epoch 502/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 46.0005\n",
            "Epoch 503/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 45.7564\n",
            "Epoch 504/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 45.5139\n",
            "Epoch 505/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 45.2729\n",
            "Epoch 506/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 45.0335\n",
            "Epoch 507/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 44.7956\n",
            "Epoch 508/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.5593\n",
            "Epoch 509/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 44.3245\n",
            "Epoch 510/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 44.0913\n",
            "Epoch 511/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 43.8595\n",
            "Epoch 512/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 43.6293\n",
            "Epoch 513/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 43.4006\n",
            "Epoch 514/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 43.1732\n",
            "Epoch 515/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 42.9474\n",
            "Epoch 516/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 42.7231\n",
            "Epoch 517/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 42.5002\n",
            "Epoch 518/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 42.2788\n",
            "Epoch 519/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 42.0587\n",
            "Epoch 520/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 41.8401\n",
            "Epoch 521/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 41.6230\n",
            "Epoch 522/2000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 41.4072\n",
            "Epoch 523/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 41.1928\n",
            "Epoch 524/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 40.9798\n",
            "Epoch 525/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 40.7682\n",
            "Epoch 526/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 40.5580\n",
            "Epoch 527/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 40.3491\n",
            "Epoch 528/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 40.1416\n",
            "Epoch 529/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 39.9354\n",
            "Epoch 530/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.7306\n",
            "Epoch 531/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.5271\n",
            "Epoch 532/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.3249\n",
            "Epoch 533/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.1240\n",
            "Epoch 534/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 38.9244\n",
            "Epoch 535/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 38.7261\n",
            "Epoch 536/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 38.5291\n",
            "Epoch 537/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 38.3334\n",
            "Epoch 538/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 38.1389\n",
            "Epoch 539/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 37.9457\n",
            "Epoch 540/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 37.7538\n",
            "Epoch 541/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 37.5630\n",
            "Epoch 542/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 37.3736\n",
            "Epoch 543/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 37.1853\n",
            "Epoch 544/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 36.9983\n",
            "Epoch 545/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 36.8125\n",
            "Epoch 546/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 36.6278\n",
            "Epoch 547/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 36.4444\n",
            "Epoch 548/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 36.2622\n",
            "Epoch 549/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 36.0811\n",
            "Epoch 550/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.9012\n",
            "Epoch 551/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.7225\n",
            "Epoch 552/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.5450\n",
            "Epoch 553/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 35.3685\n",
            "Epoch 554/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 35.1933\n",
            "Epoch 555/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 35.0191\n",
            "Epoch 556/2000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 34.8461\n",
            "Epoch 557/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 34.6743\n",
            "Epoch 558/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 34.5035\n",
            "Epoch 559/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 34.3338\n",
            "Epoch 560/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 34.1652\n",
            "Epoch 561/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 33.9977\n",
            "Epoch 562/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 33.8314\n",
            "Epoch 563/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 33.6661\n",
            "Epoch 564/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 33.5018\n",
            "Epoch 565/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 33.3386\n",
            "Epoch 566/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 33.1765\n",
            "Epoch 567/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 33.0155\n",
            "Epoch 568/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 32.8554\n",
            "Epoch 569/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 32.6964\n",
            "Epoch 570/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 32.5385\n",
            "Epoch 571/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 32.3815\n",
            "Epoch 572/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 32.2256\n",
            "Epoch 573/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 32.0707\n",
            "Epoch 574/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 31.9167\n",
            "Epoch 575/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 31.7638\n",
            "Epoch 576/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 31.6119\n",
            "Epoch 577/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 31.4609\n",
            "Epoch 578/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 31.3110\n",
            "Epoch 579/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 31.1620\n",
            "Epoch 580/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 31.0139\n",
            "Epoch 581/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 30.8669\n",
            "Epoch 582/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 30.7207\n",
            "Epoch 583/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 30.5756\n",
            "Epoch 584/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 30.4314\n",
            "Epoch 585/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 30.2880\n",
            "Epoch 586/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 30.1457\n",
            "Epoch 587/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 30.0042\n",
            "Epoch 588/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 29.8636\n",
            "Epoch 589/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 29.7240\n",
            "Epoch 590/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 29.5853\n",
            "Epoch 591/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 29.4475\n",
            "Epoch 592/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 29.3106\n",
            "Epoch 593/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 29.1745\n",
            "Epoch 594/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 29.0393\n",
            "Epoch 595/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 28.9051\n",
            "Epoch 596/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 28.7717\n",
            "Epoch 597/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 28.6391\n",
            "Epoch 598/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 28.5074\n",
            "Epoch 599/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 28.3766\n",
            "Epoch 600/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 28.2466\n",
            "Epoch 601/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 28.1174\n",
            "Epoch 602/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 27.9891\n",
            "Epoch 603/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 27.8616\n",
            "Epoch 604/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 27.7350\n",
            "Epoch 605/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 27.6092\n",
            "Epoch 606/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 27.4841\n",
            "Epoch 607/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 27.3599\n",
            "Epoch 608/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 27.2365\n",
            "Epoch 609/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 27.1139\n",
            "Epoch 610/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 26.9920\n",
            "Epoch 611/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 26.8710\n",
            "Epoch 612/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 26.7507\n",
            "Epoch 613/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 26.6313\n",
            "Epoch 614/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 26.5126\n",
            "Epoch 615/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 26.3947\n",
            "Epoch 616/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 26.2775\n",
            "Epoch 617/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 26.1611\n",
            "Epoch 618/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 26.0455\n",
            "Epoch 619/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 25.9305\n",
            "Epoch 620/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 25.8164\n",
            "Epoch 621/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 25.7030\n",
            "Epoch 622/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 25.5903\n",
            "Epoch 623/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 25.4783\n",
            "Epoch 624/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 25.3671\n",
            "Epoch 625/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 25.2566\n",
            "Epoch 626/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 25.1468\n",
            "Epoch 627/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 25.0377\n",
            "Epoch 628/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 24.9293\n",
            "Epoch 629/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 24.8216\n",
            "Epoch 630/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 24.7147\n",
            "Epoch 631/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 24.6084\n",
            "Epoch 632/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 24.5028\n",
            "Epoch 633/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 24.3979\n",
            "Epoch 634/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 24.2936\n",
            "Epoch 635/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 24.1901\n",
            "Epoch 636/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 24.0872\n",
            "Epoch 637/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 23.9850\n",
            "Epoch 638/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 23.8834\n",
            "Epoch 639/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 23.7825\n",
            "Epoch 640/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 23.6823\n",
            "Epoch 641/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 23.5827\n",
            "Epoch 642/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 23.4837\n",
            "Epoch 643/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 23.3854\n",
            "Epoch 644/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 23.2877\n",
            "Epoch 645/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 23.1907\n",
            "Epoch 646/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 23.0943\n",
            "Epoch 647/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 22.9985\n",
            "Epoch 648/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 22.9033\n",
            "Epoch 649/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 22.8087\n",
            "Epoch 650/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 22.7148\n",
            "Epoch 651/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 22.6215\n",
            "Epoch 652/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 22.5287\n",
            "Epoch 653/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 22.4366\n",
            "Epoch 654/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 22.3451\n",
            "Epoch 655/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 22.2541\n",
            "Epoch 656/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 22.1638\n",
            "Epoch 657/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 22.0740\n",
            "Epoch 658/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 21.9848\n",
            "Epoch 659/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 21.8962\n",
            "Epoch 660/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 21.8082\n",
            "Epoch 661/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 21.7207\n",
            "Epoch 662/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 21.6338\n",
            "Epoch 663/2000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 21.5474\n",
            "Epoch 664/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 21.4617\n",
            "Epoch 665/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 21.3765\n",
            "Epoch 666/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 21.2918\n",
            "Epoch 667/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 21.2077\n",
            "Epoch 668/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 21.1241\n",
            "Epoch 669/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 21.0410\n",
            "Epoch 670/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 20.9585\n",
            "Epoch 671/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 20.8766\n",
            "Epoch 672/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 20.7952\n",
            "Epoch 673/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 20.7143\n",
            "Epoch 674/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 20.6339\n",
            "Epoch 675/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 20.5540\n",
            "Epoch 676/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 20.4747\n",
            "Epoch 677/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 20.3959\n",
            "Epoch 678/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 20.3175\n",
            "Epoch 679/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 20.2397\n",
            "Epoch 680/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 20.1624\n",
            "Epoch 681/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 20.0856\n",
            "Epoch 682/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 20.0093\n",
            "Epoch 683/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 19.9335\n",
            "Epoch 684/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 19.8581\n",
            "Epoch 685/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 19.7833\n",
            "Epoch 686/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 19.7089\n",
            "Epoch 687/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 19.6351\n",
            "Epoch 688/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 19.5617\n",
            "Epoch 689/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 19.4887\n",
            "Epoch 690/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 19.4163\n",
            "Epoch 691/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 19.3443\n",
            "Epoch 692/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 19.2728\n",
            "Epoch 693/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 19.2018\n",
            "Epoch 694/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 19.1312\n",
            "Epoch 695/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 19.0610\n",
            "Epoch 696/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 18.9914\n",
            "Epoch 697/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 18.9222\n",
            "Epoch 698/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 18.8534\n",
            "Epoch 699/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 18.7850\n",
            "Epoch 700/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 18.7171\n",
            "Epoch 701/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 18.6497\n",
            "Epoch 702/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 18.5827\n",
            "Epoch 703/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 18.5161\n",
            "Epoch 704/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 18.4500\n",
            "Epoch 705/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 18.3842\n",
            "Epoch 706/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 18.3189\n",
            "Epoch 707/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 18.2541\n",
            "Epoch 708/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 18.1896\n",
            "Epoch 709/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 18.1256\n",
            "Epoch 710/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 18.0619\n",
            "Epoch 711/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 17.9987\n",
            "Epoch 712/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 17.9359\n",
            "Epoch 713/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 17.8735\n",
            "Epoch 714/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 17.8115\n",
            "Epoch 715/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 17.7499\n",
            "Epoch 716/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 17.6888\n",
            "Epoch 717/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 17.6280\n",
            "Epoch 718/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 17.5676\n",
            "Epoch 719/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 17.5076\n",
            "Epoch 720/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 17.4480\n",
            "Epoch 721/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 17.3887\n",
            "Epoch 722/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 17.3299\n",
            "Epoch 723/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 17.2714\n",
            "Epoch 724/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 17.2133\n",
            "Epoch 725/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 17.1556\n",
            "Epoch 726/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 17.0983\n",
            "Epoch 727/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 17.0413\n",
            "Epoch 728/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 16.9847\n",
            "Epoch 729/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 16.9285\n",
            "Epoch 730/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 16.8726\n",
            "Epoch 731/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 16.8171\n",
            "Epoch 732/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 16.7619\n",
            "Epoch 733/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 16.7072\n",
            "Epoch 734/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 16.6527\n",
            "Epoch 735/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 16.5986\n",
            "Epoch 736/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 16.5449\n",
            "Epoch 737/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 16.4915\n",
            "Epoch 738/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 16.4384\n",
            "Epoch 739/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 16.3858\n",
            "Epoch 740/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 16.3334\n",
            "Epoch 741/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 16.2814\n",
            "Epoch 742/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 16.2297\n",
            "Epoch 743/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 16.1783\n",
            "Epoch 744/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 16.1273\n",
            "Epoch 745/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 16.0766\n",
            "Epoch 746/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 16.0263\n",
            "Epoch 747/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 15.9763\n",
            "Epoch 748/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 15.9266\n",
            "Epoch 749/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 15.8772\n",
            "Epoch 750/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 15.8281\n",
            "Epoch 751/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 15.7794\n",
            "Epoch 752/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 15.7309\n",
            "Epoch 753/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 15.6828\n",
            "Epoch 754/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 15.6350\n",
            "Epoch 755/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 15.5875\n",
            "Epoch 756/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 15.5404\n",
            "Epoch 757/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 15.4935\n",
            "Epoch 758/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 15.4469\n",
            "Epoch 759/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 15.4006\n",
            "Epoch 760/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 15.3546\n",
            "Epoch 761/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 15.3090\n",
            "Epoch 762/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 15.2636\n",
            "Epoch 763/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 15.2185\n",
            "Epoch 764/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 15.1737\n",
            "Epoch 765/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 15.1292\n",
            "Epoch 766/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 15.0850\n",
            "Epoch 767/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 15.0410\n",
            "Epoch 768/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 14.9974\n",
            "Epoch 769/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 14.9540\n",
            "Epoch 770/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 14.9109\n",
            "Epoch 771/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 14.8681\n",
            "Epoch 772/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 14.8256\n",
            "Epoch 773/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 14.7834\n",
            "Epoch 774/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 14.7414\n",
            "Epoch 775/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 14.6997\n",
            "Epoch 776/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 14.6582\n",
            "Epoch 777/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 14.6171\n",
            "Epoch 778/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 14.5762\n",
            "Epoch 779/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 14.5355\n",
            "Epoch 780/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 14.4951\n",
            "Epoch 781/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 14.4550\n",
            "Epoch 782/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 14.4152\n",
            "Epoch 783/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 14.3756\n",
            "Epoch 784/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 14.3362\n",
            "Epoch 785/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 14.2972\n",
            "Epoch 786/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 14.2583\n",
            "Epoch 787/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 14.2197\n",
            "Epoch 788/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 14.1814\n",
            "Epoch 789/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 14.1433\n",
            "Epoch 790/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 14.1055\n",
            "Epoch 791/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 14.0679\n",
            "Epoch 792/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 14.0306\n",
            "Epoch 793/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 13.9934\n",
            "Epoch 794/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 13.9566\n",
            "Epoch 795/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 13.9200\n",
            "Epoch 796/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 13.8836\n",
            "Epoch 797/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 13.8474\n",
            "Epoch 798/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 13.8115\n",
            "Epoch 799/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 13.7758\n",
            "Epoch 800/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 13.7404\n",
            "Epoch 801/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 13.7051\n",
            "Epoch 802/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 13.6701\n",
            "Epoch 803/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 13.6354\n",
            "Epoch 804/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 13.6008\n",
            "Epoch 805/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 13.5665\n",
            "Epoch 806/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 13.5324\n",
            "Epoch 807/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 13.4985\n",
            "Epoch 808/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 13.4649\n",
            "Epoch 809/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 13.4314\n",
            "Epoch 810/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 13.3982\n",
            "Epoch 811/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 13.3652\n",
            "Epoch 812/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 13.3324\n",
            "Epoch 813/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 13.2998\n",
            "Epoch 814/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 13.2674\n",
            "Epoch 815/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 13.2353\n",
            "Epoch 816/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 13.2033\n",
            "Epoch 817/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 13.1715\n",
            "Epoch 818/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 13.1400\n",
            "Epoch 819/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 13.1087\n",
            "Epoch 820/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 13.0775\n",
            "Epoch 821/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 13.0466\n",
            "Epoch 822/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 13.0159\n",
            "Epoch 823/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.9853\n",
            "Epoch 824/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.9550\n",
            "Epoch 825/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 12.9249\n",
            "Epoch 826/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 12.8949\n",
            "Epoch 827/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.8651\n",
            "Epoch 828/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.8356\n",
            "Epoch 829/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 12.8062\n",
            "Epoch 830/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 12.7771\n",
            "Epoch 831/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.7480\n",
            "Epoch 832/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.7192\n",
            "Epoch 833/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 12.6906\n",
            "Epoch 834/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 12.6622\n",
            "Epoch 835/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 12.6340\n",
            "Epoch 836/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.6059\n",
            "Epoch 837/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.5781\n",
            "Epoch 838/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 12.5503\n",
            "Epoch 839/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.5228\n",
            "Epoch 840/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.4955\n",
            "Epoch 841/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 12.4683\n",
            "Epoch 842/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 12.4414\n",
            "Epoch 843/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.4145\n",
            "Epoch 844/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.3879\n",
            "Epoch 845/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.3614\n",
            "Epoch 846/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 12.3351\n",
            "Epoch 847/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 12.3090\n",
            "Epoch 848/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.2830\n",
            "Epoch 849/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.2572\n",
            "Epoch 850/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.2316\n",
            "Epoch 851/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 12.2062\n",
            "Epoch 852/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.1808\n",
            "Epoch 853/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.1557\n",
            "Epoch 854/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.1308\n",
            "Epoch 855/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 12.1059\n",
            "Epoch 856/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.0813\n",
            "Epoch 857/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.0568\n",
            "Epoch 858/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.0325\n",
            "Epoch 859/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.0084\n",
            "Epoch 860/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11.9843\n",
            "Epoch 861/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.9605\n",
            "Epoch 862/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.9368\n",
            "Epoch 863/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.9132\n",
            "Epoch 864/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 11.8898\n",
            "Epoch 865/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.8666\n",
            "Epoch 866/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.8435\n",
            "Epoch 867/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.8205\n",
            "Epoch 868/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 11.7977\n",
            "Epoch 869/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.7751\n",
            "Epoch 870/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.7526\n",
            "Epoch 871/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.7302\n",
            "Epoch 872/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.7080\n",
            "Epoch 873/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.6860\n",
            "Epoch 874/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 11.6640\n",
            "Epoch 875/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.6422\n",
            "Epoch 876/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.6206\n",
            "Epoch 877/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.5991\n",
            "Epoch 878/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11.5778\n",
            "Epoch 879/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.5565\n",
            "Epoch 880/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.5354\n",
            "Epoch 881/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.5145\n",
            "Epoch 882/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.4937\n",
            "Epoch 883/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.4730\n",
            "Epoch 884/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.4525\n",
            "Epoch 885/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.4321\n",
            "Epoch 886/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.4118\n",
            "Epoch 887/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.3916\n",
            "Epoch 888/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.3716\n",
            "Epoch 889/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 11.3517\n",
            "Epoch 890/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 11.3320\n",
            "Epoch 891/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.3123\n",
            "Epoch 892/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.2928\n",
            "Epoch 893/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.2734\n",
            "Epoch 894/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.2542\n",
            "Epoch 895/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.2351\n",
            "Epoch 896/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.2161\n",
            "Epoch 897/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.1972\n",
            "Epoch 898/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.1784\n",
            "Epoch 899/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.1598\n",
            "Epoch 900/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.1413\n",
            "Epoch 901/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.1229\n",
            "Epoch 902/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.1046\n",
            "Epoch 903/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 11.0864\n",
            "Epoch 904/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 11.0684\n",
            "Epoch 905/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 11.0505\n",
            "Epoch 906/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11.0326\n",
            "Epoch 907/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 11.0150\n",
            "Epoch 908/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.9974\n",
            "Epoch 909/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.9799\n",
            "Epoch 910/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.9626\n",
            "Epoch 911/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.9453\n",
            "Epoch 912/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.9282\n",
            "Epoch 913/2000\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 10.9112\n",
            "Epoch 914/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.8943\n",
            "Epoch 915/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.8775\n",
            "Epoch 916/2000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 10.8608\n",
            "Epoch 917/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.8442\n",
            "Epoch 918/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.8277\n",
            "Epoch 919/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.8114\n",
            "Epoch 920/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.7951\n",
            "Epoch 921/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.7789\n",
            "Epoch 922/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.7629\n",
            "Epoch 923/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.7469\n",
            "Epoch 924/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.7311\n",
            "Epoch 925/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.7154\n",
            "Epoch 926/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.6997\n",
            "Epoch 927/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.6842\n",
            "Epoch 928/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.6687\n",
            "Epoch 929/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.6534\n",
            "Epoch 930/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.6382\n",
            "Epoch 931/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.6230\n",
            "Epoch 932/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.6080\n",
            "Epoch 933/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.5930\n",
            "Epoch 934/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.5782\n",
            "Epoch 935/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.5635\n",
            "Epoch 936/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.5488\n",
            "Epoch 937/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.5342\n",
            "Epoch 938/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.5198\n",
            "Epoch 939/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.5054\n",
            "Epoch 940/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.4911\n",
            "Epoch 941/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.4769\n",
            "Epoch 942/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.4628\n",
            "Epoch 943/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.4488\n",
            "Epoch 944/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.4349\n",
            "Epoch 945/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.4211\n",
            "Epoch 946/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.4074\n",
            "Epoch 947/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.3937\n",
            "Epoch 948/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.3802\n",
            "Epoch 949/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.3667\n",
            "Epoch 950/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.3533\n",
            "Epoch 951/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.3400\n",
            "Epoch 952/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.3268\n",
            "Epoch 953/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.3137\n",
            "Epoch 954/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.3007\n",
            "Epoch 955/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 10.2877\n",
            "Epoch 956/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.2748\n",
            "Epoch 957/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.2620\n",
            "Epoch 958/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.2493\n",
            "Epoch 959/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.2367\n",
            "Epoch 960/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.2242\n",
            "Epoch 961/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.2117\n",
            "Epoch 962/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.1993\n",
            "Epoch 963/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.1870\n",
            "Epoch 964/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.1748\n",
            "Epoch 965/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.1627\n",
            "Epoch 966/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.1506\n",
            "Epoch 967/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.1386\n",
            "Epoch 968/2000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 10.1267\n",
            "Epoch 969/2000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 10.1149\n",
            "Epoch 970/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 10.1032\n",
            "Epoch 971/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 10.0915\n",
            "Epoch 972/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.0799\n",
            "Epoch 973/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.0684\n",
            "Epoch 974/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.0569\n",
            "Epoch 975/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.0455\n",
            "Epoch 976/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.0342\n",
            "Epoch 977/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.0230\n",
            "Epoch 978/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.0118\n",
            "Epoch 979/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.0007\n",
            "Epoch 980/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.9898\n",
            "Epoch 981/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.9788\n",
            "Epoch 982/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.9679\n",
            "Epoch 983/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.9571\n",
            "Epoch 984/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.9464\n",
            "Epoch 985/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.9357\n",
            "Epoch 986/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 9.9252\n",
            "Epoch 987/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 9.9146\n",
            "Epoch 988/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 9.9042\n",
            "Epoch 989/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.8938\n",
            "Epoch 990/2000\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 9.8835\n",
            "Epoch 991/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.8732\n",
            "Epoch 992/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.8630\n",
            "Epoch 993/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.8529\n",
            "Epoch 994/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.8428\n",
            "Epoch 995/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.8329\n",
            "Epoch 996/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.8229\n",
            "Epoch 997/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.8131\n",
            "Epoch 998/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 9.8033\n",
            "Epoch 999/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.7935\n",
            "Epoch 1000/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.7839\n",
            "Epoch 1001/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.7743\n",
            "Epoch 1002/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.7647\n",
            "Epoch 1003/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.7552\n",
            "Epoch 1004/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.7458\n",
            "Epoch 1005/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.7365\n",
            "Epoch 1006/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.7271\n",
            "Epoch 1007/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.7179\n",
            "Epoch 1008/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.7087\n",
            "Epoch 1009/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.6996\n",
            "Epoch 1010/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.6905\n",
            "Epoch 1011/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.6815\n",
            "Epoch 1012/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.6726\n",
            "Epoch 1013/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.6637\n",
            "Epoch 1014/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.6549\n",
            "Epoch 1015/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.6461\n",
            "Epoch 1016/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.6374\n",
            "Epoch 1017/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.6287\n",
            "Epoch 1018/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.6201\n",
            "Epoch 1019/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.6115\n",
            "Epoch 1020/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 9.6031\n",
            "Epoch 1021/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.5946\n",
            "Epoch 1022/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.5862\n",
            "Epoch 1023/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 9.5779\n",
            "Epoch 1024/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 9.5696\n",
            "Epoch 1025/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.5614\n",
            "Epoch 1026/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.5532\n",
            "Epoch 1027/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.5451\n",
            "Epoch 1028/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.5371\n",
            "Epoch 1029/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.5291\n",
            "Epoch 1030/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.5211\n",
            "Epoch 1031/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.5132\n",
            "Epoch 1032/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 9.5053\n",
            "Epoch 1033/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.4975\n",
            "Epoch 1034/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 9.4898\n",
            "Epoch 1035/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.4821\n",
            "Epoch 1036/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.4744\n",
            "Epoch 1037/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 9.4668\n",
            "Epoch 1038/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.4593\n",
            "Epoch 1039/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.4517\n",
            "Epoch 1040/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.4443\n",
            "Epoch 1041/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.4369\n",
            "Epoch 1042/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 9.4295\n",
            "Epoch 1043/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.4222\n",
            "Epoch 1044/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 9.4150\n",
            "Epoch 1045/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.4077\n",
            "Epoch 1046/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.4006\n",
            "Epoch 1047/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.3934\n",
            "Epoch 1048/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.3863\n",
            "Epoch 1049/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.3793\n",
            "Epoch 1050/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.3723\n",
            "Epoch 1051/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.3654\n",
            "Epoch 1052/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.3585\n",
            "Epoch 1053/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.3516\n",
            "Epoch 1054/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.3448\n",
            "Epoch 1055/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.3380\n",
            "Epoch 1056/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.3313\n",
            "Epoch 1057/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.3246\n",
            "Epoch 1058/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.3180\n",
            "Epoch 1059/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.3114\n",
            "Epoch 1060/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.3049\n",
            "Epoch 1061/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.2984\n",
            "Epoch 1062/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.2919\n",
            "Epoch 1063/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.2855\n",
            "Epoch 1064/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.2791\n",
            "Epoch 1065/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.2728\n",
            "Epoch 1066/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 9.2665\n",
            "Epoch 1067/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.2602\n",
            "Epoch 1068/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.2540\n",
            "Epoch 1069/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.2478\n",
            "Epoch 1070/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.2417\n",
            "Epoch 1071/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.2356\n",
            "Epoch 1072/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.2295\n",
            "Epoch 1073/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.2235\n",
            "Epoch 1074/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.2175\n",
            "Epoch 1075/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.2116\n",
            "Epoch 1076/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.2057\n",
            "Epoch 1077/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.1998\n",
            "Epoch 1078/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.1940\n",
            "Epoch 1079/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.1882\n",
            "Epoch 1080/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.1825\n",
            "Epoch 1081/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 9.1767\n",
            "Epoch 1082/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.1710\n",
            "Epoch 1083/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.1654\n",
            "Epoch 1084/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.1598\n",
            "Epoch 1085/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.1542\n",
            "Epoch 1086/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.1487\n",
            "Epoch 1087/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.1432\n",
            "Epoch 1088/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.1378\n",
            "Epoch 1089/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.1323\n",
            "Epoch 1090/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 9.1269\n",
            "Epoch 1091/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.1216\n",
            "Epoch 1092/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 9.1163\n",
            "Epoch 1093/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.1110\n",
            "Epoch 1094/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.1057\n",
            "Epoch 1095/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.1005\n",
            "Epoch 1096/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.0953\n",
            "Epoch 1097/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.0902\n",
            "Epoch 1098/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.0851\n",
            "Epoch 1099/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.0800\n",
            "Epoch 1100/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.0749\n",
            "Epoch 1101/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.0699\n",
            "Epoch 1102/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.0649\n",
            "Epoch 1103/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.0600\n",
            "Epoch 1104/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 9.0551\n",
            "Epoch 1105/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.0502\n",
            "Epoch 1106/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.0453\n",
            "Epoch 1107/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.0405\n",
            "Epoch 1108/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.0357\n",
            "Epoch 1109/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.0309\n",
            "Epoch 1110/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.0262\n",
            "Epoch 1111/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.0215\n",
            "Epoch 1112/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.0168\n",
            "Epoch 1113/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.0122\n",
            "Epoch 1114/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.0076\n",
            "Epoch 1115/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.0030\n",
            "Epoch 1116/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.9984\n",
            "Epoch 1117/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.9939\n",
            "Epoch 1118/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.9894\n",
            "Epoch 1119/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.9850\n",
            "Epoch 1120/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.9805\n",
            "Epoch 1121/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.9761\n",
            "Epoch 1122/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.9717\n",
            "Epoch 1123/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.9674\n",
            "Epoch 1124/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.9631\n",
            "Epoch 1125/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.9588\n",
            "Epoch 1126/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.9545\n",
            "Epoch 1127/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.9503\n",
            "Epoch 1128/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.9461\n",
            "Epoch 1129/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.9419\n",
            "Epoch 1130/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.9377\n",
            "Epoch 1131/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.9336\n",
            "Epoch 1132/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.9295\n",
            "Epoch 1133/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.9254\n",
            "Epoch 1134/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.9214\n",
            "Epoch 1135/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.9173\n",
            "Epoch 1136/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.9133\n",
            "Epoch 1137/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.9094\n",
            "Epoch 1138/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.9054\n",
            "Epoch 1139/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.9015\n",
            "Epoch 1140/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.8976\n",
            "Epoch 1141/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.8937\n",
            "Epoch 1142/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.8899\n",
            "Epoch 1143/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.8861\n",
            "Epoch 1144/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.8823\n",
            "Epoch 1145/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.8785\n",
            "Epoch 1146/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.8748\n",
            "Epoch 1147/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.8710\n",
            "Epoch 1148/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.8674\n",
            "Epoch 1149/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.8637\n",
            "Epoch 1150/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.8600\n",
            "Epoch 1151/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.8564\n",
            "Epoch 1152/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.8528\n",
            "Epoch 1153/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.8492\n",
            "Epoch 1154/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.8457\n",
            "Epoch 1155/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.8421\n",
            "Epoch 1156/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.8386\n",
            "Epoch 1157/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.8351\n",
            "Epoch 1158/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.8316\n",
            "Epoch 1159/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.8282\n",
            "Epoch 1160/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.8248\n",
            "Epoch 1161/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.8214\n",
            "Epoch 1162/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.8180\n",
            "Epoch 1163/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.8147\n",
            "Epoch 1164/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.8113\n",
            "Epoch 1165/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.8080\n",
            "Epoch 1166/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.8047\n",
            "Epoch 1167/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.8015\n",
            "Epoch 1168/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.7982\n",
            "Epoch 1169/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.7950\n",
            "Epoch 1170/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.7918\n",
            "Epoch 1171/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.7886\n",
            "Epoch 1172/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.7854\n",
            "Epoch 1173/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.7823\n",
            "Epoch 1174/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.7792\n",
            "Epoch 1175/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.7761\n",
            "Epoch 1176/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.7730\n",
            "Epoch 1177/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.7699\n",
            "Epoch 1178/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.7669\n",
            "Epoch 1179/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.7639\n",
            "Epoch 1180/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.7609\n",
            "Epoch 1181/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.7579\n",
            "Epoch 1182/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.7549\n",
            "Epoch 1183/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.7520\n",
            "Epoch 1184/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.7490\n",
            "Epoch 1185/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.7461\n",
            "Epoch 1186/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.7432\n",
            "Epoch 1187/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.7404\n",
            "Epoch 1188/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.7375\n",
            "Epoch 1189/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.7347\n",
            "Epoch 1190/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.7319\n",
            "Epoch 1191/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.7291\n",
            "Epoch 1192/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.7263\n",
            "Epoch 1193/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.7235\n",
            "Epoch 1194/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.7208\n",
            "Epoch 1195/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.7181\n",
            "Epoch 1196/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.7154\n",
            "Epoch 1197/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.7127\n",
            "Epoch 1198/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.7100\n",
            "Epoch 1199/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.7073\n",
            "Epoch 1200/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.7047\n",
            "Epoch 1201/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.7021\n",
            "Epoch 1202/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.6995\n",
            "Epoch 1203/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.6969\n",
            "Epoch 1204/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.6943\n",
            "Epoch 1205/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.6918\n",
            "Epoch 1206/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.6892\n",
            "Epoch 1207/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.6867\n",
            "Epoch 1208/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.6842\n",
            "Epoch 1209/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 8.6817\n",
            "Epoch 1210/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.6792\n",
            "Epoch 1211/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.6768\n",
            "Epoch 1212/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.6744\n",
            "Epoch 1213/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.6719\n",
            "Epoch 1214/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 8.6695\n",
            "Epoch 1215/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.6671\n",
            "Epoch 1216/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.6648\n",
            "Epoch 1217/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.6624\n",
            "Epoch 1218/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.6600\n",
            "Epoch 1219/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.6577\n",
            "Epoch 1220/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.6554\n",
            "Epoch 1221/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.6531\n",
            "Epoch 1222/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.6508\n",
            "Epoch 1223/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.6485\n",
            "Epoch 1224/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.6463\n",
            "Epoch 1225/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.6440\n",
            "Epoch 1226/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.6418\n",
            "Epoch 1227/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.6396\n",
            "Epoch 1228/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.6374\n",
            "Epoch 1229/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.6352\n",
            "Epoch 1230/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.6330\n",
            "Epoch 1231/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.6309\n",
            "Epoch 1232/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.6287\n",
            "Epoch 1233/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.6266\n",
            "Epoch 1234/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.6245\n",
            "Epoch 1235/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.6224\n",
            "Epoch 1236/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.6203\n",
            "Epoch 1237/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.6182\n",
            "Epoch 1238/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.6162\n",
            "Epoch 1239/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.6141\n",
            "Epoch 1240/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.6121\n",
            "Epoch 1241/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.6101\n",
            "Epoch 1242/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.6080\n",
            "Epoch 1243/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.6061\n",
            "Epoch 1244/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.6041\n",
            "Epoch 1245/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.6021\n",
            "Epoch 1246/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.6001\n",
            "Epoch 1247/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.5982\n",
            "Epoch 1248/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.5963\n",
            "Epoch 1249/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.5943\n",
            "Epoch 1250/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.5925\n",
            "Epoch 1251/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.5906\n",
            "Epoch 1252/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.5887\n",
            "Epoch 1253/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.5868\n",
            "Epoch 1254/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.5849\n",
            "Epoch 1255/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.5831\n",
            "Epoch 1256/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.5813\n",
            "Epoch 1257/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.5794\n",
            "Epoch 1258/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.5776\n",
            "Epoch 1259/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.5758\n",
            "Epoch 1260/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.5741\n",
            "Epoch 1261/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.5723\n",
            "Epoch 1262/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.5705\n",
            "Epoch 1263/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.5688\n",
            "Epoch 1264/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.5670\n",
            "Epoch 1265/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.5653\n",
            "Epoch 1266/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.5636\n",
            "Epoch 1267/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.5619\n",
            "Epoch 1268/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.5602\n",
            "Epoch 1269/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.5585\n",
            "Epoch 1270/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.5568\n",
            "Epoch 1271/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.5552\n",
            "Epoch 1272/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.5535\n",
            "Epoch 1273/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.5519\n",
            "Epoch 1274/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.5502\n",
            "Epoch 1275/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.5486\n",
            "Epoch 1276/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.5470\n",
            "Epoch 1277/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.5454\n",
            "Epoch 1278/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 8.5438\n",
            "Epoch 1279/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.5422\n",
            "Epoch 1280/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.5407\n",
            "Epoch 1281/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.5391\n",
            "Epoch 1282/2000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 8.5376\n",
            "Epoch 1283/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.5360\n",
            "Epoch 1284/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.5345\n",
            "Epoch 1285/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.5330\n",
            "Epoch 1286/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.5315\n",
            "Epoch 1287/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.5300\n",
            "Epoch 1288/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.5285\n",
            "Epoch 1289/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.5270\n",
            "Epoch 1290/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.5255\n",
            "Epoch 1291/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.5241\n",
            "Epoch 1292/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.5226\n",
            "Epoch 1293/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.5212\n",
            "Epoch 1294/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.5197\n",
            "Epoch 1295/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.5183\n",
            "Epoch 1296/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.5169\n",
            "Epoch 1297/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.5155\n",
            "Epoch 1298/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.5141\n",
            "Epoch 1299/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.5127\n",
            "Epoch 1300/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.5113\n",
            "Epoch 1301/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.5100\n",
            "Epoch 1302/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.5086\n",
            "Epoch 1303/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.5073\n",
            "Epoch 1304/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.5059\n",
            "Epoch 1305/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.5046\n",
            "Epoch 1306/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.5033\n",
            "Epoch 1307/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.5020\n",
            "Epoch 1308/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.5006\n",
            "Epoch 1309/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.4993\n",
            "Epoch 1310/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.4981\n",
            "Epoch 1311/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.4968\n",
            "Epoch 1312/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.4955\n",
            "Epoch 1313/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.4942\n",
            "Epoch 1314/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.4930\n",
            "Epoch 1315/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.4917\n",
            "Epoch 1316/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.4905\n",
            "Epoch 1317/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.4893\n",
            "Epoch 1318/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.4880\n",
            "Epoch 1319/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.4868\n",
            "Epoch 1320/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.4856\n",
            "Epoch 1321/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.4844\n",
            "Epoch 1322/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.4832\n",
            "Epoch 1323/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.4820\n",
            "Epoch 1324/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.4809\n",
            "Epoch 1325/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.4797\n",
            "Epoch 1326/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.4785\n",
            "Epoch 1327/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.4774\n",
            "Epoch 1328/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 8.4762\n",
            "Epoch 1329/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.4751\n",
            "Epoch 1330/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.4739\n",
            "Epoch 1331/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.4728\n",
            "Epoch 1332/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.4717\n",
            "Epoch 1333/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.4706\n",
            "Epoch 1334/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.4695\n",
            "Epoch 1335/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.4684\n",
            "Epoch 1336/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.4673\n",
            "Epoch 1337/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.4662\n",
            "Epoch 1338/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.4651\n",
            "Epoch 1339/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.4640\n",
            "Epoch 1340/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.4630\n",
            "Epoch 1341/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.4619\n",
            "Epoch 1342/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.4609\n",
            "Epoch 1343/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.4598\n",
            "Epoch 1344/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.4588\n",
            "Epoch 1345/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.4578\n",
            "Epoch 1346/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.4568\n",
            "Epoch 1347/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.4557\n",
            "Epoch 1348/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.4547\n",
            "Epoch 1349/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.4537\n",
            "Epoch 1350/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.4527\n",
            "Epoch 1351/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.4518\n",
            "Epoch 1352/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.4508\n",
            "Epoch 1353/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.4498\n",
            "Epoch 1354/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.4488\n",
            "Epoch 1355/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.4479\n",
            "Epoch 1356/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.4469\n",
            "Epoch 1357/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.4459\n",
            "Epoch 1358/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.4450\n",
            "Epoch 1359/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.4441\n",
            "Epoch 1360/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.4431\n",
            "Epoch 1361/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.4422\n",
            "Epoch 1362/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.4413\n",
            "Epoch 1363/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.4404\n",
            "Epoch 1364/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.4395\n",
            "Epoch 1365/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.4386\n",
            "Epoch 1366/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.4377\n",
            "Epoch 1367/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.4368\n",
            "Epoch 1368/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.4359\n",
            "Epoch 1369/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.4350\n",
            "Epoch 1370/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.4341\n",
            "Epoch 1371/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.4333\n",
            "Epoch 1372/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.4324\n",
            "Epoch 1373/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.4315\n",
            "Epoch 1374/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.4307\n",
            "Epoch 1375/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.4298\n",
            "Epoch 1376/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.4290\n",
            "Epoch 1377/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 8.4282\n",
            "Epoch 1378/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.4273\n",
            "Epoch 1379/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.4265\n",
            "Epoch 1380/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.4257\n",
            "Epoch 1381/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.4249\n",
            "Epoch 1382/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.4241\n",
            "Epoch 1383/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.4233\n",
            "Epoch 1384/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.4225\n",
            "Epoch 1385/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.4217\n",
            "Epoch 1386/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.4209\n",
            "Epoch 1387/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.4201\n",
            "Epoch 1388/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.4193\n",
            "Epoch 1389/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.4186\n",
            "Epoch 1390/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.4178\n",
            "Epoch 1391/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.4170\n",
            "Epoch 1392/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.4163\n",
            "Epoch 1393/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.4155\n",
            "Epoch 1394/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.4148\n",
            "Epoch 1395/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.4140\n",
            "Epoch 1396/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.4133\n",
            "Epoch 1397/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.4125\n",
            "Epoch 1398/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.4118\n",
            "Epoch 1399/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.4111\n",
            "Epoch 1400/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.4104\n",
            "Epoch 1401/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.4097\n",
            "Epoch 1402/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.4090\n",
            "Epoch 1403/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.4083\n",
            "Epoch 1404/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.4075\n",
            "Epoch 1405/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.4069\n",
            "Epoch 1406/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.4062\n",
            "Epoch 1407/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.4055\n",
            "Epoch 1408/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.4048\n",
            "Epoch 1409/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.4041\n",
            "Epoch 1410/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.4034\n",
            "Epoch 1411/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.4028\n",
            "Epoch 1412/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.4021\n",
            "Epoch 1413/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.4014\n",
            "Epoch 1414/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.4008\n",
            "Epoch 1415/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.4001\n",
            "Epoch 1416/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3995\n",
            "Epoch 1417/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3988\n",
            "Epoch 1418/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3982\n",
            "Epoch 1419/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3976\n",
            "Epoch 1420/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3969\n",
            "Epoch 1421/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3963\n",
            "Epoch 1422/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3957\n",
            "Epoch 1423/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3951\n",
            "Epoch 1424/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3944\n",
            "Epoch 1425/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3938\n",
            "Epoch 1426/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3932\n",
            "Epoch 1427/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3926\n",
            "Epoch 1428/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3920\n",
            "Epoch 1429/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3914\n",
            "Epoch 1430/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3908\n",
            "Epoch 1431/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.3902\n",
            "Epoch 1432/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3897\n",
            "Epoch 1433/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3891\n",
            "Epoch 1434/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3885\n",
            "Epoch 1435/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3879\n",
            "Epoch 1436/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.3874\n",
            "Epoch 1437/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3868\n",
            "Epoch 1438/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3862\n",
            "Epoch 1439/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3857\n",
            "Epoch 1440/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3851\n",
            "Epoch 1441/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.3846\n",
            "Epoch 1442/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3840\n",
            "Epoch 1443/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3835\n",
            "Epoch 1444/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3829\n",
            "Epoch 1445/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3824\n",
            "Epoch 1446/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3819\n",
            "Epoch 1447/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3813\n",
            "Epoch 1448/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3808\n",
            "Epoch 1449/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3803\n",
            "Epoch 1450/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.3798\n",
            "Epoch 1451/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3792\n",
            "Epoch 1452/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3787\n",
            "Epoch 1453/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3782\n",
            "Epoch 1454/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3777\n",
            "Epoch 1455/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3772\n",
            "Epoch 1456/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3767\n",
            "Epoch 1457/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3762\n",
            "Epoch 1458/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3757\n",
            "Epoch 1459/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3752\n",
            "Epoch 1460/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3747\n",
            "Epoch 1461/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3743\n",
            "Epoch 1462/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3738\n",
            "Epoch 1463/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3733\n",
            "Epoch 1464/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3728\n",
            "Epoch 1465/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3724\n",
            "Epoch 1466/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3719\n",
            "Epoch 1467/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3714\n",
            "Epoch 1468/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3710\n",
            "Epoch 1469/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3705\n",
            "Epoch 1470/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3701\n",
            "Epoch 1471/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3696\n",
            "Epoch 1472/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.3691\n",
            "Epoch 1473/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3687\n",
            "Epoch 1474/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3682\n",
            "Epoch 1475/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.3678\n",
            "Epoch 1476/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3674\n",
            "Epoch 1477/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3669\n",
            "Epoch 1478/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3665\n",
            "Epoch 1479/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3661\n",
            "Epoch 1480/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3656\n",
            "Epoch 1481/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3652\n",
            "Epoch 1482/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3648\n",
            "Epoch 1483/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3644\n",
            "Epoch 1484/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3640\n",
            "Epoch 1485/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3635\n",
            "Epoch 1486/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3631\n",
            "Epoch 1487/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3627\n",
            "Epoch 1488/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3623\n",
            "Epoch 1489/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3619\n",
            "Epoch 1490/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3615\n",
            "Epoch 1491/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3611\n",
            "Epoch 1492/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3607\n",
            "Epoch 1493/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3603\n",
            "Epoch 1494/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3599\n",
            "Epoch 1495/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3595\n",
            "Epoch 1496/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3591\n",
            "Epoch 1497/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3588\n",
            "Epoch 1498/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3584\n",
            "Epoch 1499/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3580\n",
            "Epoch 1500/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3576\n",
            "Epoch 1501/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3573\n",
            "Epoch 1502/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3569\n",
            "Epoch 1503/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3565\n",
            "Epoch 1504/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3562\n",
            "Epoch 1505/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3558\n",
            "Epoch 1506/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3554\n",
            "Epoch 1507/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3551\n",
            "Epoch 1508/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3547\n",
            "Epoch 1509/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.3544\n",
            "Epoch 1510/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3540\n",
            "Epoch 1511/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3537\n",
            "Epoch 1512/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3533\n",
            "Epoch 1513/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3530\n",
            "Epoch 1514/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3526\n",
            "Epoch 1515/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3523\n",
            "Epoch 1516/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3519\n",
            "Epoch 1517/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3516\n",
            "Epoch 1518/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3513\n",
            "Epoch 1519/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3509\n",
            "Epoch 1520/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.3506\n",
            "Epoch 1521/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.3503\n",
            "Epoch 1522/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3500\n",
            "Epoch 1523/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3496\n",
            "Epoch 1524/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3493\n",
            "Epoch 1525/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3490\n",
            "Epoch 1526/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3487\n",
            "Epoch 1527/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3484\n",
            "Epoch 1528/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.3481\n",
            "Epoch 1529/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3477\n",
            "Epoch 1530/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3474\n",
            "Epoch 1531/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3471\n",
            "Epoch 1532/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3468\n",
            "Epoch 1533/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3465\n",
            "Epoch 1534/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3462\n",
            "Epoch 1535/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3459\n",
            "Epoch 1536/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3456\n",
            "Epoch 1537/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3453\n",
            "Epoch 1538/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3450\n",
            "Epoch 1539/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3447\n",
            "Epoch 1540/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3444\n",
            "Epoch 1541/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3442\n",
            "Epoch 1542/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3439\n",
            "Epoch 1543/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3436\n",
            "Epoch 1544/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3433\n",
            "Epoch 1545/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3430\n",
            "Epoch 1546/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3427\n",
            "Epoch 1547/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3425\n",
            "Epoch 1548/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3422\n",
            "Epoch 1549/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3419\n",
            "Epoch 1550/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3417\n",
            "Epoch 1551/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3414\n",
            "Epoch 1552/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3411\n",
            "Epoch 1553/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3408\n",
            "Epoch 1554/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3406\n",
            "Epoch 1555/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3403\n",
            "Epoch 1556/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3401\n",
            "Epoch 1557/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3398\n",
            "Epoch 1558/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3395\n",
            "Epoch 1559/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3393\n",
            "Epoch 1560/2000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 8.3390\n",
            "Epoch 1561/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.3388\n",
            "Epoch 1562/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3385\n",
            "Epoch 1563/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3383\n",
            "Epoch 1564/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3380\n",
            "Epoch 1565/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3378\n",
            "Epoch 1566/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3375\n",
            "Epoch 1567/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3373\n",
            "Epoch 1568/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3370\n",
            "Epoch 1569/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3368\n",
            "Epoch 1570/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3366\n",
            "Epoch 1571/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3364\n",
            "Epoch 1572/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3361\n",
            "Epoch 1573/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3359\n",
            "Epoch 1574/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3356\n",
            "Epoch 1575/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3354\n",
            "Epoch 1576/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3352\n",
            "Epoch 1577/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3350\n",
            "Epoch 1578/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3347\n",
            "Epoch 1579/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3345\n",
            "Epoch 1580/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.3343\n",
            "Epoch 1581/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3341\n",
            "Epoch 1582/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3338\n",
            "Epoch 1583/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.3336\n",
            "Epoch 1584/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3334\n",
            "Epoch 1585/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3332\n",
            "Epoch 1586/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3330\n",
            "Epoch 1587/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3328\n",
            "Epoch 1588/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3326\n",
            "Epoch 1589/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.3323\n",
            "Epoch 1590/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3321\n",
            "Epoch 1591/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.3319\n",
            "Epoch 1592/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.3317\n",
            "Epoch 1593/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3315\n",
            "Epoch 1594/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.3313\n",
            "Epoch 1595/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3311\n",
            "Epoch 1596/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3309\n",
            "Epoch 1597/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3307\n",
            "Epoch 1598/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3305\n",
            "Epoch 1599/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3303\n",
            "Epoch 1600/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.3301\n",
            "Epoch 1601/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3299\n",
            "Epoch 1602/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.3297\n",
            "Epoch 1603/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3295\n",
            "Epoch 1604/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.3293\n",
            "Epoch 1605/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3291\n",
            "Epoch 1606/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.3290\n",
            "Epoch 1607/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3288\n",
            "Epoch 1608/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3286\n",
            "Epoch 1609/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3284\n",
            "Epoch 1610/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3282\n",
            "Epoch 1611/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3280\n",
            "Epoch 1612/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3278\n",
            "Epoch 1613/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3277\n",
            "Epoch 1614/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3275\n",
            "Epoch 1615/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3273\n",
            "Epoch 1616/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3271\n",
            "Epoch 1617/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3270\n",
            "Epoch 1618/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3268\n",
            "Epoch 1619/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3266\n",
            "Epoch 1620/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3264\n",
            "Epoch 1621/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3263\n",
            "Epoch 1622/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3261\n",
            "Epoch 1623/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3259\n",
            "Epoch 1624/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3258\n",
            "Epoch 1625/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3256\n",
            "Epoch 1626/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3254\n",
            "Epoch 1627/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3252\n",
            "Epoch 1628/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3251\n",
            "Epoch 1629/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3249\n",
            "Epoch 1630/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3248\n",
            "Epoch 1631/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3246\n",
            "Epoch 1632/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3245\n",
            "Epoch 1633/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3243\n",
            "Epoch 1634/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3241\n",
            "Epoch 1635/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3240\n",
            "Epoch 1636/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3238\n",
            "Epoch 1637/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3237\n",
            "Epoch 1638/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3235\n",
            "Epoch 1639/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3234\n",
            "Epoch 1640/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3232\n",
            "Epoch 1641/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3231\n",
            "Epoch 1642/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3229\n",
            "Epoch 1643/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3228\n",
            "Epoch 1644/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3226\n",
            "Epoch 1645/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3225\n",
            "Epoch 1646/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3223\n",
            "Epoch 1647/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3222\n",
            "Epoch 1648/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3220\n",
            "Epoch 1649/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3219\n",
            "Epoch 1650/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3218\n",
            "Epoch 1651/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3216\n",
            "Epoch 1652/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3215\n",
            "Epoch 1653/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3213\n",
            "Epoch 1654/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3212\n",
            "Epoch 1655/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3211\n",
            "Epoch 1656/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3209\n",
            "Epoch 1657/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3208\n",
            "Epoch 1658/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3206\n",
            "Epoch 1659/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3205\n",
            "Epoch 1660/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3204\n",
            "Epoch 1661/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3202\n",
            "Epoch 1662/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3201\n",
            "Epoch 1663/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3200\n",
            "Epoch 1664/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3199\n",
            "Epoch 1665/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3197\n",
            "Epoch 1666/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3196\n",
            "Epoch 1667/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3195\n",
            "Epoch 1668/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3194\n",
            "Epoch 1669/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3192\n",
            "Epoch 1670/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3191\n",
            "Epoch 1671/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3190\n",
            "Epoch 1672/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3189\n",
            "Epoch 1673/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3187\n",
            "Epoch 1674/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3186\n",
            "Epoch 1675/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3185\n",
            "Epoch 1676/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3184\n",
            "Epoch 1677/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3183\n",
            "Epoch 1678/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3181\n",
            "Epoch 1679/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3180\n",
            "Epoch 1680/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3179\n",
            "Epoch 1681/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3178\n",
            "Epoch 1682/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3177\n",
            "Epoch 1683/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3175\n",
            "Epoch 1684/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3174\n",
            "Epoch 1685/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3173\n",
            "Epoch 1686/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3172\n",
            "Epoch 1687/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3171\n",
            "Epoch 1688/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3170\n",
            "Epoch 1689/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3169\n",
            "Epoch 1690/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3168\n",
            "Epoch 1691/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3167\n",
            "Epoch 1692/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3166\n",
            "Epoch 1693/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3165\n",
            "Epoch 1694/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3163\n",
            "Epoch 1695/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3162\n",
            "Epoch 1696/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3161\n",
            "Epoch 1697/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3160\n",
            "Epoch 1698/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3159\n",
            "Epoch 1699/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3158\n",
            "Epoch 1700/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3157\n",
            "Epoch 1701/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3156\n",
            "Epoch 1702/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.3155\n",
            "Epoch 1703/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3154\n",
            "Epoch 1704/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3153\n",
            "Epoch 1705/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3152\n",
            "Epoch 1706/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3151\n",
            "Epoch 1707/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3150\n",
            "Epoch 1708/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3149\n",
            "Epoch 1709/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3148\n",
            "Epoch 1710/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3147\n",
            "Epoch 1711/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3146\n",
            "Epoch 1712/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3145\n",
            "Epoch 1713/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3144\n",
            "Epoch 1714/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3144\n",
            "Epoch 1715/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3143\n",
            "Epoch 1716/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3142\n",
            "Epoch 1717/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3141\n",
            "Epoch 1718/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3140\n",
            "Epoch 1719/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3139\n",
            "Epoch 1720/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3138\n",
            "Epoch 1721/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3137\n",
            "Epoch 1722/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3136\n",
            "Epoch 1723/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3135\n",
            "Epoch 1724/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3135\n",
            "Epoch 1725/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3134\n",
            "Epoch 1726/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3133\n",
            "Epoch 1727/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3132\n",
            "Epoch 1728/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3131\n",
            "Epoch 1729/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3130\n",
            "Epoch 1730/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3129\n",
            "Epoch 1731/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3129\n",
            "Epoch 1732/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3128\n",
            "Epoch 1733/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3127\n",
            "Epoch 1734/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3126\n",
            "Epoch 1735/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3125\n",
            "Epoch 1736/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3124\n",
            "Epoch 1737/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3124\n",
            "Epoch 1738/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3123\n",
            "Epoch 1739/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3122\n",
            "Epoch 1740/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3121\n",
            "Epoch 1741/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3120\n",
            "Epoch 1742/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3120\n",
            "Epoch 1743/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3119\n",
            "Epoch 1744/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3118\n",
            "Epoch 1745/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3117\n",
            "Epoch 1746/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3117\n",
            "Epoch 1747/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3116\n",
            "Epoch 1748/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3115\n",
            "Epoch 1749/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3114\n",
            "Epoch 1750/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3114\n",
            "Epoch 1751/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3113\n",
            "Epoch 1752/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3112\n",
            "Epoch 1753/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3111\n",
            "Epoch 1754/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3111\n",
            "Epoch 1755/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3110\n",
            "Epoch 1756/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3109\n",
            "Epoch 1757/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3109\n",
            "Epoch 1758/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3108\n",
            "Epoch 1759/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3107\n",
            "Epoch 1760/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3106\n",
            "Epoch 1761/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3106\n",
            "Epoch 1762/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3105\n",
            "Epoch 1763/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3104\n",
            "Epoch 1764/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3104\n",
            "Epoch 1765/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3103\n",
            "Epoch 1766/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3102\n",
            "Epoch 1767/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3102\n",
            "Epoch 1768/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3101\n",
            "Epoch 1769/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3100\n",
            "Epoch 1770/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3100\n",
            "Epoch 1771/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3099\n",
            "Epoch 1772/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3098\n",
            "Epoch 1773/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3098\n",
            "Epoch 1774/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3097\n",
            "Epoch 1775/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3096\n",
            "Epoch 1776/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3096\n",
            "Epoch 1777/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3095\n",
            "Epoch 1778/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3095\n",
            "Epoch 1779/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3094\n",
            "Epoch 1780/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3093\n",
            "Epoch 1781/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3093\n",
            "Epoch 1782/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3092\n",
            "Epoch 1783/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3092\n",
            "Epoch 1784/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3091\n",
            "Epoch 1785/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3090\n",
            "Epoch 1786/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3090\n",
            "Epoch 1787/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3089\n",
            "Epoch 1788/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3089\n",
            "Epoch 1789/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3088\n",
            "Epoch 1790/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3088\n",
            "Epoch 1791/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3087\n",
            "Epoch 1792/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3086\n",
            "Epoch 1793/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3086\n",
            "Epoch 1794/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3085\n",
            "Epoch 1795/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3085\n",
            "Epoch 1796/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3084\n",
            "Epoch 1797/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3084\n",
            "Epoch 1798/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3083\n",
            "Epoch 1799/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3083\n",
            "Epoch 1800/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3082\n",
            "Epoch 1801/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3082\n",
            "Epoch 1802/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3081\n",
            "Epoch 1803/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.3080\n",
            "Epoch 1804/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3080\n",
            "Epoch 1805/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3079\n",
            "Epoch 1806/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3079\n",
            "Epoch 1807/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3079\n",
            "Epoch 1808/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3078\n",
            "Epoch 1809/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3078\n",
            "Epoch 1810/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3077\n",
            "Epoch 1811/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3076\n",
            "Epoch 1812/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3076\n",
            "Epoch 1813/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3075\n",
            "Epoch 1814/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3075\n",
            "Epoch 1815/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3074\n",
            "Epoch 1816/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3074\n",
            "Epoch 1817/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3074\n",
            "Epoch 1818/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.3073\n",
            "Epoch 1819/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3073\n",
            "Epoch 1820/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3072\n",
            "Epoch 1821/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3072\n",
            "Epoch 1822/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3071\n",
            "Epoch 1823/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3071\n",
            "Epoch 1824/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3070\n",
            "Epoch 1825/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3070\n",
            "Epoch 1826/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3069\n",
            "Epoch 1827/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3069\n",
            "Epoch 1828/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3068\n",
            "Epoch 1829/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3068\n",
            "Epoch 1830/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3067\n",
            "Epoch 1831/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3067\n",
            "Epoch 1832/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3067\n",
            "Epoch 1833/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3066\n",
            "Epoch 1834/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3066\n",
            "Epoch 1835/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3065\n",
            "Epoch 1836/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3065\n",
            "Epoch 1837/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3065\n",
            "Epoch 1838/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3064\n",
            "Epoch 1839/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3064\n",
            "Epoch 1840/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3063\n",
            "Epoch 1841/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3063\n",
            "Epoch 1842/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3062\n",
            "Epoch 1843/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3062\n",
            "Epoch 1844/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3062\n",
            "Epoch 1845/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3061\n",
            "Epoch 1846/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3061\n",
            "Epoch 1847/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3060\n",
            "Epoch 1848/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3060\n",
            "Epoch 1849/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3060\n",
            "Epoch 1850/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3059\n",
            "Epoch 1851/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3059\n",
            "Epoch 1852/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3059\n",
            "Epoch 1853/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3058\n",
            "Epoch 1854/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3058\n",
            "Epoch 1855/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3057\n",
            "Epoch 1856/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.3057\n",
            "Epoch 1857/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3057\n",
            "Epoch 1858/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3056\n",
            "Epoch 1859/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3056\n",
            "Epoch 1860/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3056\n",
            "Epoch 1861/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3055\n",
            "Epoch 1862/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3055\n",
            "Epoch 1863/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3055\n",
            "Epoch 1864/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3054\n",
            "Epoch 1865/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3054\n",
            "Epoch 1866/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3054\n",
            "Epoch 1867/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3053\n",
            "Epoch 1868/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3053\n",
            "Epoch 1869/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3052\n",
            "Epoch 1870/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3052\n",
            "Epoch 1871/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3052\n",
            "Epoch 1872/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3051\n",
            "Epoch 1873/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3051\n",
            "Epoch 1874/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.3051\n",
            "Epoch 1875/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3050\n",
            "Epoch 1876/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3050\n",
            "Epoch 1877/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3050\n",
            "Epoch 1878/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3049\n",
            "Epoch 1879/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3049\n",
            "Epoch 1880/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3049\n",
            "Epoch 1881/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3048\n",
            "Epoch 1882/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3048\n",
            "Epoch 1883/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3048\n",
            "Epoch 1884/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3047\n",
            "Epoch 1885/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3047\n",
            "Epoch 1886/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3047\n",
            "Epoch 1887/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3047\n",
            "Epoch 1888/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3046\n",
            "Epoch 1889/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3046\n",
            "Epoch 1890/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3046\n",
            "Epoch 1891/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3045\n",
            "Epoch 1892/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3045\n",
            "Epoch 1893/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3045\n",
            "Epoch 1894/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3045\n",
            "Epoch 1895/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3044\n",
            "Epoch 1896/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3044\n",
            "Epoch 1897/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3044\n",
            "Epoch 1898/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3044\n",
            "Epoch 1899/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3043\n",
            "Epoch 1900/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3043\n",
            "Epoch 1901/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3042\n",
            "Epoch 1902/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3042\n",
            "Epoch 1903/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3042\n",
            "Epoch 1904/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3042\n",
            "Epoch 1905/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3041\n",
            "Epoch 1906/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3041\n",
            "Epoch 1907/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3041\n",
            "Epoch 1908/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3041\n",
            "Epoch 1909/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3040\n",
            "Epoch 1910/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3040\n",
            "Epoch 1911/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3040\n",
            "Epoch 1912/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3040\n",
            "Epoch 1913/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3039\n",
            "Epoch 1914/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3039\n",
            "Epoch 1915/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3039\n",
            "Epoch 1916/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3039\n",
            "Epoch 1917/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3038\n",
            "Epoch 1918/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3038\n",
            "Epoch 1919/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3038\n",
            "Epoch 1920/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3038\n",
            "Epoch 1921/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3037\n",
            "Epoch 1922/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3037\n",
            "Epoch 1923/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3037\n",
            "Epoch 1924/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3037\n",
            "Epoch 1925/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3036\n",
            "Epoch 1926/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3036\n",
            "Epoch 1927/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3036\n",
            "Epoch 1928/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3036\n",
            "Epoch 1929/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3035\n",
            "Epoch 1930/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3035\n",
            "Epoch 1931/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3035\n",
            "Epoch 1932/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3035\n",
            "Epoch 1933/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3035\n",
            "Epoch 1934/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3034\n",
            "Epoch 1935/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3034\n",
            "Epoch 1936/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3034\n",
            "Epoch 1937/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3034\n",
            "Epoch 1938/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3034\n",
            "Epoch 1939/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3033\n",
            "Epoch 1940/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3033\n",
            "Epoch 1941/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3033\n",
            "Epoch 1942/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3033\n",
            "Epoch 1943/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3033\n",
            "Epoch 1944/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3032\n",
            "Epoch 1945/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3032\n",
            "Epoch 1946/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3032\n",
            "Epoch 1947/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3032\n",
            "Epoch 1948/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3031\n",
            "Epoch 1949/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3031\n",
            "Epoch 1950/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3031\n",
            "Epoch 1951/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3031\n",
            "Epoch 1952/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3031\n",
            "Epoch 1953/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3030\n",
            "Epoch 1954/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3030\n",
            "Epoch 1955/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3030\n",
            "Epoch 1956/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3030\n",
            "Epoch 1957/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3030\n",
            "Epoch 1958/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3029\n",
            "Epoch 1959/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3029\n",
            "Epoch 1960/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3029\n",
            "Epoch 1961/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3029\n",
            "Epoch 1962/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3029\n",
            "Epoch 1963/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3028\n",
            "Epoch 1964/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3028\n",
            "Epoch 1965/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3028\n",
            "Epoch 1966/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3028\n",
            "Epoch 1967/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3028\n",
            "Epoch 1968/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3028\n",
            "Epoch 1969/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3027\n",
            "Epoch 1970/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3027\n",
            "Epoch 1971/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3027\n",
            "Epoch 1972/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3027\n",
            "Epoch 1973/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3027\n",
            "Epoch 1974/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3027\n",
            "Epoch 1975/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3026\n",
            "Epoch 1976/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.3026\n",
            "Epoch 1977/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3026\n",
            "Epoch 1978/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3026\n",
            "Epoch 1979/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3026\n",
            "Epoch 1980/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3026\n",
            "Epoch 1981/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3025\n",
            "Epoch 1982/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3025\n",
            "Epoch 1983/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3025\n",
            "Epoch 1984/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3025\n",
            "Epoch 1985/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3025\n",
            "Epoch 1986/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3025\n",
            "Epoch 1987/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3024\n",
            "Epoch 1988/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.3024\n",
            "Epoch 1989/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3024\n",
            "Epoch 1990/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3024\n",
            "Epoch 1991/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3024\n",
            "Epoch 1992/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3023\n",
            "Epoch 1993/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3023\n",
            "Epoch 1994/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3023\n",
            "Epoch 1995/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3023\n",
            "Epoch 1996/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3023\n",
            "Epoch 1997/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3023\n",
            "Epoch 1998/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3023\n",
            "Epoch 1999/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3023\n",
            "Epoch 2000/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3022\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7cfd6518f9a0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(x,y)\n",
        "plt.plot(x, model.predict(x),'r') # 예측 결과를 그래프로 나타냅니다.\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "JMJKPanCXKt6",
        "outputId": "9b0341e7-7c4f-4b8f-acfa-c2df30d97b59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 61ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 임의의 시간을 집어넣어 점수를 예측하는 모델을 테스트해 보겠습니다.\n",
        "\n",
        "hour = 7\n",
        "prediction = model.predict([hour])\n",
        "\n",
        "print(\"%.f시간을 공부할 경우의 예상 점수는 %.02f점입니다\" % (hour, prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nde-Fe3mX0yC",
        "outputId": "1a6fc9ce-708e-40bc-aee1-886dd3a33362"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 47ms/step\n",
            "7시간을 공부할 경우의 예상 점수는 95.12점입니다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서플로/케라스에서 실행하는 다중 선형회귀 모델\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#텐서플로의 케라스 API에서 필요한 함수들을 불러 옵니다.\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "x = np.array([[2, 0], [4, 4], [6, 2], [8, 3]])\n",
        "y = np.array([81, 93, 91, 97])\n",
        "\n",
        "# model = Sequential()\n",
        "\n",
        "# 출력 값, 입력 변수, 분석 방법에 맞게끔 모델을 설정합니다.\n",
        "# model.add(Dense(1, input_dim=2, activation='linear'))\n",
        "# model.add(Dense(1, input_dim=2))\n",
        "model = Sequential([Dense(1, input_dim=2, activation='linear')])\n",
        "\n",
        "# 오차 수정을 위해 경사 하강법(sgd)을, 오차의 정도를 판단하기 위해 평균 제곱 오차(mse)를 사용합니다.\n",
        "model.compile(optimizer='sgd', loss='mse')\n",
        "\n",
        "# 오차를 최소화하는 과정을 2000번 반복합니다.\n",
        "model.fit(x, y, epochs=2000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4YjduOVagEa",
        "outputId": "8dacdc9f-9d89-453b-c205-6f920f2fdc52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "1/1 [==============================] - 0s 448ms/step - loss: 9395.7988\n",
            "Epoch 2/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1518.4700\n",
            "Epoch 3/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 958.9648\n",
            "Epoch 4/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 914.1587\n",
            "Epoch 5/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 905.5889\n",
            "Epoch 6/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 899.6049\n",
            "Epoch 7/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 893.8395\n",
            "Epoch 8/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 888.1262\n",
            "Epoch 9/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 882.4525\n",
            "Epoch 10/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 876.8175\n",
            "Epoch 11/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 871.2203\n",
            "Epoch 12/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 865.6612\n",
            "Epoch 13/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 860.1393\n",
            "Epoch 14/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 854.6544\n",
            "Epoch 15/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 849.2063\n",
            "Epoch 16/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 843.7946\n",
            "Epoch 17/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 838.4187\n",
            "Epoch 18/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 833.0787\n",
            "Epoch 19/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 827.7739\n",
            "Epoch 20/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 822.5043\n",
            "Epoch 21/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 817.2695\n",
            "Epoch 22/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 812.0690\n",
            "Epoch 23/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 806.9029\n",
            "Epoch 24/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 801.7707\n",
            "Epoch 25/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 796.6721\n",
            "Epoch 26/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 791.6068\n",
            "Epoch 27/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 786.5746\n",
            "Epoch 28/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 781.5754\n",
            "Epoch 29/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 776.6085\n",
            "Epoch 30/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 771.6740\n",
            "Epoch 31/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 766.7717\n",
            "Epoch 32/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 761.9010\n",
            "Epoch 33/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 757.0621\n",
            "Epoch 34/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 752.2544\n",
            "Epoch 35/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 747.4779\n",
            "Epoch 36/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 742.7322\n",
            "Epoch 37/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 738.0172\n",
            "Epoch 38/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 733.3326\n",
            "Epoch 39/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 728.6782\n",
            "Epoch 40/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 724.0537\n",
            "Epoch 41/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 719.4590\n",
            "Epoch 42/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 714.8939\n",
            "Epoch 43/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 710.3582\n",
            "Epoch 44/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 705.8514\n",
            "Epoch 45/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 701.3738\n",
            "Epoch 46/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 696.9247\n",
            "Epoch 47/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 692.5042\n",
            "Epoch 48/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 688.1119\n",
            "Epoch 49/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 683.7479\n",
            "Epoch 50/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 679.4119\n",
            "Epoch 51/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 675.1036\n",
            "Epoch 52/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 670.8227\n",
            "Epoch 53/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 666.5691\n",
            "Epoch 54/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 662.3428\n",
            "Epoch 55/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 658.1436\n",
            "Epoch 56/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 653.9711\n",
            "Epoch 57/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 649.8253\n",
            "Epoch 58/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 645.7057\n",
            "Epoch 59/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 641.6125\n",
            "Epoch 60/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 637.5457\n",
            "Epoch 61/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 633.5044\n",
            "Epoch 62/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 629.4890\n",
            "Epoch 63/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 625.4991\n",
            "Epoch 64/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 621.5348\n",
            "Epoch 65/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 617.5956\n",
            "Epoch 66/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 613.6816\n",
            "Epoch 67/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 609.7923\n",
            "Epoch 68/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 605.9278\n",
            "Epoch 69/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 602.0881\n",
            "Epoch 70/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 598.2726\n",
            "Epoch 71/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 594.4814\n",
            "Epoch 72/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 590.7143\n",
            "Epoch 73/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 586.9713\n",
            "Epoch 74/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 583.2519\n",
            "Epoch 75/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 579.5562\n",
            "Epoch 76/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 575.8840\n",
            "Epoch 77/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 572.2350\n",
            "Epoch 78/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 568.6094\n",
            "Epoch 79/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 565.0067\n",
            "Epoch 80/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 561.4269\n",
            "Epoch 81/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 557.8698\n",
            "Epoch 82/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 554.3352\n",
            "Epoch 83/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 550.8232\n",
            "Epoch 84/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 547.3334\n",
            "Epoch 85/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 543.8658\n",
            "Epoch 86/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 540.4202\n",
            "Epoch 87/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 536.9965\n",
            "Epoch 88/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 533.5944\n",
            "Epoch 89/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 530.2139\n",
            "Epoch 90/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 526.8550\n",
            "Epoch 91/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 523.5173\n",
            "Epoch 92/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 520.2008\n",
            "Epoch 93/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 516.9053\n",
            "Epoch 94/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 513.6308\n",
            "Epoch 95/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 510.3769\n",
            "Epoch 96/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 507.1437\n",
            "Epoch 97/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 503.9311\n",
            "Epoch 98/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 500.7387\n",
            "Epoch 99/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 497.5667\n",
            "Epoch 100/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 494.4148\n",
            "Epoch 101/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 491.2828\n",
            "Epoch 102/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 488.1707\n",
            "Epoch 103/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 485.0783\n",
            "Epoch 104/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 482.0056\n",
            "Epoch 105/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 478.9523\n",
            "Epoch 106/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 475.9183\n",
            "Epoch 107/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 472.9037\n",
            "Epoch 108/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 469.9082\n",
            "Epoch 109/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 466.9315\n",
            "Epoch 110/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 463.9738\n",
            "Epoch 111/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 461.0349\n",
            "Epoch 112/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 458.1144\n",
            "Epoch 113/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 455.2126\n",
            "Epoch 114/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 452.3291\n",
            "Epoch 115/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 449.4640\n",
            "Epoch 116/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 446.6169\n",
            "Epoch 117/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 443.7880\n",
            "Epoch 118/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 440.9770\n",
            "Epoch 119/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 438.1837\n",
            "Epoch 120/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 435.4081\n",
            "Epoch 121/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 432.6502\n",
            "Epoch 122/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 429.9097\n",
            "Epoch 123/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 427.1867\n",
            "Epoch 124/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 424.4807\n",
            "Epoch 125/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 421.7921\n",
            "Epoch 126/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 419.1205\n",
            "Epoch 127/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 416.4657\n",
            "Epoch 128/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 413.8278\n",
            "Epoch 129/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 411.2066\n",
            "Epoch 130/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 408.6019\n",
            "Epoch 131/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 406.0140\n",
            "Epoch 132/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 403.4422\n",
            "Epoch 133/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 400.8869\n",
            "Epoch 134/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 398.3477\n",
            "Epoch 135/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 395.8246\n",
            "Epoch 136/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 393.3174\n",
            "Epoch 137/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 390.8262\n",
            "Epoch 138/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 388.3507\n",
            "Epoch 139/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 385.8910\n",
            "Epoch 140/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 383.4468\n",
            "Epoch 141/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 381.0181\n",
            "Epoch 142/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 378.6048\n",
            "Epoch 143/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 376.2067\n",
            "Epoch 144/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 373.8239\n",
            "Epoch 145/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 371.4562\n",
            "Epoch 146/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 369.1035\n",
            "Epoch 147/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 366.7656\n",
            "Epoch 148/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 364.4427\n",
            "Epoch 149/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 362.1344\n",
            "Epoch 150/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 359.8406\n",
            "Epoch 151/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 357.5615\n",
            "Epoch 152/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 355.2968\n",
            "Epoch 153/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 353.0464\n",
            "Epoch 154/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 350.8103\n",
            "Epoch 155/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 348.5884\n",
            "Epoch 156/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 346.3806\n",
            "Epoch 157/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 344.1866\n",
            "Epoch 158/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 342.0068\n",
            "Epoch 159/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 339.8406\n",
            "Epoch 160/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 337.6882\n",
            "Epoch 161/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 335.5493\n",
            "Epoch 162/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 333.4241\n",
            "Epoch 163/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 331.3122\n",
            "Epoch 164/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 329.2140\n",
            "Epoch 165/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 327.1289\n",
            "Epoch 166/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 325.0569\n",
            "Epoch 167/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 322.9981\n",
            "Epoch 168/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 320.9525\n",
            "Epoch 169/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 318.9196\n",
            "Epoch 170/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 316.8997\n",
            "Epoch 171/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 314.8926\n",
            "Epoch 172/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 312.8983\n",
            "Epoch 173/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 310.9165\n",
            "Epoch 174/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 308.9474\n",
            "Epoch 175/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 306.9906\n",
            "Epoch 176/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 305.0463\n",
            "Epoch 177/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 303.1142\n",
            "Epoch 178/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 301.1944\n",
            "Epoch 179/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 299.2867\n",
            "Epoch 180/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 297.3913\n",
            "Epoch 181/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 295.5077\n",
            "Epoch 182/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 293.6362\n",
            "Epoch 183/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 291.7765\n",
            "Epoch 184/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 289.9286\n",
            "Epoch 185/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 288.0923\n",
            "Epoch 186/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 286.2677\n",
            "Epoch 187/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 284.4547\n",
            "Epoch 188/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 282.6531\n",
            "Epoch 189/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 280.8629\n",
            "Epoch 190/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 279.0841\n",
            "Epoch 191/2000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 277.3166\n",
            "Epoch 192/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 275.5602\n",
            "Epoch 193/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 273.8150\n",
            "Epoch 194/2000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 272.0809\n",
            "Epoch 195/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 270.3577\n",
            "Epoch 196/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 268.6453\n",
            "Epoch 197/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 266.9440\n",
            "Epoch 198/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 265.2533\n",
            "Epoch 199/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 263.5735\n",
            "Epoch 200/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 261.9041\n",
            "Epoch 201/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 260.2455\n",
            "Epoch 202/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 258.5973\n",
            "Epoch 203/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 256.9595\n",
            "Epoch 204/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 255.3322\n",
            "Epoch 205/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 253.7151\n",
            "Epoch 206/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 252.1083\n",
            "Epoch 207/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 250.5116\n",
            "Epoch 208/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 248.9252\n",
            "Epoch 209/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 247.3486\n",
            "Epoch 210/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 245.7821\n",
            "Epoch 211/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 244.2255\n",
            "Epoch 212/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 242.6789\n",
            "Epoch 213/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 241.1419\n",
            "Epoch 214/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 239.6147\n",
            "Epoch 215/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 238.0973\n",
            "Epoch 216/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 236.5893\n",
            "Epoch 217/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 235.0910\n",
            "Epoch 218/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 233.6022\n",
            "Epoch 219/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 232.1227\n",
            "Epoch 220/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 230.6527\n",
            "Epoch 221/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 229.1919\n",
            "Epoch 222/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 227.7405\n",
            "Epoch 223/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 226.2982\n",
            "Epoch 224/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 224.8650\n",
            "Epoch 225/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 223.4410\n",
            "Epoch 226/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 222.0260\n",
            "Epoch 227/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 220.6199\n",
            "Epoch 228/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 219.2228\n",
            "Epoch 229/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 217.8344\n",
            "Epoch 230/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 216.4550\n",
            "Epoch 231/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 215.0841\n",
            "Epoch 232/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 213.7220\n",
            "Epoch 233/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 212.3686\n",
            "Epoch 234/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 211.0237\n",
            "Epoch 235/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 209.6873\n",
            "Epoch 236/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 208.3594\n",
            "Epoch 237/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 207.0399\n",
            "Epoch 238/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 205.7287\n",
            "Epoch 239/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 204.4260\n",
            "Epoch 240/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 203.1313\n",
            "Epoch 241/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 201.8450\n",
            "Epoch 242/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 200.5668\n",
            "Epoch 243/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 199.2967\n",
            "Epoch 244/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 198.0346\n",
            "Epoch 245/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 196.7805\n",
            "Epoch 246/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 195.5344\n",
            "Epoch 247/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 194.2961\n",
            "Epoch 248/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 193.0657\n",
            "Epoch 249/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 191.8431\n",
            "Epoch 250/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 190.6283\n",
            "Epoch 251/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 189.4211\n",
            "Epoch 252/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 188.2215\n",
            "Epoch 253/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 187.0296\n",
            "Epoch 254/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 185.8453\n",
            "Epoch 255/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 184.6684\n",
            "Epoch 256/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 183.4989\n",
            "Epoch 257/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 182.3369\n",
            "Epoch 258/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 181.1824\n",
            "Epoch 259/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 180.0350\n",
            "Epoch 260/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 178.8949\n",
            "Epoch 261/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 177.7621\n",
            "Epoch 262/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 176.6364\n",
            "Epoch 263/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 175.5179\n",
            "Epoch 264/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 174.4064\n",
            "Epoch 265/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 173.3020\n",
            "Epoch 266/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 172.2046\n",
            "Epoch 267/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 171.1142\n",
            "Epoch 268/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 170.0306\n",
            "Epoch 269/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 168.9539\n",
            "Epoch 270/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 167.8840\n",
            "Epoch 271/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 166.8209\n",
            "Epoch 272/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 165.7646\n",
            "Epoch 273/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 164.7149\n",
            "Epoch 274/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 163.6719\n",
            "Epoch 275/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 162.6355\n",
            "Epoch 276/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 161.6057\n",
            "Epoch 277/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 160.5823\n",
            "Epoch 278/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 159.5656\n",
            "Epoch 279/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 158.5551\n",
            "Epoch 280/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 157.5511\n",
            "Epoch 281/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 156.5535\n",
            "Epoch 282/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 155.5622\n",
            "Epoch 283/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 154.5772\n",
            "Epoch 284/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 153.5984\n",
            "Epoch 285/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 152.6259\n",
            "Epoch 286/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 151.6594\n",
            "Epoch 287/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 150.6991\n",
            "Epoch 288/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 149.7449\n",
            "Epoch 289/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 148.7967\n",
            "Epoch 290/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 147.8546\n",
            "Epoch 291/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 146.9184\n",
            "Epoch 292/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 145.9881\n",
            "Epoch 293/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 145.0638\n",
            "Epoch 294/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 144.1452\n",
            "Epoch 295/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 143.2325\n",
            "Epoch 296/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 142.3256\n",
            "Epoch 297/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 141.4244\n",
            "Epoch 298/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 140.5289\n",
            "Epoch 299/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 139.6391\n",
            "Epoch 300/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 138.7550\n",
            "Epoch 301/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 137.8764\n",
            "Epoch 302/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 137.0034\n",
            "Epoch 303/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 136.1359\n",
            "Epoch 304/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 135.2740\n",
            "Epoch 305/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 134.4175\n",
            "Epoch 306/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 133.5664\n",
            "Epoch 307/2000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 132.7207\n",
            "Epoch 308/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 131.8804\n",
            "Epoch 309/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 131.0453\n",
            "Epoch 310/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 130.2157\n",
            "Epoch 311/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 129.3912\n",
            "Epoch 312/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 128.5719\n",
            "Epoch 313/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 127.7579\n",
            "Epoch 314/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 126.9491\n",
            "Epoch 315/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 126.1453\n",
            "Epoch 316/2000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 125.3466\n",
            "Epoch 317/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 124.5529\n",
            "Epoch 318/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 123.7644\n",
            "Epoch 319/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 122.9808\n",
            "Epoch 320/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 122.2021\n",
            "Epoch 321/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 121.4285\n",
            "Epoch 322/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 120.6597\n",
            "Epoch 323/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 119.8957\n",
            "Epoch 324/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 119.1366\n",
            "Epoch 325/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 118.3824\n",
            "Epoch 326/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 117.6329\n",
            "Epoch 327/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 116.8881\n",
            "Epoch 328/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 116.1481\n",
            "Epoch 329/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 115.4127\n",
            "Epoch 330/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 114.6821\n",
            "Epoch 331/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 113.9560\n",
            "Epoch 332/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 113.2345\n",
            "Epoch 333/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 112.5177\n",
            "Epoch 334/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 111.8054\n",
            "Epoch 335/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 111.0975\n",
            "Epoch 336/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 110.3941\n",
            "Epoch 337/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 109.6952\n",
            "Epoch 338/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 109.0008\n",
            "Epoch 339/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 108.3107\n",
            "Epoch 340/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 107.6250\n",
            "Epoch 341/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 106.9437\n",
            "Epoch 342/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 106.2667\n",
            "Epoch 343/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 105.5940\n",
            "Epoch 344/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 104.9255\n",
            "Epoch 345/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 104.2612\n",
            "Epoch 346/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 103.6012\n",
            "Epoch 347/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 102.9453\n",
            "Epoch 348/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 102.2936\n",
            "Epoch 349/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 101.6460\n",
            "Epoch 350/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 101.0025\n",
            "Epoch 351/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 100.3631\n",
            "Epoch 352/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 99.7277\n",
            "Epoch 353/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 99.0965\n",
            "Epoch 354/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 98.4691\n",
            "Epoch 355/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 97.8457\n",
            "Epoch 356/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 97.2264\n",
            "Epoch 357/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 96.6109\n",
            "Epoch 358/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 95.9993\n",
            "Epoch 359/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 95.3916\n",
            "Epoch 360/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 94.7878\n",
            "Epoch 361/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 94.1878\n",
            "Epoch 362/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 93.5916\n",
            "Epoch 363/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 92.9991\n",
            "Epoch 364/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 92.4104\n",
            "Epoch 365/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 91.8254\n",
            "Epoch 366/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 91.2442\n",
            "Epoch 367/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 90.6666\n",
            "Epoch 368/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 90.0927\n",
            "Epoch 369/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 89.5224\n",
            "Epoch 370/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 88.9557\n",
            "Epoch 371/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 88.3927\n",
            "Epoch 372/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 87.8332\n",
            "Epoch 373/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 87.2771\n",
            "Epoch 374/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 86.7247\n",
            "Epoch 375/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 86.1758\n",
            "Epoch 376/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 85.6303\n",
            "Epoch 377/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 85.0883\n",
            "Epoch 378/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 84.5498\n",
            "Epoch 379/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 84.0146\n",
            "Epoch 380/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 83.4828\n",
            "Epoch 381/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 82.9544\n",
            "Epoch 382/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 82.4294\n",
            "Epoch 383/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 81.9076\n",
            "Epoch 384/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 81.3891\n",
            "Epoch 385/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 80.8740\n",
            "Epoch 386/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 80.3622\n",
            "Epoch 387/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 79.8535\n",
            "Epoch 388/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 79.3481\n",
            "Epoch 389/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 78.8459\n",
            "Epoch 390/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 78.3469\n",
            "Epoch 391/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 77.8510\n",
            "Epoch 392/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 77.3582\n",
            "Epoch 393/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 76.8686\n",
            "Epoch 394/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 76.3821\n",
            "Epoch 395/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 75.8987\n",
            "Epoch 396/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 75.4184\n",
            "Epoch 397/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 74.9410\n",
            "Epoch 398/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 74.4668\n",
            "Epoch 399/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 73.9955\n",
            "Epoch 400/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 73.5271\n",
            "Epoch 401/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 73.0618\n",
            "Epoch 402/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 72.5994\n",
            "Epoch 403/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 72.1400\n",
            "Epoch 404/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 71.6834\n",
            "Epoch 405/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 71.2298\n",
            "Epoch 406/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 70.7790\n",
            "Epoch 407/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 70.3310\n",
            "Epoch 408/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 69.8860\n",
            "Epoch 409/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 69.4437\n",
            "Epoch 410/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 69.0042\n",
            "Epoch 411/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 68.5675\n",
            "Epoch 412/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 68.1336\n",
            "Epoch 413/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 67.7024\n",
            "Epoch 414/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 67.2740\n",
            "Epoch 415/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 66.8483\n",
            "Epoch 416/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 66.4252\n",
            "Epoch 417/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 66.0049\n",
            "Epoch 418/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 65.5871\n",
            "Epoch 419/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 65.1721\n",
            "Epoch 420/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 64.7597\n",
            "Epoch 421/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 64.3499\n",
            "Epoch 422/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 63.9427\n",
            "Epoch 423/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 63.5381\n",
            "Epoch 424/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 63.1360\n",
            "Epoch 425/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 62.7365\n",
            "Epoch 426/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 62.3395\n",
            "Epoch 427/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 61.9450\n",
            "Epoch 428/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 61.5531\n",
            "Epoch 429/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 61.1636\n",
            "Epoch 430/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 60.7766\n",
            "Epoch 431/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 60.3920\n",
            "Epoch 432/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 60.0099\n",
            "Epoch 433/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 59.6301\n",
            "Epoch 434/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 59.2529\n",
            "Epoch 435/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 58.8779\n",
            "Epoch 436/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 58.5054\n",
            "Epoch 437/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 58.1352\n",
            "Epoch 438/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 57.7674\n",
            "Epoch 439/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 57.4019\n",
            "Epoch 440/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 57.0387\n",
            "Epoch 441/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 56.6778\n",
            "Epoch 442/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 56.3192\n",
            "Epoch 443/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 55.9629\n",
            "Epoch 444/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 55.6088\n",
            "Epoch 445/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 55.2570\n",
            "Epoch 446/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 54.9074\n",
            "Epoch 447/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 54.5600\n",
            "Epoch 448/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 54.2148\n",
            "Epoch 449/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 53.8718\n",
            "Epoch 450/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 53.5310\n",
            "Epoch 451/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 53.1924\n",
            "Epoch 452/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 52.8559\n",
            "Epoch 453/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 52.5214\n",
            "Epoch 454/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 52.1892\n",
            "Epoch 455/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 51.8590\n",
            "Epoch 456/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 51.5310\n",
            "Epoch 457/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 51.2050\n",
            "Epoch 458/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 50.8810\n",
            "Epoch 459/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 50.5592\n",
            "Epoch 460/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 50.2393\n",
            "Epoch 461/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 49.9215\n",
            "Epoch 462/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 49.6057\n",
            "Epoch 463/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 49.2919\n",
            "Epoch 464/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 48.9801\n",
            "Epoch 465/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 48.6702\n",
            "Epoch 466/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 48.3624\n",
            "Epoch 467/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 48.0564\n",
            "Epoch 468/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 47.7525\n",
            "Epoch 469/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 47.4504\n",
            "Epoch 470/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 47.1503\n",
            "Epoch 471/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 46.8520\n",
            "Epoch 472/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 46.5557\n",
            "Epoch 473/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 46.2612\n",
            "Epoch 474/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 45.9686\n",
            "Epoch 475/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 45.6778\n",
            "Epoch 476/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 45.3889\n",
            "Epoch 477/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 45.1019\n",
            "Epoch 478/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.8166\n",
            "Epoch 479/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.5331\n",
            "Epoch 480/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 44.2515\n",
            "Epoch 481/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.9716\n",
            "Epoch 482/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.6935\n",
            "Epoch 483/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.4171\n",
            "Epoch 484/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.1426\n",
            "Epoch 485/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 42.8697\n",
            "Epoch 486/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.5986\n",
            "Epoch 487/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.3292\n",
            "Epoch 488/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.0615\n",
            "Epoch 489/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 41.7955\n",
            "Epoch 490/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 41.5311\n",
            "Epoch 491/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 41.2685\n",
            "Epoch 492/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 41.0075\n",
            "Epoch 493/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.7482\n",
            "Epoch 494/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 40.4905\n",
            "Epoch 495/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 40.2345\n",
            "Epoch 496/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.9800\n",
            "Epoch 497/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 39.7272\n",
            "Epoch 498/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 39.4760\n",
            "Epoch 499/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 39.2264\n",
            "Epoch 500/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 38.9783\n",
            "Epoch 501/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 38.7318\n",
            "Epoch 502/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 38.4869\n",
            "Epoch 503/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 38.2436\n",
            "Epoch 504/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 38.0017\n",
            "Epoch 505/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 37.7614\n",
            "Epoch 506/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 37.5227\n",
            "Epoch 507/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 37.2854\n",
            "Epoch 508/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 37.0497\n",
            "Epoch 509/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 36.8154\n",
            "Epoch 510/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 36.5827\n",
            "Epoch 511/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 36.3514\n",
            "Epoch 512/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 36.1215\n",
            "Epoch 513/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 35.8932\n",
            "Epoch 514/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 35.6662\n",
            "Epoch 515/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 35.4407\n",
            "Epoch 516/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 35.2167\n",
            "Epoch 517/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 34.9940\n",
            "Epoch 518/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 34.7728\n",
            "Epoch 519/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 34.5530\n",
            "Epoch 520/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 34.3345\n",
            "Epoch 521/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 34.1175\n",
            "Epoch 522/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 33.9018\n",
            "Epoch 523/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 33.6875\n",
            "Epoch 524/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 33.4745\n",
            "Epoch 525/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 33.2629\n",
            "Epoch 526/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 33.0526\n",
            "Epoch 527/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 32.8437\n",
            "Epoch 528/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 32.6361\n",
            "Epoch 529/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 32.4298\n",
            "Epoch 530/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 32.2248\n",
            "Epoch 531/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 32.0211\n",
            "Epoch 532/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 31.8187\n",
            "Epoch 533/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 31.6176\n",
            "Epoch 534/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 31.4177\n",
            "Epoch 535/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 31.2191\n",
            "Epoch 536/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 31.0219\n",
            "Epoch 537/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 30.8258\n",
            "Epoch 538/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 30.6309\n",
            "Epoch 539/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 30.4374\n",
            "Epoch 540/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 30.2450\n",
            "Epoch 541/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 30.0539\n",
            "Epoch 542/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 29.8640\n",
            "Epoch 543/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 29.6752\n",
            "Epoch 544/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 29.4877\n",
            "Epoch 545/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 29.3013\n",
            "Epoch 546/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 29.1162\n",
            "Epoch 547/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 28.9322\n",
            "Epoch 548/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 28.7493\n",
            "Epoch 549/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 28.5676\n",
            "Epoch 550/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 28.3871\n",
            "Epoch 551/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 28.2077\n",
            "Epoch 552/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 28.0295\n",
            "Epoch 553/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 27.8524\n",
            "Epoch 554/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 27.6764\n",
            "Epoch 555/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 27.5015\n",
            "Epoch 556/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 27.3278\n",
            "Epoch 557/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 27.1551\n",
            "Epoch 558/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 26.9835\n",
            "Epoch 559/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 26.8131\n",
            "Epoch 560/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 26.6437\n",
            "Epoch 561/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 26.4753\n",
            "Epoch 562/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 26.3081\n",
            "Epoch 563/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 26.1418\n",
            "Epoch 564/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 25.9767\n",
            "Epoch 565/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 25.8126\n",
            "Epoch 566/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 25.6495\n",
            "Epoch 567/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 25.4875\n",
            "Epoch 568/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 25.3265\n",
            "Epoch 569/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 25.1665\n",
            "Epoch 570/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 25.0075\n",
            "Epoch 571/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 24.8495\n",
            "Epoch 572/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 24.6926\n",
            "Epoch 573/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 24.5366\n",
            "Epoch 574/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 24.3816\n",
            "Epoch 575/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 24.2276\n",
            "Epoch 576/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 24.0745\n",
            "Epoch 577/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 23.9225\n",
            "Epoch 578/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 23.7714\n",
            "Epoch 579/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 23.6213\n",
            "Epoch 580/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 23.4721\n",
            "Epoch 581/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 23.3238\n",
            "Epoch 582/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 23.1765\n",
            "Epoch 583/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 23.0301\n",
            "Epoch 584/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 22.8847\n",
            "Epoch 585/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 22.7402\n",
            "Epoch 586/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 22.5966\n",
            "Epoch 587/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 22.4539\n",
            "Epoch 588/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 22.3121\n",
            "Epoch 589/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 22.1712\n",
            "Epoch 590/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 22.0312\n",
            "Epoch 591/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 21.8921\n",
            "Epoch 592/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 21.7539\n",
            "Epoch 593/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 21.6165\n",
            "Epoch 594/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 21.4800\n",
            "Epoch 595/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 21.3444\n",
            "Epoch 596/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 21.2096\n",
            "Epoch 597/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 21.0757\n",
            "Epoch 598/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 20.9427\n",
            "Epoch 599/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 20.8105\n",
            "Epoch 600/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 20.6791\n",
            "Epoch 601/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 20.5486\n",
            "Epoch 602/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 20.4189\n",
            "Epoch 603/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 20.2899\n",
            "Epoch 604/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 20.1618\n",
            "Epoch 605/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 20.0346\n",
            "Epoch 606/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 19.9082\n",
            "Epoch 607/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 19.7824\n",
            "Epoch 608/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 19.6576\n",
            "Epoch 609/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 19.5335\n",
            "Epoch 610/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 19.4102\n",
            "Epoch 611/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 19.2877\n",
            "Epoch 612/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 19.1660\n",
            "Epoch 613/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 19.0450\n",
            "Epoch 614/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 18.9248\n",
            "Epoch 615/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 18.8054\n",
            "Epoch 616/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 18.6867\n",
            "Epoch 617/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 18.5688\n",
            "Epoch 618/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 18.4516\n",
            "Epoch 619/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 18.3352\n",
            "Epoch 620/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 18.2195\n",
            "Epoch 621/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 18.1045\n",
            "Epoch 622/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 17.9903\n",
            "Epoch 623/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 17.8768\n",
            "Epoch 624/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 17.7640\n",
            "Epoch 625/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 17.6519\n",
            "Epoch 626/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 17.5405\n",
            "Epoch 627/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 17.4298\n",
            "Epoch 628/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 17.3199\n",
            "Epoch 629/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 17.2106\n",
            "Epoch 630/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 17.1020\n",
            "Epoch 631/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 16.9941\n",
            "Epoch 632/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 16.8869\n",
            "Epoch 633/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 16.7804\n",
            "Epoch 634/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 16.6746\n",
            "Epoch 635/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 16.5694\n",
            "Epoch 636/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 16.4649\n",
            "Epoch 637/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 16.3610\n",
            "Epoch 638/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 16.2578\n",
            "Epoch 639/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 16.1553\n",
            "Epoch 640/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 16.0534\n",
            "Epoch 641/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 15.9522\n",
            "Epoch 642/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 15.8515\n",
            "Epoch 643/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 15.7516\n",
            "Epoch 644/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 15.6523\n",
            "Epoch 645/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 15.5536\n",
            "Epoch 646/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 15.4555\n",
            "Epoch 647/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 15.3580\n",
            "Epoch 648/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 15.2612\n",
            "Epoch 649/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 15.1650\n",
            "Epoch 650/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 15.0693\n",
            "Epoch 651/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 14.9743\n",
            "Epoch 652/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 14.8799\n",
            "Epoch 653/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 14.7861\n",
            "Epoch 654/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 14.6929\n",
            "Epoch 655/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 14.6003\n",
            "Epoch 656/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 14.5082\n",
            "Epoch 657/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 14.4168\n",
            "Epoch 658/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 14.3259\n",
            "Epoch 659/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 14.2356\n",
            "Epoch 660/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 14.1459\n",
            "Epoch 661/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 14.0567\n",
            "Epoch 662/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 13.9681\n",
            "Epoch 663/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 13.8800\n",
            "Epoch 664/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 13.7926\n",
            "Epoch 665/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 13.7057\n",
            "Epoch 666/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 13.6193\n",
            "Epoch 667/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 13.5335\n",
            "Epoch 668/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 13.4482\n",
            "Epoch 669/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 13.3634\n",
            "Epoch 670/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 13.2793\n",
            "Epoch 671/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 13.1956\n",
            "Epoch 672/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 13.1125\n",
            "Epoch 673/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 13.0298\n",
            "Epoch 674/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 12.9478\n",
            "Epoch 675/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 12.8662\n",
            "Epoch 676/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 12.7851\n",
            "Epoch 677/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 12.7046\n",
            "Epoch 678/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.6246\n",
            "Epoch 679/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 12.5450\n",
            "Epoch 680/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 12.4660\n",
            "Epoch 681/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 12.3875\n",
            "Epoch 682/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 12.3095\n",
            "Epoch 683/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.2319\n",
            "Epoch 684/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.1549\n",
            "Epoch 685/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 12.0784\n",
            "Epoch 686/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 12.0023\n",
            "Epoch 687/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 11.9267\n",
            "Epoch 688/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.8516\n",
            "Epoch 689/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11.7770\n",
            "Epoch 690/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.7028\n",
            "Epoch 691/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 11.6292\n",
            "Epoch 692/2000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 11.5560\n",
            "Epoch 693/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 11.4832\n",
            "Epoch 694/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.4109\n",
            "Epoch 695/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 11.3391\n",
            "Epoch 696/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.2677\n",
            "Epoch 697/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.1967\n",
            "Epoch 698/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 11.1262\n",
            "Epoch 699/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.0562\n",
            "Epoch 700/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.9866\n",
            "Epoch 701/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.9175\n",
            "Epoch 702/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.8488\n",
            "Epoch 703/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.7805\n",
            "Epoch 704/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.7127\n",
            "Epoch 705/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.6453\n",
            "Epoch 706/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.5783\n",
            "Epoch 707/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.5117\n",
            "Epoch 708/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.4456\n",
            "Epoch 709/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.3798\n",
            "Epoch 710/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.3145\n",
            "Epoch 711/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.2496\n",
            "Epoch 712/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.1852\n",
            "Epoch 713/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.1211\n",
            "Epoch 714/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.0574\n",
            "Epoch 715/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.9942\n",
            "Epoch 716/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.9313\n",
            "Epoch 717/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.8688\n",
            "Epoch 718/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.8068\n",
            "Epoch 719/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.7451\n",
            "Epoch 720/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.6838\n",
            "Epoch 721/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.6229\n",
            "Epoch 722/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.5624\n",
            "Epoch 723/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.5023\n",
            "Epoch 724/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 9.4426\n",
            "Epoch 725/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.3832\n",
            "Epoch 726/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.3242\n",
            "Epoch 727/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.2656\n",
            "Epoch 728/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.2073\n",
            "Epoch 729/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.1494\n",
            "Epoch 730/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 9.0919\n",
            "Epoch 731/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.0348\n",
            "Epoch 732/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.9780\n",
            "Epoch 733/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.9216\n",
            "Epoch 734/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.8655\n",
            "Epoch 735/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.8098\n",
            "Epoch 736/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.7545\n",
            "Epoch 737/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.6995\n",
            "Epoch 738/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.6448\n",
            "Epoch 739/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.5905\n",
            "Epoch 740/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.5365\n",
            "Epoch 741/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.4829\n",
            "Epoch 742/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.4296\n",
            "Epoch 743/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3767\n",
            "Epoch 744/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3240\n",
            "Epoch 745/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.2718\n",
            "Epoch 746/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.2198\n",
            "Epoch 747/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.1682\n",
            "Epoch 748/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.1169\n",
            "Epoch 749/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.0659\n",
            "Epoch 750/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.0153\n",
            "Epoch 751/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.9650\n",
            "Epoch 752/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.9150\n",
            "Epoch 753/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.8653\n",
            "Epoch 754/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.8159\n",
            "Epoch 755/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.7668\n",
            "Epoch 756/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.7181\n",
            "Epoch 757/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.6697\n",
            "Epoch 758/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.6215\n",
            "Epoch 759/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.5737\n",
            "Epoch 760/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.5262\n",
            "Epoch 761/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.4790\n",
            "Epoch 762/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.4321\n",
            "Epoch 763/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.3854\n",
            "Epoch 764/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.3391\n",
            "Epoch 765/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2930\n",
            "Epoch 766/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.2473\n",
            "Epoch 767/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.2018\n",
            "Epoch 768/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1567\n",
            "Epoch 769/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1118\n",
            "Epoch 770/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0672\n",
            "Epoch 771/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0228\n",
            "Epoch 772/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9788\n",
            "Epoch 773/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9351\n",
            "Epoch 774/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.8916\n",
            "Epoch 775/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.8484\n",
            "Epoch 776/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.8054\n",
            "Epoch 777/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.7628\n",
            "Epoch 778/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.7204\n",
            "Epoch 779/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.6783\n",
            "Epoch 780/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.6364\n",
            "Epoch 781/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.5948\n",
            "Epoch 782/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.5535\n",
            "Epoch 783/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.5124\n",
            "Epoch 784/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.4716\n",
            "Epoch 785/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.4311\n",
            "Epoch 786/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.3908\n",
            "Epoch 787/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.3508\n",
            "Epoch 788/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.3110\n",
            "Epoch 789/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.2714\n",
            "Epoch 790/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.2322\n",
            "Epoch 791/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.1931\n",
            "Epoch 792/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.1544\n",
            "Epoch 793/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.1158\n",
            "Epoch 794/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.0775\n",
            "Epoch 795/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.0395\n",
            "Epoch 796/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.0017\n",
            "Epoch 797/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.9641\n",
            "Epoch 798/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.9268\n",
            "Epoch 799/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.8897\n",
            "Epoch 800/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.8528\n",
            "Epoch 801/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.8162\n",
            "Epoch 802/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.7798\n",
            "Epoch 803/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.7437\n",
            "Epoch 804/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.7077\n",
            "Epoch 805/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.6720\n",
            "Epoch 806/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.6365\n",
            "Epoch 807/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.6013\n",
            "Epoch 808/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.5662\n",
            "Epoch 809/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.5314\n",
            "Epoch 810/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.4968\n",
            "Epoch 811/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4625\n",
            "Epoch 812/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.4283\n",
            "Epoch 813/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.3944\n",
            "Epoch 814/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.3607\n",
            "Epoch 815/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.3271\n",
            "Epoch 816/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2938\n",
            "Epoch 817/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.2608\n",
            "Epoch 818/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2279\n",
            "Epoch 819/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.1952\n",
            "Epoch 820/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.1628\n",
            "Epoch 821/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.1305\n",
            "Epoch 822/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.0985\n",
            "Epoch 823/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.0666\n",
            "Epoch 824/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.0350\n",
            "Epoch 825/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.0035\n",
            "Epoch 826/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.9723\n",
            "Epoch 827/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.9412\n",
            "Epoch 828/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.9104\n",
            "Epoch 829/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.8797\n",
            "Epoch 830/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.8493\n",
            "Epoch 831/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.8190\n",
            "Epoch 832/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.7889\n",
            "Epoch 833/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.7590\n",
            "Epoch 834/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.7294\n",
            "Epoch 835/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.6999\n",
            "Epoch 836/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.6705\n",
            "Epoch 837/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.6414\n",
            "Epoch 838/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.6124\n",
            "Epoch 839/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.5837\n",
            "Epoch 840/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 4.5551\n",
            "Epoch 841/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.5267\n",
            "Epoch 842/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.4984\n",
            "Epoch 843/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.4704\n",
            "Epoch 844/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 4.4425\n",
            "Epoch 845/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.4149\n",
            "Epoch 846/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.3873\n",
            "Epoch 847/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.3600\n",
            "Epoch 848/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.3328\n",
            "Epoch 849/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.3058\n",
            "Epoch 850/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.2790\n",
            "Epoch 851/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.2524\n",
            "Epoch 852/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.2259\n",
            "Epoch 853/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.1996\n",
            "Epoch 854/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.1734\n",
            "Epoch 855/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.1474\n",
            "Epoch 856/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.1216\n",
            "Epoch 857/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.0959\n",
            "Epoch 858/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.0704\n",
            "Epoch 859/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.0451\n",
            "Epoch 860/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.0199\n",
            "Epoch 861/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.9949\n",
            "Epoch 862/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9700\n",
            "Epoch 863/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.9454\n",
            "Epoch 864/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.9208\n",
            "Epoch 865/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8964\n",
            "Epoch 866/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.8722\n",
            "Epoch 867/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8481\n",
            "Epoch 868/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8242\n",
            "Epoch 869/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8004\n",
            "Epoch 870/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7768\n",
            "Epoch 871/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.7533\n",
            "Epoch 872/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7300\n",
            "Epoch 873/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7068\n",
            "Epoch 874/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6838\n",
            "Epoch 875/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.6609\n",
            "Epoch 876/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6382\n",
            "Epoch 877/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6156\n",
            "Epoch 878/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.5931\n",
            "Epoch 879/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.5708\n",
            "Epoch 880/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.5487\n",
            "Epoch 881/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.5266\n",
            "Epoch 882/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.5047\n",
            "Epoch 883/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.4830\n",
            "Epoch 884/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.4614\n",
            "Epoch 885/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.4399\n",
            "Epoch 886/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.4186\n",
            "Epoch 887/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.3973\n",
            "Epoch 888/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.3763\n",
            "Epoch 889/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.3554\n",
            "Epoch 890/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.3345\n",
            "Epoch 891/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.3139\n",
            "Epoch 892/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.2933\n",
            "Epoch 893/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.2729\n",
            "Epoch 894/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.2526\n",
            "Epoch 895/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.2325\n",
            "Epoch 896/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.2125\n",
            "Epoch 897/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.1926\n",
            "Epoch 898/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.1728\n",
            "Epoch 899/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.1531\n",
            "Epoch 900/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.1336\n",
            "Epoch 901/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.1142\n",
            "Epoch 902/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.0950\n",
            "Epoch 903/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.0758\n",
            "Epoch 904/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.0568\n",
            "Epoch 905/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.0379\n",
            "Epoch 906/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.0191\n",
            "Epoch 907/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.0004\n",
            "Epoch 908/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.9818\n",
            "Epoch 909/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.9634\n",
            "Epoch 910/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.9451\n",
            "Epoch 911/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.9269\n",
            "Epoch 912/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.9088\n",
            "Epoch 913/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.8908\n",
            "Epoch 914/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.8729\n",
            "Epoch 915/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.8552\n",
            "Epoch 916/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.8376\n",
            "Epoch 917/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.8200\n",
            "Epoch 918/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.8026\n",
            "Epoch 919/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.7853\n",
            "Epoch 920/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.7681\n",
            "Epoch 921/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.7510\n",
            "Epoch 922/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.7341\n",
            "Epoch 923/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.7172\n",
            "Epoch 924/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.7004\n",
            "Epoch 925/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6838\n",
            "Epoch 926/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6672\n",
            "Epoch 927/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6508\n",
            "Epoch 928/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.6344\n",
            "Epoch 929/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6182\n",
            "Epoch 930/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6021\n",
            "Epoch 931/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.5860\n",
            "Epoch 932/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5701\n",
            "Epoch 933/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.5543\n",
            "Epoch 934/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5386\n",
            "Epoch 935/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.5229\n",
            "Epoch 936/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5074\n",
            "Epoch 937/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.4920\n",
            "Epoch 938/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.4766\n",
            "Epoch 939/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.4614\n",
            "Epoch 940/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.4463\n",
            "Epoch 941/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.4312\n",
            "Epoch 942/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.4163\n",
            "Epoch 943/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.4014\n",
            "Epoch 944/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.3867\n",
            "Epoch 945/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.3720\n",
            "Epoch 946/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3574\n",
            "Epoch 947/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3429\n",
            "Epoch 948/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3286\n",
            "Epoch 949/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.3142\n",
            "Epoch 950/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3000\n",
            "Epoch 951/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2859\n",
            "Epoch 952/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2719\n",
            "Epoch 953/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2580\n",
            "Epoch 954/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2441\n",
            "Epoch 955/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2303\n",
            "Epoch 956/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2167\n",
            "Epoch 957/2000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.2031\n",
            "Epoch 958/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.1896\n",
            "Epoch 959/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.1762\n",
            "Epoch 960/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.1628\n",
            "Epoch 961/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.1496\n",
            "Epoch 962/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.1364\n",
            "Epoch 963/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.1233\n",
            "Epoch 964/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1103\n",
            "Epoch 965/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.0974\n",
            "Epoch 966/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0846\n",
            "Epoch 967/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0718\n",
            "Epoch 968/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.0591\n",
            "Epoch 969/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0466\n",
            "Epoch 970/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0340\n",
            "Epoch 971/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.0216\n",
            "Epoch 972/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0093\n",
            "Epoch 973/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9970\n",
            "Epoch 974/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9848\n",
            "Epoch 975/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9727\n",
            "Epoch 976/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.9606\n",
            "Epoch 977/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9487\n",
            "Epoch 978/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9368\n",
            "Epoch 979/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9249\n",
            "Epoch 980/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9132\n",
            "Epoch 981/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.9015\n",
            "Epoch 982/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.8899\n",
            "Epoch 983/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.8784\n",
            "Epoch 984/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.8670\n",
            "Epoch 985/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.8556\n",
            "Epoch 986/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.8443\n",
            "Epoch 987/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8331\n",
            "Epoch 988/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.8219\n",
            "Epoch 989/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.8108\n",
            "Epoch 990/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7998\n",
            "Epoch 991/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7888\n",
            "Epoch 992/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7780\n",
            "Epoch 993/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7671\n",
            "Epoch 994/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.7564\n",
            "Epoch 995/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7457\n",
            "Epoch 996/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7351\n",
            "Epoch 997/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.7246\n",
            "Epoch 998/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.7141\n",
            "Epoch 999/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.7037\n",
            "Epoch 1000/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6934\n",
            "Epoch 1001/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.6831\n",
            "Epoch 1002/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6729\n",
            "Epoch 1003/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6627\n",
            "Epoch 1004/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6527\n",
            "Epoch 1005/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6426\n",
            "Epoch 1006/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6327\n",
            "Epoch 1007/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6228\n",
            "Epoch 1008/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.6130\n",
            "Epoch 1009/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6032\n",
            "Epoch 1010/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5935\n",
            "Epoch 1011/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.5839\n",
            "Epoch 1012/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.5743\n",
            "Epoch 1013/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.5648\n",
            "Epoch 1014/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5553\n",
            "Epoch 1015/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5459\n",
            "Epoch 1016/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5366\n",
            "Epoch 1017/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5273\n",
            "Epoch 1018/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.5181\n",
            "Epoch 1019/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5089\n",
            "Epoch 1020/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4998\n",
            "Epoch 1021/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4907\n",
            "Epoch 1022/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.4818\n",
            "Epoch 1023/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4728\n",
            "Epoch 1024/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4639\n",
            "Epoch 1025/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4551\n",
            "Epoch 1026/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4464\n",
            "Epoch 1027/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4376\n",
            "Epoch 1028/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4290\n",
            "Epoch 1029/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4204\n",
            "Epoch 1030/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.4118\n",
            "Epoch 1031/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4034\n",
            "Epoch 1032/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3949\n",
            "Epoch 1033/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3865\n",
            "Epoch 1034/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.3782\n",
            "Epoch 1035/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3699\n",
            "Epoch 1036/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3617\n",
            "Epoch 1037/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3535\n",
            "Epoch 1038/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3454\n",
            "Epoch 1039/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3373\n",
            "Epoch 1040/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3293\n",
            "Epoch 1041/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3213\n",
            "Epoch 1042/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3134\n",
            "Epoch 1043/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3056\n",
            "Epoch 1044/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2977\n",
            "Epoch 1045/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2900\n",
            "Epoch 1046/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2823\n",
            "Epoch 1047/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2746\n",
            "Epoch 1048/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2670\n",
            "Epoch 1049/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2594\n",
            "Epoch 1050/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2519\n",
            "Epoch 1051/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2444\n",
            "Epoch 1052/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2369\n",
            "Epoch 1053/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2296\n",
            "Epoch 1054/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2222\n",
            "Epoch 1055/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2149\n",
            "Epoch 1056/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2077\n",
            "Epoch 1057/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.2005\n",
            "Epoch 1058/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1934\n",
            "Epoch 1059/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1862\n",
            "Epoch 1060/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1792\n",
            "Epoch 1061/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1722\n",
            "Epoch 1062/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1652\n",
            "Epoch 1063/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.1583\n",
            "Epoch 1064/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1514\n",
            "Epoch 1065/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1445\n",
            "Epoch 1066/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1377\n",
            "Epoch 1067/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1310\n",
            "Epoch 1068/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1243\n",
            "Epoch 1069/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1176\n",
            "Epoch 1070/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1110\n",
            "Epoch 1071/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.1044\n",
            "Epoch 1072/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0978\n",
            "Epoch 1073/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0913\n",
            "Epoch 1074/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0849\n",
            "Epoch 1075/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0785\n",
            "Epoch 1076/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0721\n",
            "Epoch 1077/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0657\n",
            "Epoch 1078/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0594\n",
            "Epoch 1079/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0532\n",
            "Epoch 1080/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0470\n",
            "Epoch 1081/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0408\n",
            "Epoch 1082/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0346\n",
            "Epoch 1083/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0285\n",
            "Epoch 1084/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0225\n",
            "Epoch 1085/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0165\n",
            "Epoch 1086/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0105\n",
            "Epoch 1087/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0045\n",
            "Epoch 1088/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9986\n",
            "Epoch 1089/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9927\n",
            "Epoch 1090/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9869\n",
            "Epoch 1091/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9811\n",
            "Epoch 1092/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.9753\n",
            "Epoch 1093/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.9696\n",
            "Epoch 1094/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.9639\n",
            "Epoch 1095/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9583\n",
            "Epoch 1096/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9526\n",
            "Epoch 1097/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9471\n",
            "Epoch 1098/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9415\n",
            "Epoch 1099/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9360\n",
            "Epoch 1100/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9305\n",
            "Epoch 1101/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.9251\n",
            "Epoch 1102/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9197\n",
            "Epoch 1103/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9143\n",
            "Epoch 1104/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9090\n",
            "Epoch 1105/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9037\n",
            "Epoch 1106/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8984\n",
            "Epoch 1107/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8932\n",
            "Epoch 1108/2000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.8879\n",
            "Epoch 1109/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8828\n",
            "Epoch 1110/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.8776\n",
            "Epoch 1111/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8725\n",
            "Epoch 1112/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8675\n",
            "Epoch 1113/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.8624\n",
            "Epoch 1114/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8574\n",
            "Epoch 1115/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8524\n",
            "Epoch 1116/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8475\n",
            "Epoch 1117/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8426\n",
            "Epoch 1118/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.8377\n",
            "Epoch 1119/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.8328\n",
            "Epoch 1120/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8280\n",
            "Epoch 1121/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8232\n",
            "Epoch 1122/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8184\n",
            "Epoch 1123/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8137\n",
            "Epoch 1124/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8090\n",
            "Epoch 1125/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.8043\n",
            "Epoch 1126/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7997\n",
            "Epoch 1127/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7951\n",
            "Epoch 1128/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7905\n",
            "Epoch 1129/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7859\n",
            "Epoch 1130/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7814\n",
            "Epoch 1131/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7769\n",
            "Epoch 1132/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7724\n",
            "Epoch 1133/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7680\n",
            "Epoch 1134/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7636\n",
            "Epoch 1135/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.7592\n",
            "Epoch 1136/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7548\n",
            "Epoch 1137/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.7505\n",
            "Epoch 1138/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7462\n",
            "Epoch 1139/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.7419\n",
            "Epoch 1140/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7377\n",
            "Epoch 1141/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7335\n",
            "Epoch 1142/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7293\n",
            "Epoch 1143/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7251\n",
            "Epoch 1144/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7210\n",
            "Epoch 1145/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7169\n",
            "Epoch 1146/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7128\n",
            "Epoch 1147/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7087\n",
            "Epoch 1148/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7047\n",
            "Epoch 1149/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7007\n",
            "Epoch 1150/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6967\n",
            "Epoch 1151/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6927\n",
            "Epoch 1152/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6888\n",
            "Epoch 1153/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6849\n",
            "Epoch 1154/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6810\n",
            "Epoch 1155/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6771\n",
            "Epoch 1156/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6733\n",
            "Epoch 1157/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6695\n",
            "Epoch 1158/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6657\n",
            "Epoch 1159/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6619\n",
            "Epoch 1160/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6582\n",
            "Epoch 1161/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6545\n",
            "Epoch 1162/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6508\n",
            "Epoch 1163/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6471\n",
            "Epoch 1164/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6434\n",
            "Epoch 1165/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6398\n",
            "Epoch 1166/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6362\n",
            "Epoch 1167/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6326\n",
            "Epoch 1168/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6291\n",
            "Epoch 1169/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6256\n",
            "Epoch 1170/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6220\n",
            "Epoch 1171/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6186\n",
            "Epoch 1172/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6151\n",
            "Epoch 1173/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6116\n",
            "Epoch 1174/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6082\n",
            "Epoch 1175/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6048\n",
            "Epoch 1176/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6014\n",
            "Epoch 1177/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5981\n",
            "Epoch 1178/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5948\n",
            "Epoch 1179/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5914\n",
            "Epoch 1180/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5881\n",
            "Epoch 1181/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5849\n",
            "Epoch 1182/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5816\n",
            "Epoch 1183/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5784\n",
            "Epoch 1184/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5752\n",
            "Epoch 1185/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5720\n",
            "Epoch 1186/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5688\n",
            "Epoch 1187/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5657\n",
            "Epoch 1188/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5625\n",
            "Epoch 1189/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5594\n",
            "Epoch 1190/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5563\n",
            "Epoch 1191/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5533\n",
            "Epoch 1192/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5502\n",
            "Epoch 1193/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5472\n",
            "Epoch 1194/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5442\n",
            "Epoch 1195/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5412\n",
            "Epoch 1196/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5382\n",
            "Epoch 1197/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5352\n",
            "Epoch 1198/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5323\n",
            "Epoch 1199/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5294\n",
            "Epoch 1200/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5265\n",
            "Epoch 1201/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5236\n",
            "Epoch 1202/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5207\n",
            "Epoch 1203/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5179\n",
            "Epoch 1204/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5151\n",
            "Epoch 1205/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5122\n",
            "Epoch 1206/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5095\n",
            "Epoch 1207/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5067\n",
            "Epoch 1208/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5039\n",
            "Epoch 1209/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5012\n",
            "Epoch 1210/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4985\n",
            "Epoch 1211/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4958\n",
            "Epoch 1212/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4931\n",
            "Epoch 1213/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4904\n",
            "Epoch 1214/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4877\n",
            "Epoch 1215/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4851\n",
            "Epoch 1216/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4825\n",
            "Epoch 1217/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4799\n",
            "Epoch 1218/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4773\n",
            "Epoch 1219/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4747\n",
            "Epoch 1220/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4722\n",
            "Epoch 1221/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4696\n",
            "Epoch 1222/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4671\n",
            "Epoch 1223/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4646\n",
            "Epoch 1224/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4621\n",
            "Epoch 1225/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4596\n",
            "Epoch 1226/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4572\n",
            "Epoch 1227/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4547\n",
            "Epoch 1228/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4523\n",
            "Epoch 1229/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4499\n",
            "Epoch 1230/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4475\n",
            "Epoch 1231/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4451\n",
            "Epoch 1232/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4427\n",
            "Epoch 1233/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4404\n",
            "Epoch 1234/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4380\n",
            "Epoch 1235/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4357\n",
            "Epoch 1236/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4334\n",
            "Epoch 1237/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4311\n",
            "Epoch 1238/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4288\n",
            "Epoch 1239/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4266\n",
            "Epoch 1240/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4243\n",
            "Epoch 1241/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4221\n",
            "Epoch 1242/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4199\n",
            "Epoch 1243/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4177\n",
            "Epoch 1244/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4155\n",
            "Epoch 1245/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4133\n",
            "Epoch 1246/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4111\n",
            "Epoch 1247/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4090\n",
            "Epoch 1248/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4068\n",
            "Epoch 1249/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4047\n",
            "Epoch 1250/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4026\n",
            "Epoch 1251/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4005\n",
            "Epoch 1252/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3984\n",
            "Epoch 1253/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.3963\n",
            "Epoch 1254/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3943\n",
            "Epoch 1255/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.3922\n",
            "Epoch 1256/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3902\n",
            "Epoch 1257/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3882\n",
            "Epoch 1258/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3862\n",
            "Epoch 1259/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3842\n",
            "Epoch 1260/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3822\n",
            "Epoch 1261/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3802\n",
            "Epoch 1262/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3783\n",
            "Epoch 1263/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3763\n",
            "Epoch 1264/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3744\n",
            "Epoch 1265/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3725\n",
            "Epoch 1266/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3706\n",
            "Epoch 1267/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3687\n",
            "Epoch 1268/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3668\n",
            "Epoch 1269/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3649\n",
            "Epoch 1270/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3631\n",
            "Epoch 1271/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3612\n",
            "Epoch 1272/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3594\n",
            "Epoch 1273/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3576\n",
            "Epoch 1274/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3558\n",
            "Epoch 1275/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3540\n",
            "Epoch 1276/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3522\n",
            "Epoch 1277/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3504\n",
            "Epoch 1278/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3486\n",
            "Epoch 1279/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3469\n",
            "Epoch 1280/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3451\n",
            "Epoch 1281/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3434\n",
            "Epoch 1282/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3417\n",
            "Epoch 1283/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3399\n",
            "Epoch 1284/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3382\n",
            "Epoch 1285/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3366\n",
            "Epoch 1286/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3349\n",
            "Epoch 1287/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3332\n",
            "Epoch 1288/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3315\n",
            "Epoch 1289/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3299\n",
            "Epoch 1290/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3283\n",
            "Epoch 1291/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3266\n",
            "Epoch 1292/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3250\n",
            "Epoch 1293/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3234\n",
            "Epoch 1294/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3218\n",
            "Epoch 1295/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3202\n",
            "Epoch 1296/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3187\n",
            "Epoch 1297/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3171\n",
            "Epoch 1298/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3155\n",
            "Epoch 1299/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3140\n",
            "Epoch 1300/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3125\n",
            "Epoch 1301/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3109\n",
            "Epoch 1302/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3094\n",
            "Epoch 1303/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3079\n",
            "Epoch 1304/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3064\n",
            "Epoch 1305/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3049\n",
            "Epoch 1306/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3034\n",
            "Epoch 1307/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3020\n",
            "Epoch 1308/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3005\n",
            "Epoch 1309/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2990\n",
            "Epoch 1310/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2976\n",
            "Epoch 1311/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2962\n",
            "Epoch 1312/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2948\n",
            "Epoch 1313/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2933\n",
            "Epoch 1314/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2919\n",
            "Epoch 1315/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2905\n",
            "Epoch 1316/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2891\n",
            "Epoch 1317/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2878\n",
            "Epoch 1318/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2864\n",
            "Epoch 1319/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2850\n",
            "Epoch 1320/2000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.2837\n",
            "Epoch 1321/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2823\n",
            "Epoch 1322/2000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.2810\n",
            "Epoch 1323/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2797\n",
            "Epoch 1324/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2784\n",
            "Epoch 1325/2000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.2770\n",
            "Epoch 1326/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2757\n",
            "Epoch 1327/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2745\n",
            "Epoch 1328/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2732\n",
            "Epoch 1329/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2719\n",
            "Epoch 1330/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2706\n",
            "Epoch 1331/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2694\n",
            "Epoch 1332/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2681\n",
            "Epoch 1333/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2669\n",
            "Epoch 1334/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2656\n",
            "Epoch 1335/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2644\n",
            "Epoch 1336/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2632\n",
            "Epoch 1337/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2620\n",
            "Epoch 1338/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2607\n",
            "Epoch 1339/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2595\n",
            "Epoch 1340/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2584\n",
            "Epoch 1341/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2572\n",
            "Epoch 1342/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2560\n",
            "Epoch 1343/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2548\n",
            "Epoch 1344/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2537\n",
            "Epoch 1345/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2525\n",
            "Epoch 1346/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2514\n",
            "Epoch 1347/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2502\n",
            "Epoch 1348/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2491\n",
            "Epoch 1349/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2480\n",
            "Epoch 1350/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2468\n",
            "Epoch 1351/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2457\n",
            "Epoch 1352/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2446\n",
            "Epoch 1353/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2435\n",
            "Epoch 1354/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2424\n",
            "Epoch 1355/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2414\n",
            "Epoch 1356/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2403\n",
            "Epoch 1357/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2392\n",
            "Epoch 1358/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2381\n",
            "Epoch 1359/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2371\n",
            "Epoch 1360/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2360\n",
            "Epoch 1361/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2350\n",
            "Epoch 1362/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2340\n",
            "Epoch 1363/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2329\n",
            "Epoch 1364/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2319\n",
            "Epoch 1365/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2309\n",
            "Epoch 1366/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2299\n",
            "Epoch 1367/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2289\n",
            "Epoch 1368/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2279\n",
            "Epoch 1369/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2269\n",
            "Epoch 1370/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2259\n",
            "Epoch 1371/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2249\n",
            "Epoch 1372/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2240\n",
            "Epoch 1373/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2230\n",
            "Epoch 1374/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2220\n",
            "Epoch 1375/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2211\n",
            "Epoch 1376/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2201\n",
            "Epoch 1377/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2192\n",
            "Epoch 1378/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2183\n",
            "Epoch 1379/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2173\n",
            "Epoch 1380/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2164\n",
            "Epoch 1381/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2155\n",
            "Epoch 1382/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2146\n",
            "Epoch 1383/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2137\n",
            "Epoch 1384/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2128\n",
            "Epoch 1385/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2119\n",
            "Epoch 1386/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2110\n",
            "Epoch 1387/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2101\n",
            "Epoch 1388/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2092\n",
            "Epoch 1389/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2083\n",
            "Epoch 1390/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2075\n",
            "Epoch 1391/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2066\n",
            "Epoch 1392/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2058\n",
            "Epoch 1393/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2049\n",
            "Epoch 1394/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2041\n",
            "Epoch 1395/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2032\n",
            "Epoch 1396/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2024\n",
            "Epoch 1397/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2016\n",
            "Epoch 1398/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2007\n",
            "Epoch 1399/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1999\n",
            "Epoch 1400/2000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1991\n",
            "Epoch 1401/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1983\n",
            "Epoch 1402/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1975\n",
            "Epoch 1403/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1967\n",
            "Epoch 1404/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1959\n",
            "Epoch 1405/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1951\n",
            "Epoch 1406/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1943\n",
            "Epoch 1407/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1935\n",
            "Epoch 1408/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1928\n",
            "Epoch 1409/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1920\n",
            "Epoch 1410/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1912\n",
            "Epoch 1411/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1905\n",
            "Epoch 1412/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1897\n",
            "Epoch 1413/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1890\n",
            "Epoch 1414/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1882\n",
            "Epoch 1415/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1875\n",
            "Epoch 1416/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1867\n",
            "Epoch 1417/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1860\n",
            "Epoch 1418/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1853\n",
            "Epoch 1419/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1846\n",
            "Epoch 1420/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1839\n",
            "Epoch 1421/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1831\n",
            "Epoch 1422/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1824\n",
            "Epoch 1423/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1817\n",
            "Epoch 1424/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1810\n",
            "Epoch 1425/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1803\n",
            "Epoch 1426/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1796\n",
            "Epoch 1427/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1790\n",
            "Epoch 1428/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1783\n",
            "Epoch 1429/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1776\n",
            "Epoch 1430/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1769\n",
            "Epoch 1431/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1763\n",
            "Epoch 1432/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1756\n",
            "Epoch 1433/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1749\n",
            "Epoch 1434/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1743\n",
            "Epoch 1435/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1736\n",
            "Epoch 1436/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1730\n",
            "Epoch 1437/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1723\n",
            "Epoch 1438/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1717\n",
            "Epoch 1439/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1711\n",
            "Epoch 1440/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1704\n",
            "Epoch 1441/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1698\n",
            "Epoch 1442/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1692\n",
            "Epoch 1443/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1686\n",
            "Epoch 1444/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1679\n",
            "Epoch 1445/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1673\n",
            "Epoch 1446/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1667\n",
            "Epoch 1447/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1661\n",
            "Epoch 1448/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1655\n",
            "Epoch 1449/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1649\n",
            "Epoch 1450/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1643\n",
            "Epoch 1451/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1637\n",
            "Epoch 1452/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1632\n",
            "Epoch 1453/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1626\n",
            "Epoch 1454/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1620\n",
            "Epoch 1455/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1614\n",
            "Epoch 1456/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1609\n",
            "Epoch 1457/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1603\n",
            "Epoch 1458/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1597\n",
            "Epoch 1459/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1592\n",
            "Epoch 1460/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1586\n",
            "Epoch 1461/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1581\n",
            "Epoch 1462/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1575\n",
            "Epoch 1463/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1570\n",
            "Epoch 1464/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1564\n",
            "Epoch 1465/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1559\n",
            "Epoch 1466/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1553\n",
            "Epoch 1467/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1548\n",
            "Epoch 1468/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1543\n",
            "Epoch 1469/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1538\n",
            "Epoch 1470/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1532\n",
            "Epoch 1471/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1527\n",
            "Epoch 1472/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1522\n",
            "Epoch 1473/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1517\n",
            "Epoch 1474/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1512\n",
            "Epoch 1475/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1507\n",
            "Epoch 1476/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1502\n",
            "Epoch 1477/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1497\n",
            "Epoch 1478/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1492\n",
            "Epoch 1479/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1487\n",
            "Epoch 1480/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1482\n",
            "Epoch 1481/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1477\n",
            "Epoch 1482/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1472\n",
            "Epoch 1483/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1467\n",
            "Epoch 1484/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1463\n",
            "Epoch 1485/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1458\n",
            "Epoch 1486/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1453\n",
            "Epoch 1487/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1449\n",
            "Epoch 1488/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1444\n",
            "Epoch 1489/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1439\n",
            "Epoch 1490/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1435\n",
            "Epoch 1491/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1430\n",
            "Epoch 1492/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1426\n",
            "Epoch 1493/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1421\n",
            "Epoch 1494/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1417\n",
            "Epoch 1495/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1412\n",
            "Epoch 1496/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1408\n",
            "Epoch 1497/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1403\n",
            "Epoch 1498/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1399\n",
            "Epoch 1499/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1395\n",
            "Epoch 1500/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1390\n",
            "Epoch 1501/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1386\n",
            "Epoch 1502/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1382\n",
            "Epoch 1503/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1378\n",
            "Epoch 1504/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1373\n",
            "Epoch 1505/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1369\n",
            "Epoch 1506/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1365\n",
            "Epoch 1507/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1361\n",
            "Epoch 1508/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1357\n",
            "Epoch 1509/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1353\n",
            "Epoch 1510/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1349\n",
            "Epoch 1511/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1345\n",
            "Epoch 1512/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1341\n",
            "Epoch 1513/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1337\n",
            "Epoch 1514/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1333\n",
            "Epoch 1515/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1329\n",
            "Epoch 1516/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1325\n",
            "Epoch 1517/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1321\n",
            "Epoch 1518/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1317\n",
            "Epoch 1519/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1313\n",
            "Epoch 1520/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1310\n",
            "Epoch 1521/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1306\n",
            "Epoch 1522/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1302\n",
            "Epoch 1523/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1298\n",
            "Epoch 1524/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1295\n",
            "Epoch 1525/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1291\n",
            "Epoch 1526/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1287\n",
            "Epoch 1527/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1284\n",
            "Epoch 1528/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1280\n",
            "Epoch 1529/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1277\n",
            "Epoch 1530/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1273\n",
            "Epoch 1531/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1269\n",
            "Epoch 1532/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1266\n",
            "Epoch 1533/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1262\n",
            "Epoch 1534/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1259\n",
            "Epoch 1535/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1256\n",
            "Epoch 1536/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1252\n",
            "Epoch 1537/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1249\n",
            "Epoch 1538/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1245\n",
            "Epoch 1539/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1242\n",
            "Epoch 1540/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1239\n",
            "Epoch 1541/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1235\n",
            "Epoch 1542/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1232\n",
            "Epoch 1543/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1229\n",
            "Epoch 1544/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1225\n",
            "Epoch 1545/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1222\n",
            "Epoch 1546/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1219\n",
            "Epoch 1547/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1216\n",
            "Epoch 1548/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1213\n",
            "Epoch 1549/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1209\n",
            "Epoch 1550/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1206\n",
            "Epoch 1551/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1203\n",
            "Epoch 1552/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1200\n",
            "Epoch 1553/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1197\n",
            "Epoch 1554/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1194\n",
            "Epoch 1555/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1191\n",
            "Epoch 1556/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1188\n",
            "Epoch 1557/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1185\n",
            "Epoch 1558/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1182\n",
            "Epoch 1559/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1179\n",
            "Epoch 1560/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1176\n",
            "Epoch 1561/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1173\n",
            "Epoch 1562/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1170\n",
            "Epoch 1563/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1167\n",
            "Epoch 1564/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1164\n",
            "Epoch 1565/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1162\n",
            "Epoch 1566/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1159\n",
            "Epoch 1567/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1156\n",
            "Epoch 1568/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1153\n",
            "Epoch 1569/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1150\n",
            "Epoch 1570/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1148\n",
            "Epoch 1571/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1145\n",
            "Epoch 1572/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1142\n",
            "Epoch 1573/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1139\n",
            "Epoch 1574/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1137\n",
            "Epoch 1575/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1134\n",
            "Epoch 1576/2000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.1131\n",
            "Epoch 1577/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1129\n",
            "Epoch 1578/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1126\n",
            "Epoch 1579/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1124\n",
            "Epoch 1580/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1121\n",
            "Epoch 1581/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1118\n",
            "Epoch 1582/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1116\n",
            "Epoch 1583/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1113\n",
            "Epoch 1584/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1111\n",
            "Epoch 1585/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1108\n",
            "Epoch 1586/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1106\n",
            "Epoch 1587/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1103\n",
            "Epoch 1588/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1101\n",
            "Epoch 1589/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1098\n",
            "Epoch 1590/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1096\n",
            "Epoch 1591/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1093\n",
            "Epoch 1592/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1091\n",
            "Epoch 1593/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1089\n",
            "Epoch 1594/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1086\n",
            "Epoch 1595/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1084\n",
            "Epoch 1596/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1082\n",
            "Epoch 1597/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1079\n",
            "Epoch 1598/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1077\n",
            "Epoch 1599/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1075\n",
            "Epoch 1600/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1072\n",
            "Epoch 1601/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1070\n",
            "Epoch 1602/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1068\n",
            "Epoch 1603/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1066\n",
            "Epoch 1604/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1063\n",
            "Epoch 1605/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1061\n",
            "Epoch 1606/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1059\n",
            "Epoch 1607/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1057\n",
            "Epoch 1608/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1055\n",
            "Epoch 1609/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1052\n",
            "Epoch 1610/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1050\n",
            "Epoch 1611/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1048\n",
            "Epoch 1612/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1046\n",
            "Epoch 1613/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1044\n",
            "Epoch 1614/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1042\n",
            "Epoch 1615/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1040\n",
            "Epoch 1616/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1038\n",
            "Epoch 1617/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1036\n",
            "Epoch 1618/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1034\n",
            "Epoch 1619/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1032\n",
            "Epoch 1620/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1030\n",
            "Epoch 1621/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1028\n",
            "Epoch 1622/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1026\n",
            "Epoch 1623/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1024\n",
            "Epoch 1624/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1022\n",
            "Epoch 1625/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1020\n",
            "Epoch 1626/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1018\n",
            "Epoch 1627/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1016\n",
            "Epoch 1628/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1014\n",
            "Epoch 1629/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1012\n",
            "Epoch 1630/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1010\n",
            "Epoch 1631/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1008\n",
            "Epoch 1632/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1006\n",
            "Epoch 1633/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1005\n",
            "Epoch 1634/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1003\n",
            "Epoch 1635/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1001\n",
            "Epoch 1636/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0999\n",
            "Epoch 1637/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0997\n",
            "Epoch 1638/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0996\n",
            "Epoch 1639/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0994\n",
            "Epoch 1640/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0992\n",
            "Epoch 1641/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0990\n",
            "Epoch 1642/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0988\n",
            "Epoch 1643/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0987\n",
            "Epoch 1644/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0985\n",
            "Epoch 1645/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0983\n",
            "Epoch 1646/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0982\n",
            "Epoch 1647/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0980\n",
            "Epoch 1648/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0978\n",
            "Epoch 1649/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0977\n",
            "Epoch 1650/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0975\n",
            "Epoch 1651/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0973\n",
            "Epoch 1652/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0972\n",
            "Epoch 1653/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0970\n",
            "Epoch 1654/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0968\n",
            "Epoch 1655/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0967\n",
            "Epoch 1656/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0965\n",
            "Epoch 1657/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0964\n",
            "Epoch 1658/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0962\n",
            "Epoch 1659/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0960\n",
            "Epoch 1660/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0959\n",
            "Epoch 1661/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0957\n",
            "Epoch 1662/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0956\n",
            "Epoch 1663/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0954\n",
            "Epoch 1664/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0953\n",
            "Epoch 1665/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0951\n",
            "Epoch 1666/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0950\n",
            "Epoch 1667/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0948\n",
            "Epoch 1668/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0947\n",
            "Epoch 1669/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0945\n",
            "Epoch 1670/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0944\n",
            "Epoch 1671/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0942\n",
            "Epoch 1672/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0941\n",
            "Epoch 1673/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0939\n",
            "Epoch 1674/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0938\n",
            "Epoch 1675/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0937\n",
            "Epoch 1676/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0935\n",
            "Epoch 1677/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0934\n",
            "Epoch 1678/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0932\n",
            "Epoch 1679/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0931\n",
            "Epoch 1680/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0930\n",
            "Epoch 1681/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0928\n",
            "Epoch 1682/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0927\n",
            "Epoch 1683/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0926\n",
            "Epoch 1684/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0924\n",
            "Epoch 1685/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0923\n",
            "Epoch 1686/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0922\n",
            "Epoch 1687/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0920\n",
            "Epoch 1688/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0919\n",
            "Epoch 1689/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0918\n",
            "Epoch 1690/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0916\n",
            "Epoch 1691/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0915\n",
            "Epoch 1692/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0914\n",
            "Epoch 1693/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0913\n",
            "Epoch 1694/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0911\n",
            "Epoch 1695/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0910\n",
            "Epoch 1696/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0909\n",
            "Epoch 1697/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0908\n",
            "Epoch 1698/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0906\n",
            "Epoch 1699/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0905\n",
            "Epoch 1700/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0904\n",
            "Epoch 1701/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0903\n",
            "Epoch 1702/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0902\n",
            "Epoch 1703/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0900\n",
            "Epoch 1704/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0899\n",
            "Epoch 1705/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0898\n",
            "Epoch 1706/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0897\n",
            "Epoch 1707/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0896\n",
            "Epoch 1708/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0895\n",
            "Epoch 1709/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0893\n",
            "Epoch 1710/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0892\n",
            "Epoch 1711/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0891\n",
            "Epoch 1712/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0890\n",
            "Epoch 1713/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0889\n",
            "Epoch 1714/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0888\n",
            "Epoch 1715/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0887\n",
            "Epoch 1716/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0886\n",
            "Epoch 1717/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0885\n",
            "Epoch 1718/2000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0883\n",
            "Epoch 1719/2000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0882\n",
            "Epoch 1720/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0881\n",
            "Epoch 1721/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0880\n",
            "Epoch 1722/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0879\n",
            "Epoch 1723/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0878\n",
            "Epoch 1724/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0877\n",
            "Epoch 1725/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0876\n",
            "Epoch 1726/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0875\n",
            "Epoch 1727/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0874\n",
            "Epoch 1728/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0873\n",
            "Epoch 1729/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0872\n",
            "Epoch 1730/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0871\n",
            "Epoch 1731/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0870\n",
            "Epoch 1732/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0869\n",
            "Epoch 1733/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0868\n",
            "Epoch 1734/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0867\n",
            "Epoch 1735/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0866\n",
            "Epoch 1736/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0865\n",
            "Epoch 1737/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0864\n",
            "Epoch 1738/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0863\n",
            "Epoch 1739/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0862\n",
            "Epoch 1740/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0861\n",
            "Epoch 1741/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0860\n",
            "Epoch 1742/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0860\n",
            "Epoch 1743/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0859\n",
            "Epoch 1744/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0858\n",
            "Epoch 1745/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0857\n",
            "Epoch 1746/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0856\n",
            "Epoch 1747/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0855\n",
            "Epoch 1748/2000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0854\n",
            "Epoch 1749/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0853\n",
            "Epoch 1750/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0852\n",
            "Epoch 1751/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0851\n",
            "Epoch 1752/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0851\n",
            "Epoch 1753/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0850\n",
            "Epoch 1754/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0849\n",
            "Epoch 1755/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0848\n",
            "Epoch 1756/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0847\n",
            "Epoch 1757/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0846\n",
            "Epoch 1758/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0845\n",
            "Epoch 1759/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0845\n",
            "Epoch 1760/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0844\n",
            "Epoch 1761/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0843\n",
            "Epoch 1762/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0842\n",
            "Epoch 1763/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0841\n",
            "Epoch 1764/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0841\n",
            "Epoch 1765/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0840\n",
            "Epoch 1766/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0839\n",
            "Epoch 1767/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0838\n",
            "Epoch 1768/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0837\n",
            "Epoch 1769/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0837\n",
            "Epoch 1770/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0836\n",
            "Epoch 1771/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0835\n",
            "Epoch 1772/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0834\n",
            "Epoch 1773/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0834\n",
            "Epoch 1774/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0833\n",
            "Epoch 1775/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0832\n",
            "Epoch 1776/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0831\n",
            "Epoch 1777/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0831\n",
            "Epoch 1778/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0830\n",
            "Epoch 1779/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0829\n",
            "Epoch 1780/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0828\n",
            "Epoch 1781/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0828\n",
            "Epoch 1782/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0827\n",
            "Epoch 1783/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0826\n",
            "Epoch 1784/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0826\n",
            "Epoch 1785/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0825\n",
            "Epoch 1786/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0824\n",
            "Epoch 1787/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0823\n",
            "Epoch 1788/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0823\n",
            "Epoch 1789/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0822\n",
            "Epoch 1790/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0821\n",
            "Epoch 1791/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0821\n",
            "Epoch 1792/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0820\n",
            "Epoch 1793/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0819\n",
            "Epoch 1794/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0819\n",
            "Epoch 1795/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0818\n",
            "Epoch 1796/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0817\n",
            "Epoch 1797/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0817\n",
            "Epoch 1798/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0816\n",
            "Epoch 1799/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0815\n",
            "Epoch 1800/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0815\n",
            "Epoch 1801/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0814\n",
            "Epoch 1802/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0813\n",
            "Epoch 1803/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0813\n",
            "Epoch 1804/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0812\n",
            "Epoch 1805/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0812\n",
            "Epoch 1806/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0811\n",
            "Epoch 1807/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0810\n",
            "Epoch 1808/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0810\n",
            "Epoch 1809/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0809\n",
            "Epoch 1810/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0809\n",
            "Epoch 1811/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0808\n",
            "Epoch 1812/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0807\n",
            "Epoch 1813/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0807\n",
            "Epoch 1814/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0806\n",
            "Epoch 1815/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0806\n",
            "Epoch 1816/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0805\n",
            "Epoch 1817/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0804\n",
            "Epoch 1818/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0804\n",
            "Epoch 1819/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0803\n",
            "Epoch 1820/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0803\n",
            "Epoch 1821/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0802\n",
            "Epoch 1822/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0802\n",
            "Epoch 1823/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0801\n",
            "Epoch 1824/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0801\n",
            "Epoch 1825/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0800\n",
            "Epoch 1826/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0799\n",
            "Epoch 1827/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0799\n",
            "Epoch 1828/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0798\n",
            "Epoch 1829/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0798\n",
            "Epoch 1830/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0797\n",
            "Epoch 1831/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0797\n",
            "Epoch 1832/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0796\n",
            "Epoch 1833/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0796\n",
            "Epoch 1834/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0795\n",
            "Epoch 1835/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0795\n",
            "Epoch 1836/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0794\n",
            "Epoch 1837/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0794\n",
            "Epoch 1838/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0793\n",
            "Epoch 1839/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0793\n",
            "Epoch 1840/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0792\n",
            "Epoch 1841/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0792\n",
            "Epoch 1842/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0791\n",
            "Epoch 1843/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0791\n",
            "Epoch 1844/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0790\n",
            "Epoch 1845/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0790\n",
            "Epoch 1846/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0789\n",
            "Epoch 1847/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0789\n",
            "Epoch 1848/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0788\n",
            "Epoch 1849/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0788\n",
            "Epoch 1850/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0787\n",
            "Epoch 1851/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0787\n",
            "Epoch 1852/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0786\n",
            "Epoch 1853/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0786\n",
            "Epoch 1854/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0786\n",
            "Epoch 1855/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0785\n",
            "Epoch 1856/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0785\n",
            "Epoch 1857/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0784\n",
            "Epoch 1858/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0784\n",
            "Epoch 1859/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0783\n",
            "Epoch 1860/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0783\n",
            "Epoch 1861/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0782\n",
            "Epoch 1862/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0782\n",
            "Epoch 1863/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0782\n",
            "Epoch 1864/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0781\n",
            "Epoch 1865/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0781\n",
            "Epoch 1866/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0780\n",
            "Epoch 1867/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0780\n",
            "Epoch 1868/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0779\n",
            "Epoch 1869/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0779\n",
            "Epoch 1870/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0779\n",
            "Epoch 1871/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0778\n",
            "Epoch 1872/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0778\n",
            "Epoch 1873/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0777\n",
            "Epoch 1874/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0777\n",
            "Epoch 1875/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0777\n",
            "Epoch 1876/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0776\n",
            "Epoch 1877/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0776\n",
            "Epoch 1878/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0775\n",
            "Epoch 1879/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0775\n",
            "Epoch 1880/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0775\n",
            "Epoch 1881/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0774\n",
            "Epoch 1882/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0774\n",
            "Epoch 1883/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0774\n",
            "Epoch 1884/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0773\n",
            "Epoch 1885/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0773\n",
            "Epoch 1886/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0772\n",
            "Epoch 1887/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0772\n",
            "Epoch 1888/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0772\n",
            "Epoch 1889/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0771\n",
            "Epoch 1890/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0771\n",
            "Epoch 1891/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0771\n",
            "Epoch 1892/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0770\n",
            "Epoch 1893/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0770\n",
            "Epoch 1894/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0770\n",
            "Epoch 1895/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0769\n",
            "Epoch 1896/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0769\n",
            "Epoch 1897/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0769\n",
            "Epoch 1898/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0768\n",
            "Epoch 1899/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0768\n",
            "Epoch 1900/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0768\n",
            "Epoch 1901/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0767\n",
            "Epoch 1902/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0767\n",
            "Epoch 1903/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0766\n",
            "Epoch 1904/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0766\n",
            "Epoch 1905/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0766\n",
            "Epoch 1906/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0765\n",
            "Epoch 1907/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0765\n",
            "Epoch 1908/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0765\n",
            "Epoch 1909/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0765\n",
            "Epoch 1910/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0764\n",
            "Epoch 1911/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0764\n",
            "Epoch 1912/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0764\n",
            "Epoch 1913/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0763\n",
            "Epoch 1914/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0763\n",
            "Epoch 1915/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0763\n",
            "Epoch 1916/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0762\n",
            "Epoch 1917/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0762\n",
            "Epoch 1918/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0762\n",
            "Epoch 1919/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0761\n",
            "Epoch 1920/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0761\n",
            "Epoch 1921/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0761\n",
            "Epoch 1922/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0761\n",
            "Epoch 1923/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0760\n",
            "Epoch 1924/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0760\n",
            "Epoch 1925/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0760\n",
            "Epoch 1926/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0759\n",
            "Epoch 1927/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0759\n",
            "Epoch 1928/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0759\n",
            "Epoch 1929/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0759\n",
            "Epoch 1930/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0758\n",
            "Epoch 1931/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0758\n",
            "Epoch 1932/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0758\n",
            "Epoch 1933/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0757\n",
            "Epoch 1934/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0757\n",
            "Epoch 1935/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0757\n",
            "Epoch 1936/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0757\n",
            "Epoch 1937/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0756\n",
            "Epoch 1938/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0756\n",
            "Epoch 1939/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0756\n",
            "Epoch 1940/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0756\n",
            "Epoch 1941/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0755\n",
            "Epoch 1942/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0755\n",
            "Epoch 1943/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0755\n",
            "Epoch 1944/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0755\n",
            "Epoch 1945/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0754\n",
            "Epoch 1946/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0754\n",
            "Epoch 1947/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0754\n",
            "Epoch 1948/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0754\n",
            "Epoch 1949/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0753\n",
            "Epoch 1950/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0753\n",
            "Epoch 1951/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0753\n",
            "Epoch 1952/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0753\n",
            "Epoch 1953/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0752\n",
            "Epoch 1954/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0752\n",
            "Epoch 1955/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0752\n",
            "Epoch 1956/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0752\n",
            "Epoch 1957/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0751\n",
            "Epoch 1958/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0751\n",
            "Epoch 1959/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0751\n",
            "Epoch 1960/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0751\n",
            "Epoch 1961/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0750\n",
            "Epoch 1962/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0750\n",
            "Epoch 1963/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0750\n",
            "Epoch 1964/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0750\n",
            "Epoch 1965/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0749\n",
            "Epoch 1966/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0749\n",
            "Epoch 1967/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0749\n",
            "Epoch 1968/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0749\n",
            "Epoch 1969/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0749\n",
            "Epoch 1970/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0748\n",
            "Epoch 1971/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0748\n",
            "Epoch 1972/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0748\n",
            "Epoch 1973/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0748\n",
            "Epoch 1974/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0748\n",
            "Epoch 1975/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0747\n",
            "Epoch 1976/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0747\n",
            "Epoch 1977/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0747\n",
            "Epoch 1978/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0747\n",
            "Epoch 1979/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0746\n",
            "Epoch 1980/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0746\n",
            "Epoch 1981/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0746\n",
            "Epoch 1982/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0746\n",
            "Epoch 1983/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0746\n",
            "Epoch 1984/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0745\n",
            "Epoch 1985/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0745\n",
            "Epoch 1986/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0745\n",
            "Epoch 1987/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0745\n",
            "Epoch 1988/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0745\n",
            "Epoch 1989/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0745\n",
            "Epoch 1990/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0744\n",
            "Epoch 1991/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0744\n",
            "Epoch 1992/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0744\n",
            "Epoch 1993/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0744\n",
            "Epoch 1994/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0744\n",
            "Epoch 1995/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0743\n",
            "Epoch 1996/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0743\n",
            "Epoch 1997/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0743\n",
            "Epoch 1998/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0743\n",
            "Epoch 1999/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0743\n",
            "Epoch 2000/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0742\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7cfd64ff5360>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 임의의 학습 시간과 과외 시간을 집어넣어 점수를 예측하는 모델을 테스트해 보겠습니다.\n",
        "\n",
        "hour = 7\n",
        "private_class = 4\n",
        "prediction = model.predict([[hour, private_class]])\n",
        "\n",
        "print(\"%.f시간을 공부하고 %.f시간의 과외를 받을 경우, 예상 점수는 %.02f점입니다\"% (hour, private_class, prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8L1b4t6gR5P",
        "outputId": "42a502ce-cecf-41c3-bf7f-168c89190210"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 48ms/step\n",
            "7시간을 공부하고 4시간의 과외를 받을 경우, 예상 점수는 97.53점입니다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Q2_0202. 모델의 목적은 환자의 병력을 기반으로 수술 후 1년 후 결과(사망 또는 생존)를 예측하세요. (학습 Only)\n",
        "- Sequential\n",
        "  - 다양하게 시도\n",
        "- Functional"
      ],
      "metadata": {
        "id": "hHs7h78JhjL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서플로 라이브러리 안에 있는 케라스 API에서 필요한 함수들을 불러옵니다.\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# 데이터를 다루는 데 필요한 라이브러리를 불러옵니다.\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "iqE0DYwKhiXK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 준비\n",
        "- 데이터 세트는 입력 특성(X)과 대상 변수(y)로 분할.\n",
        "- 'X'에는 환자의 다양한 건강검진 기록을 나타내는 데이터 세트의 처음 16개 열이 포함.\n",
        "- y는 마지막 열로 수술 후 1년 후의 결과(사망 또는 생존)를 나타낸다."
      ],
      "metadata": {
        "id": "Fh5iZQpZnZev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 기존 환자의 진찰 기록 데이터를 이용해 새로운 환자의 수술 결과를 예측하는 모델\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 준비된 수술 환자 데이터를 불러옵니다.\n",
        "Data_set = np.loadtxt('/content/drive/MyDrive/KITA_1026/m6_dl/dataset/ThoraricSurgery3.csv', delimiter=\",\")\n",
        "X = Data_set[:,0:16]    # 환자의 진찰 기록을 X로 지정합니다.\n",
        "y = Data_set[:,16]      # 수술 1년 후 사망/생존 여부를 y로 지정합니다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAdNCjxsiCTp",
        "outputId": "aadb4306-9a17-4541-9470-fb8bd1d83ae3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Data_set.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWGpOZeUiOQ2",
        "outputId": "29f7559d-beab-4c12-db4f-85175bb59636"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(470, 17)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Q. Data_set[:,16]은 폐암 수술 환자의 생존 예측 데이터 셋의 label값이다. label의 class별 갯수를 구하세요."
      ],
      "metadata": {
        "id": "f7EStgbai8WJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 폐암 수술 환자의 생존 예측 데이터 셋의 label값이다. label의 class별 갯수 구하기\n",
        "Data_set[:,16]\n",
        "unique_values, counts= np.unique(Data_set[:,16], return_counts=True)\n",
        "print(\"Unique values:\", unique_values)\n",
        "print(\"Counts:\", counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nzHKafXiwbm",
        "outputId": "79a6475d-3430-4719-d754-daf629f0235f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique values: [0. 1.]\n",
            "Counts: [400  70]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1-1. Sequential-다중 선형회귀 모델\n",
        "# 텐서플로/케라스에서 실행하는 다중 선형회귀 모델\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#텐서플로의 케라스 API에서 필요한 함수들을 불러 옵니다.\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "\n",
        "# model = Sequential()\n",
        "\n",
        "# 출력 값, 입력 변수, 분석 방법에 맞게끔 모델을 설정합니다.\n",
        "model = Sequential([Dense(1, input_dim=16, activation='linear')])\n",
        "\n",
        "# 오차 수정을 위해 경사 하강법(sgd)을, 오차의 정도를 판단하기 위해 평균 제곱 오차(mse)를 사용합니다.\n",
        "sgd = optimizers.SGD(learning_rate = 0.0000000000001)\n",
        "model.compile(optimizer='sgd', loss='mse', metrics=['mse'])\n",
        "\n",
        "# 오차를 최소화하는 과정을 100번 반복합니다. <- batch 사이즈 조정해보기\n",
        "model.fit(X, y, epochs=5, batch_size=130, verbose=1)"
      ],
      "metadata": {
        "id": "Z-IlAyKhjUYS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4916f9a2-8907-4b8f-aa5c-38ecddb69b90"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "4/4 [==============================] - 1s 8ms/step - loss: 15243508973568.0000 - mse: 15243508973568.0000\n",
            "Epoch 2/5\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 24421562428066435524336812032.0000 - mse: 24421562428066435524336812032.0000\n",
            "Epoch 3/5\n",
            "4/4 [==============================] - 0s 7ms/step - loss: inf - mse: inf                                                                  \n",
            "Epoch 4/5\n",
            "4/4 [==============================] - 0s 8ms/step - loss: inf - mse: inf\n",
            "Epoch 5/5\n",
            "4/4 [==============================] - 0s 6ms/step - loss: inf - mse: inf\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x788f6af00040>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# batch 50\n",
        "575023227476221651954980795591950336\n",
        "# batch 60\n",
        "8175945247996184912545710080\n",
        "# batch 70\n",
        "1525051563915867808858112\n",
        "# batch 80\n",
        "739068424136704393216\n",
        "# batch 90\n",
        "180330638188751093760\n",
        "# batch 100\n",
        "54270369233633280\n",
        "# batch 110\n",
        "7026022109151232\n",
        "# batch 120\n",
        "9994782113792\n",
        "# batch 130\n",
        "15243508973568"
      ],
      "metadata": {
        "id": "vp-Lpps2AHof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1-2. Sequential\n",
        "\n",
        "# 입력 계층 및 첫 번째 Dense 계층 : 출력 10, activation='relu'\n",
        "# 두 번째 Dense 계층 : 출력 5, activation='relu'\n",
        "# 출력 계층 : 출력 1, activation='sigmoid' <- sigmoid이니 출력을 1로함\n",
        "# 모델 컴파일 : optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']\n",
        "# 모델 학습 : epochs=150, batch_size=10\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#텐서플로의 케라스 API에서 필요한 함수들을 불러 옵니다.\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Sequential 모델 정의\n",
        "model_sequential = Sequential([\n",
        "    Dense(10, activation='relu', input_shape=(16,)), # 첫번째 Dense 계층\n",
        "    Dense(5, activation='relu'), # 두번째 Dense 계층\n",
        "    Dense(1, activation='sigmoid') #출력\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model_sequential.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_sequential.summary()\n",
        "\n",
        "\n",
        "# 모델 학습\n",
        "model_sequential.fit(X, y, epochs=150, batch_size=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScZP7rTrp-Gq",
        "outputId": "e6e987e9-d844-409f-8ddf-dd0f07341996"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 10)                170       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 5)                 55        \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 231 (924.00 Byte)\n",
            "Trainable params: 231 (924.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/150\n",
            "47/47 [==============================] - 3s 2ms/step - loss: 0.9528 - accuracy: 0.8489\n",
            "Epoch 2/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.8489\n",
            "Epoch 3/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.8489\n",
            "Epoch 4/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.8489\n",
            "Epoch 5/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.8511\n",
            "Epoch 6/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.8511\n",
            "Epoch 7/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.8511\n",
            "Epoch 8/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.8511\n",
            "Epoch 9/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.8511\n",
            "Epoch 10/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.8511\n",
            "Epoch 11/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.8511\n",
            "Epoch 12/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.8511\n",
            "Epoch 13/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.8511\n",
            "Epoch 14/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.8511\n",
            "Epoch 15/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.8511\n",
            "Epoch 16/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.8511\n",
            "Epoch 17/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.8511\n",
            "Epoch 18/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.8511\n",
            "Epoch 19/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8511\n",
            "Epoch 20/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.8511\n",
            "Epoch 21/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.8511\n",
            "Epoch 22/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.8511\n",
            "Epoch 23/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.8511\n",
            "Epoch 24/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.8511\n",
            "Epoch 25/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.8511\n",
            "Epoch 26/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.8511\n",
            "Epoch 27/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8511\n",
            "Epoch 28/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.8511\n",
            "Epoch 29/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.8511\n",
            "Epoch 30/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.8511\n",
            "Epoch 31/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.8511\n",
            "Epoch 32/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.8511\n",
            "Epoch 33/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4092 - accuracy: 0.8511\n",
            "Epoch 34/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.8511\n",
            "Epoch 35/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.8511\n",
            "Epoch 36/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4060 - accuracy: 0.8489\n",
            "Epoch 37/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.8511\n",
            "Epoch 38/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4050 - accuracy: 0.8511\n",
            "Epoch 39/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4030 - accuracy: 0.8511\n",
            "Epoch 40/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4042 - accuracy: 0.8511\n",
            "Epoch 41/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3991 - accuracy: 0.8511\n",
            "Epoch 42/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4003 - accuracy: 0.8511\n",
            "Epoch 43/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3990 - accuracy: 0.8511\n",
            "Epoch 44/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4014 - accuracy: 0.8511\n",
            "Epoch 45/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3985 - accuracy: 0.8511\n",
            "Epoch 46/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8511\n",
            "Epoch 47/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4043 - accuracy: 0.8511\n",
            "Epoch 48/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3955 - accuracy: 0.8511\n",
            "Epoch 49/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3950 - accuracy: 0.8511\n",
            "Epoch 50/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3932 - accuracy: 0.8511\n",
            "Epoch 51/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3943 - accuracy: 0.8511\n",
            "Epoch 52/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3967 - accuracy: 0.8511\n",
            "Epoch 53/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3955 - accuracy: 0.8511\n",
            "Epoch 54/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3977 - accuracy: 0.8511\n",
            "Epoch 55/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3941 - accuracy: 0.8511\n",
            "Epoch 56/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3903 - accuracy: 0.8511\n",
            "Epoch 57/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3903 - accuracy: 0.8511\n",
            "Epoch 58/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3905 - accuracy: 0.8511\n",
            "Epoch 59/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3908 - accuracy: 0.8511\n",
            "Epoch 60/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3873 - accuracy: 0.8511\n",
            "Epoch 61/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.8511\n",
            "Epoch 62/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3854 - accuracy: 0.8511\n",
            "Epoch 63/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3951 - accuracy: 0.8511\n",
            "Epoch 64/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.8511\n",
            "Epoch 65/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3903 - accuracy: 0.8511\n",
            "Epoch 66/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3933 - accuracy: 0.8511\n",
            "Epoch 67/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3894 - accuracy: 0.8511\n",
            "Epoch 68/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3913 - accuracy: 0.8511\n",
            "Epoch 69/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3852 - accuracy: 0.8511\n",
            "Epoch 70/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3858 - accuracy: 0.8511\n",
            "Epoch 71/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3905 - accuracy: 0.8511\n",
            "Epoch 72/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3889 - accuracy: 0.8511\n",
            "Epoch 73/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3895 - accuracy: 0.8511\n",
            "Epoch 74/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3845 - accuracy: 0.8532\n",
            "Epoch 75/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.8511\n",
            "Epoch 76/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3892 - accuracy: 0.8532\n",
            "Epoch 77/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3832 - accuracy: 0.8511\n",
            "Epoch 78/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3905 - accuracy: 0.8532\n",
            "Epoch 79/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3854 - accuracy: 0.8532\n",
            "Epoch 80/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3866 - accuracy: 0.8511\n",
            "Epoch 81/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3930 - accuracy: 0.8511\n",
            "Epoch 82/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3909 - accuracy: 0.8489\n",
            "Epoch 83/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3901 - accuracy: 0.8511\n",
            "Epoch 84/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3894 - accuracy: 0.8511\n",
            "Epoch 85/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3872 - accuracy: 0.8511\n",
            "Epoch 86/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3833 - accuracy: 0.8511\n",
            "Epoch 87/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3856 - accuracy: 0.8511\n",
            "Epoch 88/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3833 - accuracy: 0.8532\n",
            "Epoch 89/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.8511\n",
            "Epoch 90/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3969 - accuracy: 0.8489\n",
            "Epoch 91/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3863 - accuracy: 0.8511\n",
            "Epoch 92/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3837 - accuracy: 0.8511\n",
            "Epoch 93/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3838 - accuracy: 0.8511\n",
            "Epoch 94/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3821 - accuracy: 0.8532\n",
            "Epoch 95/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3850 - accuracy: 0.8511\n",
            "Epoch 96/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3797 - accuracy: 0.8511\n",
            "Epoch 97/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3808 - accuracy: 0.8511\n",
            "Epoch 98/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3835 - accuracy: 0.8511\n",
            "Epoch 99/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.8511\n",
            "Epoch 100/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3834 - accuracy: 0.8532\n",
            "Epoch 101/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3817 - accuracy: 0.8511\n",
            "Epoch 102/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3807 - accuracy: 0.8511\n",
            "Epoch 103/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3841 - accuracy: 0.8511\n",
            "Epoch 104/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3830 - accuracy: 0.8532\n",
            "Epoch 105/150\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3852 - accuracy: 0.8511\n",
            "Epoch 106/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3788 - accuracy: 0.8532\n",
            "Epoch 107/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3838 - accuracy: 0.8532\n",
            "Epoch 108/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3796 - accuracy: 0.8511\n",
            "Epoch 109/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3808 - accuracy: 0.8532\n",
            "Epoch 110/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3837 - accuracy: 0.8511\n",
            "Epoch 111/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3950 - accuracy: 0.8511\n",
            "Epoch 112/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3776 - accuracy: 0.8511\n",
            "Epoch 113/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3808 - accuracy: 0.8532\n",
            "Epoch 114/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3847 - accuracy: 0.8532\n",
            "Epoch 115/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3800 - accuracy: 0.8532\n",
            "Epoch 116/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3841 - accuracy: 0.8532\n",
            "Epoch 117/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3803 - accuracy: 0.8511\n",
            "Epoch 118/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3846 - accuracy: 0.8532\n",
            "Epoch 119/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3833 - accuracy: 0.8511\n",
            "Epoch 120/150\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3880 - accuracy: 0.8532\n",
            "Epoch 121/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3809 - accuracy: 0.8532\n",
            "Epoch 122/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.8532\n",
            "Epoch 123/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3784 - accuracy: 0.8532\n",
            "Epoch 124/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3801 - accuracy: 0.8532\n",
            "Epoch 125/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3819 - accuracy: 0.8511\n",
            "Epoch 126/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3840 - accuracy: 0.8511\n",
            "Epoch 127/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3839 - accuracy: 0.8532\n",
            "Epoch 128/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3784 - accuracy: 0.8511\n",
            "Epoch 129/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3798 - accuracy: 0.8532\n",
            "Epoch 130/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3728 - accuracy: 0.8511\n",
            "Epoch 131/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3861 - accuracy: 0.8532\n",
            "Epoch 132/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8511\n",
            "Epoch 133/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3814 - accuracy: 0.8532\n",
            "Epoch 134/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3795 - accuracy: 0.8511\n",
            "Epoch 135/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3786 - accuracy: 0.8532\n",
            "Epoch 136/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3802 - accuracy: 0.8532\n",
            "Epoch 137/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3750 - accuracy: 0.8532\n",
            "Epoch 138/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3777 - accuracy: 0.8532\n",
            "Epoch 139/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3808 - accuracy: 0.8511\n",
            "Epoch 140/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3781 - accuracy: 0.8532\n",
            "Epoch 141/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3785 - accuracy: 0.8511\n",
            "Epoch 142/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3814 - accuracy: 0.8532\n",
            "Epoch 143/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3834 - accuracy: 0.8511\n",
            "Epoch 144/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8532\n",
            "Epoch 145/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3798 - accuracy: 0.8532\n",
            "Epoch 146/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3755 - accuracy: 0.8532\n",
            "Epoch 147/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3757 - accuracy: 0.8532\n",
            "Epoch 148/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3831 - accuracy: 0.8532\n",
            "Epoch 149/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3749 - accuracy: 0.8532\n",
            "Epoch 150/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8532\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x788f8e461540>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1-3-1. Sequential: 은닉층 둘에서 하나로 변경 및 node 갯수 동일\n",
        "\n",
        "# 입력 계층 및 첫 번째 Dense 계층 : 출력 20, activation='relu'\n",
        "# 출력 계층 : 출력 1, activation='sigmoid' <- sigmoid이니 출력을 1로함\n",
        "# 모델 컴파일 : optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']\n",
        "# 모델 학습 : epochs=150, batch_size=10\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#텐서플로의 케라스 API에서 필요한 함수들을 불러 옵니다.\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Sequential 모델 정의\n",
        "model_sequential = Sequential([\n",
        "    Dense(10, activation='relu', input_shape=(16,)), # 첫번째 Dense 계층\n",
        "    Dense(1, activation='sigmoid') #출력\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model_sequential.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_sequential.summary()\n",
        "\n",
        "\n",
        "# 모델 학습\n",
        "model_sequential.fit(X, y, epochs=150, batch_size=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrJ_m8Rx68Xx",
        "outputId": "54eec833-5caf-4bbd-a882-30c5f16e808d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_11 (Dense)            (None, 10)                170       \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 181 (724.00 Byte)\n",
            "Trainable params: 181 (724.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/150\n",
            "47/47 [==============================] - 1s 3ms/step - loss: 0.5920 - accuracy: 0.7468\n",
            "Epoch 2/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.8511\n",
            "Epoch 3/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.8511\n",
            "Epoch 4/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.8511\n",
            "Epoch 5/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.8489\n",
            "Epoch 6/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.8532\n",
            "Epoch 7/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.8489\n",
            "Epoch 8/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.8489\n",
            "Epoch 9/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.8532\n",
            "Epoch 10/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.8532\n",
            "Epoch 11/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4136 - accuracy: 0.8532\n",
            "Epoch 12/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8553\n",
            "Epoch 13/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4070 - accuracy: 0.8511\n",
            "Epoch 14/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4066 - accuracy: 0.8489\n",
            "Epoch 15/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.8489\n",
            "Epoch 16/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4055 - accuracy: 0.8511\n",
            "Epoch 17/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4070 - accuracy: 0.8532\n",
            "Epoch 18/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4037 - accuracy: 0.8511\n",
            "Epoch 19/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4022 - accuracy: 0.8532\n",
            "Epoch 20/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3986 - accuracy: 0.8511\n",
            "Epoch 21/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4048 - accuracy: 0.8511\n",
            "Epoch 22/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3977 - accuracy: 0.8511\n",
            "Epoch 23/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8489\n",
            "Epoch 24/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4004 - accuracy: 0.8596\n",
            "Epoch 25/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4010 - accuracy: 0.8511\n",
            "Epoch 26/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3980 - accuracy: 0.8489\n",
            "Epoch 27/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4020 - accuracy: 0.8532\n",
            "Epoch 28/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3927 - accuracy: 0.8489\n",
            "Epoch 29/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4046 - accuracy: 0.8574\n",
            "Epoch 30/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8532\n",
            "Epoch 31/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3917 - accuracy: 0.8511\n",
            "Epoch 32/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3966 - accuracy: 0.8511\n",
            "Epoch 33/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3890 - accuracy: 0.8553\n",
            "Epoch 34/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3958 - accuracy: 0.8489\n",
            "Epoch 35/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3928 - accuracy: 0.8553\n",
            "Epoch 36/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3913 - accuracy: 0.8511\n",
            "Epoch 37/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 0.8532\n",
            "Epoch 38/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3982 - accuracy: 0.8532\n",
            "Epoch 39/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3899 - accuracy: 0.8553\n",
            "Epoch 40/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3914 - accuracy: 0.8617\n",
            "Epoch 41/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3900 - accuracy: 0.8532\n",
            "Epoch 42/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3956 - accuracy: 0.8553\n",
            "Epoch 43/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3864 - accuracy: 0.8574\n",
            "Epoch 44/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3925 - accuracy: 0.8532\n",
            "Epoch 45/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3905 - accuracy: 0.8574\n",
            "Epoch 46/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.8532\n",
            "Epoch 47/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3973 - accuracy: 0.8511\n",
            "Epoch 48/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8596\n",
            "Epoch 49/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3882 - accuracy: 0.8511\n",
            "Epoch 50/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3983 - accuracy: 0.8511\n",
            "Epoch 51/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3919 - accuracy: 0.8574\n",
            "Epoch 52/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8511\n",
            "Epoch 53/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3937 - accuracy: 0.8511\n",
            "Epoch 54/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3864 - accuracy: 0.8553\n",
            "Epoch 55/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8532\n",
            "Epoch 56/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3830 - accuracy: 0.8532\n",
            "Epoch 57/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3915 - accuracy: 0.8532\n",
            "Epoch 58/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3950 - accuracy: 0.8447\n",
            "Epoch 59/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3948 - accuracy: 0.8511\n",
            "Epoch 60/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3919 - accuracy: 0.8553\n",
            "Epoch 61/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3980 - accuracy: 0.8532\n",
            "Epoch 62/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3917 - accuracy: 0.8511\n",
            "Epoch 63/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3909 - accuracy: 0.8532\n",
            "Epoch 64/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3941 - accuracy: 0.8511\n",
            "Epoch 65/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3948 - accuracy: 0.8553\n",
            "Epoch 66/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.8574\n",
            "Epoch 67/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4002 - accuracy: 0.8553\n",
            "Epoch 68/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3894 - accuracy: 0.8532\n",
            "Epoch 69/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3896 - accuracy: 0.8574\n",
            "Epoch 70/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.8489\n",
            "Epoch 71/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3867 - accuracy: 0.8511\n",
            "Epoch 72/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3890 - accuracy: 0.8574\n",
            "Epoch 73/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3903 - accuracy: 0.8553\n",
            "Epoch 74/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3845 - accuracy: 0.8553\n",
            "Epoch 75/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3888 - accuracy: 0.8532\n",
            "Epoch 76/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3875 - accuracy: 0.8596\n",
            "Epoch 77/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3859 - accuracy: 0.8532\n",
            "Epoch 78/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 0.8553\n",
            "Epoch 79/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3912 - accuracy: 0.8489\n",
            "Epoch 80/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.8596\n",
            "Epoch 81/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4009 - accuracy: 0.8489\n",
            "Epoch 82/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3905 - accuracy: 0.8553\n",
            "Epoch 83/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3888 - accuracy: 0.8532\n",
            "Epoch 84/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8574\n",
            "Epoch 85/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3900 - accuracy: 0.8532\n",
            "Epoch 86/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8489\n",
            "Epoch 87/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3844 - accuracy: 0.8553\n",
            "Epoch 88/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3863 - accuracy: 0.8553\n",
            "Epoch 89/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3853 - accuracy: 0.8532\n",
            "Epoch 90/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4005 - accuracy: 0.8511\n",
            "Epoch 91/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3853 - accuracy: 0.8532\n",
            "Epoch 92/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3872 - accuracy: 0.8574\n",
            "Epoch 93/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3943 - accuracy: 0.8553\n",
            "Epoch 94/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8532\n",
            "Epoch 95/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3841 - accuracy: 0.8511\n",
            "Epoch 96/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3883 - accuracy: 0.8553\n",
            "Epoch 97/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8468\n",
            "Epoch 98/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4014 - accuracy: 0.8532\n",
            "Epoch 99/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.8532\n",
            "Epoch 100/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3885 - accuracy: 0.8532\n",
            "Epoch 101/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3849 - accuracy: 0.8532\n",
            "Epoch 102/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3883 - accuracy: 0.8574\n",
            "Epoch 103/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4012 - accuracy: 0.8447\n",
            "Epoch 104/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3935 - accuracy: 0.8447\n",
            "Epoch 105/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3910 - accuracy: 0.8532\n",
            "Epoch 106/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3852 - accuracy: 0.8532\n",
            "Epoch 107/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3885 - accuracy: 0.8553\n",
            "Epoch 108/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3853 - accuracy: 0.8532\n",
            "Epoch 109/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3915 - accuracy: 0.8511\n",
            "Epoch 110/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3923 - accuracy: 0.8574\n",
            "Epoch 111/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3862 - accuracy: 0.8553\n",
            "Epoch 112/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3861 - accuracy: 0.8489\n",
            "Epoch 113/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3891 - accuracy: 0.8511\n",
            "Epoch 114/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3934 - accuracy: 0.8489\n",
            "Epoch 115/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3896 - accuracy: 0.8532\n",
            "Epoch 116/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3882 - accuracy: 0.8489\n",
            "Epoch 117/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3933 - accuracy: 0.8511\n",
            "Epoch 118/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3874 - accuracy: 0.8532\n",
            "Epoch 119/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3830 - accuracy: 0.8447\n",
            "Epoch 120/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3889 - accuracy: 0.8574\n",
            "Epoch 121/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3826 - accuracy: 0.8468\n",
            "Epoch 122/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3867 - accuracy: 0.8574\n",
            "Epoch 123/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3866 - accuracy: 0.8596\n",
            "Epoch 124/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3931 - accuracy: 0.8574\n",
            "Epoch 125/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3856 - accuracy: 0.8489\n",
            "Epoch 126/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3860 - accuracy: 0.8532\n",
            "Epoch 127/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3847 - accuracy: 0.8489\n",
            "Epoch 128/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4022 - accuracy: 0.8468\n",
            "Epoch 129/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3861 - accuracy: 0.8596\n",
            "Epoch 130/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3886 - accuracy: 0.8511\n",
            "Epoch 131/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3957 - accuracy: 0.8574\n",
            "Epoch 132/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3856 - accuracy: 0.8574\n",
            "Epoch 133/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3884 - accuracy: 0.8511\n",
            "Epoch 134/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3841 - accuracy: 0.8511\n",
            "Epoch 135/150\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3871 - accuracy: 0.8574\n",
            "Epoch 136/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3845 - accuracy: 0.8532\n",
            "Epoch 137/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3831 - accuracy: 0.8553\n",
            "Epoch 138/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3941 - accuracy: 0.8447\n",
            "Epoch 139/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3870 - accuracy: 0.8532\n",
            "Epoch 140/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3953 - accuracy: 0.8468\n",
            "Epoch 141/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3918 - accuracy: 0.8489\n",
            "Epoch 142/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3940 - accuracy: 0.8511\n",
            "Epoch 143/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3837 - accuracy: 0.8511\n",
            "Epoch 144/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3861 - accuracy: 0.8596\n",
            "Epoch 145/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3822 - accuracy: 0.8511\n",
            "Epoch 146/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3860 - accuracy: 0.8553\n",
            "Epoch 147/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3849 - accuracy: 0.8489\n",
            "Epoch 148/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3854 - accuracy: 0.8511\n",
            "Epoch 149/150\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3874 - accuracy: 0.8511\n",
            "Epoch 150/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3898 - accuracy: 0.8511\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x788f8d897220>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1-3-2. Sequential: 은닉층 둘에서 하나로 변경 및 node 갯수 20으로 수정\n",
        "\n",
        "# 입력 계층 및 첫 번째 Dense 계층 : 출력 20, activation='relu'\n",
        "# 출력 계층 : 출력 1, activation='sigmoid' <- sigmoid이니 출력을 1로함\n",
        "# 모델 컴파일 : optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']\n",
        "# 모델 학습 : epochs=150, batch_size=10\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#텐서플로의 케라스 API에서 필요한 함수들을 불러 옵니다.\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Sequential 모델 정의\n",
        "model_sequential = Sequential([\n",
        "    Dense(20, activation='relu', input_shape=(16,)), # 첫번째 Dense 계층\n",
        "    Dense(1, activation='sigmoid') #출력\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model_sequential.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_sequential.summary()\n",
        "\n",
        "\n",
        "# 모델 학습\n",
        "model_sequential.fit(X, y, epochs=150, batch_size=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cwYBPn05tHD",
        "outputId": "b101b7d9-968f-4858-f19c-a0ee0ba4ad33"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 20)                340       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 361 (1.41 KB)\n",
            "Trainable params: 361 (1.41 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/150\n",
            "47/47 [==============================] - 1s 2ms/step - loss: 0.7893 - accuracy: 0.8255\n",
            "Epoch 2/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.6764 - accuracy: 0.8255\n",
            "Epoch 3/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.5740 - accuracy: 0.8255\n",
            "Epoch 4/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.8255\n",
            "Epoch 5/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.8468\n",
            "Epoch 6/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.8489\n",
            "Epoch 7/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.8511\n",
            "Epoch 8/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.8511\n",
            "Epoch 9/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.8511\n",
            "Epoch 10/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.8511\n",
            "Epoch 11/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8511\n",
            "Epoch 12/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8511\n",
            "Epoch 13/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.8511\n",
            "Epoch 14/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.8511\n",
            "Epoch 15/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.8511\n",
            "Epoch 16/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8511\n",
            "Epoch 17/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.8511\n",
            "Epoch 18/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.8511\n",
            "Epoch 19/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8511\n",
            "Epoch 20/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.8511\n",
            "Epoch 21/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.8511\n",
            "Epoch 22/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.8511\n",
            "Epoch 23/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.8511\n",
            "Epoch 24/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4090 - accuracy: 0.8511\n",
            "Epoch 25/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4041 - accuracy: 0.8511\n",
            "Epoch 26/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.8511\n",
            "Epoch 27/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4017 - accuracy: 0.8511\n",
            "Epoch 28/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4022 - accuracy: 0.8511\n",
            "Epoch 29/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4051 - accuracy: 0.8511\n",
            "Epoch 30/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4038 - accuracy: 0.8511\n",
            "Epoch 31/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.8511\n",
            "Epoch 32/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4071 - accuracy: 0.8511\n",
            "Epoch 33/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4024 - accuracy: 0.8489\n",
            "Epoch 34/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3992 - accuracy: 0.8511\n",
            "Epoch 35/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4015 - accuracy: 0.8511\n",
            "Epoch 36/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4010 - accuracy: 0.8511\n",
            "Epoch 37/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3968 - accuracy: 0.8489\n",
            "Epoch 38/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.8489\n",
            "Epoch 39/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3950 - accuracy: 0.8511\n",
            "Epoch 40/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.8511\n",
            "Epoch 41/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4014 - accuracy: 0.8489\n",
            "Epoch 42/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3981 - accuracy: 0.8511\n",
            "Epoch 43/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3944 - accuracy: 0.8489\n",
            "Epoch 44/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3944 - accuracy: 0.8489\n",
            "Epoch 45/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3980 - accuracy: 0.8511\n",
            "Epoch 46/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3960 - accuracy: 0.8511\n",
            "Epoch 47/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3933 - accuracy: 0.8511\n",
            "Epoch 48/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3934 - accuracy: 0.8511\n",
            "Epoch 49/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3987 - accuracy: 0.8489\n",
            "Epoch 50/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3931 - accuracy: 0.8511\n",
            "Epoch 51/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3982 - accuracy: 0.8532\n",
            "Epoch 52/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3952 - accuracy: 0.8532\n",
            "Epoch 53/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3982 - accuracy: 0.8489\n",
            "Epoch 54/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3955 - accuracy: 0.8489\n",
            "Epoch 55/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3919 - accuracy: 0.8489\n",
            "Epoch 56/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3915 - accuracy: 0.8489\n",
            "Epoch 57/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.8489\n",
            "Epoch 58/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3956 - accuracy: 0.8511\n",
            "Epoch 59/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3913 - accuracy: 0.8511\n",
            "Epoch 60/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3913 - accuracy: 0.8489\n",
            "Epoch 61/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3971 - accuracy: 0.8511\n",
            "Epoch 62/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8511\n",
            "Epoch 63/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3926 - accuracy: 0.8511\n",
            "Epoch 64/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3920 - accuracy: 0.8489\n",
            "Epoch 65/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3908 - accuracy: 0.8468\n",
            "Epoch 66/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3912 - accuracy: 0.8468\n",
            "Epoch 67/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3938 - accuracy: 0.8489\n",
            "Epoch 68/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3934 - accuracy: 0.8511\n",
            "Epoch 69/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3912 - accuracy: 0.8489\n",
            "Epoch 70/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3827 - accuracy: 0.8511\n",
            "Epoch 71/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3944 - accuracy: 0.8553\n",
            "Epoch 72/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8489\n",
            "Epoch 73/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3885 - accuracy: 0.8511\n",
            "Epoch 74/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3903 - accuracy: 0.8489\n",
            "Epoch 75/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3898 - accuracy: 0.8511\n",
            "Epoch 76/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3912 - accuracy: 0.8511\n",
            "Epoch 77/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3898 - accuracy: 0.8468\n",
            "Epoch 78/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3888 - accuracy: 0.8489\n",
            "Epoch 79/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3865 - accuracy: 0.8511\n",
            "Epoch 80/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3928 - accuracy: 0.8489\n",
            "Epoch 81/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3912 - accuracy: 0.8489\n",
            "Epoch 82/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3871 - accuracy: 0.8532\n",
            "Epoch 83/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3905 - accuracy: 0.8468\n",
            "Epoch 84/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3871 - accuracy: 0.8511\n",
            "Epoch 85/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3950 - accuracy: 0.8553\n",
            "Epoch 86/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3907 - accuracy: 0.8489\n",
            "Epoch 87/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3942 - accuracy: 0.8511\n",
            "Epoch 88/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3868 - accuracy: 0.8532\n",
            "Epoch 89/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3859 - accuracy: 0.8489\n",
            "Epoch 90/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3902 - accuracy: 0.8468\n",
            "Epoch 91/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3903 - accuracy: 0.8489\n",
            "Epoch 92/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3864 - accuracy: 0.8489\n",
            "Epoch 93/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3883 - accuracy: 0.8489\n",
            "Epoch 94/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3888 - accuracy: 0.8489\n",
            "Epoch 95/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3955 - accuracy: 0.8468\n",
            "Epoch 96/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3919 - accuracy: 0.8553\n",
            "Epoch 97/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3876 - accuracy: 0.8511\n",
            "Epoch 98/150\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3879 - accuracy: 0.8511\n",
            "Epoch 99/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3873 - accuracy: 0.8532\n",
            "Epoch 100/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3857 - accuracy: 0.8532\n",
            "Epoch 101/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3849 - accuracy: 0.8511\n",
            "Epoch 102/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3879 - accuracy: 0.8489\n",
            "Epoch 103/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3927 - accuracy: 0.8574\n",
            "Epoch 104/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3953 - accuracy: 0.8511\n",
            "Epoch 105/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3830 - accuracy: 0.8468\n",
            "Epoch 106/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3859 - accuracy: 0.8532\n",
            "Epoch 107/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3860 - accuracy: 0.8489\n",
            "Epoch 108/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3837 - accuracy: 0.8468\n",
            "Epoch 109/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3839 - accuracy: 0.8553\n",
            "Epoch 110/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3858 - accuracy: 0.8489\n",
            "Epoch 111/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3867 - accuracy: 0.8553\n",
            "Epoch 112/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3860 - accuracy: 0.8532\n",
            "Epoch 113/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3980 - accuracy: 0.8489\n",
            "Epoch 114/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3884 - accuracy: 0.8553\n",
            "Epoch 115/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8553\n",
            "Epoch 116/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.8511\n",
            "Epoch 117/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3838 - accuracy: 0.8511\n",
            "Epoch 118/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8468\n",
            "Epoch 119/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3840 - accuracy: 0.8532\n",
            "Epoch 120/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8447\n",
            "Epoch 121/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3984 - accuracy: 0.8489\n",
            "Epoch 122/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3860 - accuracy: 0.8489\n",
            "Epoch 123/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3898 - accuracy: 0.8511\n",
            "Epoch 124/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3851 - accuracy: 0.8532\n",
            "Epoch 125/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3867 - accuracy: 0.8511\n",
            "Epoch 126/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.8489\n",
            "Epoch 127/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3900 - accuracy: 0.8426\n",
            "Epoch 128/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3878 - accuracy: 0.8511\n",
            "Epoch 129/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3843 - accuracy: 0.8511\n",
            "Epoch 130/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3823 - accuracy: 0.8489\n",
            "Epoch 131/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3853 - accuracy: 0.8447\n",
            "Epoch 132/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8511\n",
            "Epoch 133/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3835 - accuracy: 0.8511\n",
            "Epoch 134/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3906 - accuracy: 0.8468\n",
            "Epoch 135/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3849 - accuracy: 0.8532\n",
            "Epoch 136/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3873 - accuracy: 0.8532\n",
            "Epoch 137/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3895 - accuracy: 0.8447\n",
            "Epoch 138/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3814 - accuracy: 0.8489\n",
            "Epoch 139/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8553\n",
            "Epoch 140/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3851 - accuracy: 0.8532\n",
            "Epoch 141/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8468\n",
            "Epoch 142/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3917 - accuracy: 0.8447\n",
            "Epoch 143/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3845 - accuracy: 0.8574\n",
            "Epoch 144/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3835 - accuracy: 0.8553\n",
            "Epoch 145/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.8574\n",
            "Epoch 146/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3960 - accuracy: 0.8511\n",
            "Epoch 147/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.8553\n",
            "Epoch 148/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3866 - accuracy: 0.8511\n",
            "Epoch 149/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3902 - accuracy: 0.8447\n",
            "Epoch 150/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3826 - accuracy: 0.8532\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x788f8e441450>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1-2. Sequential - batch 수 10 -> 20 으로 수정\n",
        "\n",
        "# 입력 계층 및 첫 번째 Dense 계층 : 출력 10, activation='relu'\n",
        "# 두 번째 Dense 계층 : 출력 5, activation='relu'\n",
        "# 출력 계층 : 출력 1, activation='sigmoid' <- sigmoid이니 출력을 1로함\n",
        "# 모델 컴파일 : optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']\n",
        "# 모델 학습 : epochs=150, batch_size=10\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#텐서플로의 케라스 API에서 필요한 함수들을 불러 옵니다.\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Sequential 모델 정의\n",
        "model_sequential = Sequential([\n",
        "    Dense(10, activation='relu', input_shape=(16,)), # 첫번째 Dense 계층\n",
        "    Dense(5, activation='relu'), # 두번째 Dense 계층\n",
        "    Dense(1, activation='sigmoid') #출력\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model_sequential.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_sequential.summary()\n",
        "\n",
        "\n",
        "# 모델 학습\n",
        "model_sequential.fit(X, y, epochs=150, batch_size=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COUFMNPz6iIh",
        "outputId": "91323659-8b07-46c2-daf7-35c9db85f4b3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 10)                170       \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 5)                 55        \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 231 (924.00 Byte)\n",
            "Trainable params: 231 (924.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/150\n",
            "24/24 [==============================] - 1s 2ms/step - loss: 4.8632 - accuracy: 0.1489 \n",
            "Epoch 2/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 2.0316 - accuracy: 0.1489\n",
            "Epoch 3/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 1.3449 - accuracy: 0.1489\n",
            "Epoch 4/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 1.1416 - accuracy: 0.1489\n",
            "Epoch 5/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 1.0008 - accuracy: 0.1489\n",
            "Epoch 6/150\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.8992 - accuracy: 0.1489\n",
            "Epoch 7/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.8283 - accuracy: 0.1489\n",
            "Epoch 8/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.7757 - accuracy: 0.1511\n",
            "Epoch 9/150\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.1553\n",
            "Epoch 10/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.7040 - accuracy: 0.3191\n",
            "Epoch 11/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.6793 - accuracy: 0.7830\n",
            "Epoch 12/150\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.6587 - accuracy: 0.8383\n",
            "Epoch 13/150\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.6415 - accuracy: 0.8511\n",
            "Epoch 14/150\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.6260 - accuracy: 0.8511\n",
            "Epoch 15/150\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.6121 - accuracy: 0.8511\n",
            "Epoch 16/150\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.5989 - accuracy: 0.8511\n",
            "Epoch 17/150\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.5865 - accuracy: 0.8511\n",
            "Epoch 18/150\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.5736 - accuracy: 0.8511\n",
            "Epoch 19/150\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.5612 - accuracy: 0.8511\n",
            "Epoch 20/150\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.5480 - accuracy: 0.8511\n",
            "Epoch 21/150\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.5348 - accuracy: 0.8511\n",
            "Epoch 22/150\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.5210 - accuracy: 0.8511\n",
            "Epoch 23/150\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.8511\n",
            "Epoch 24/150\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.4929 - accuracy: 0.8511\n",
            "Epoch 25/150\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4802 - accuracy: 0.8511\n",
            "Epoch 26/150\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4677 - accuracy: 0.8511\n",
            "Epoch 27/150\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.8511\n",
            "Epoch 28/150\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.8511\n",
            "Epoch 29/150\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.8511\n",
            "Epoch 30/150\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.8511\n",
            "Epoch 31/150\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.8511\n",
            "Epoch 32/150\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.8511\n",
            "Epoch 33/150\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.8511\n",
            "Epoch 34/150\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.8511\n",
            "Epoch 35/150\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.8511\n",
            "Epoch 36/150\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.8511\n",
            "Epoch 37/150\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.8511\n",
            "Epoch 38/150\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.8511\n",
            "Epoch 39/150\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4244 - accuracy: 0.8511\n",
            "Epoch 40/150\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.8511\n",
            "Epoch 41/150\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.8511\n",
            "Epoch 42/150\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.8511\n",
            "Epoch 43/150\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.8511\n",
            "Epoch 44/150\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.8511\n",
            "Epoch 45/150\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.8511\n",
            "Epoch 46/150\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.8511\n",
            "Epoch 47/150\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.8511\n",
            "Epoch 48/150\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.8511\n",
            "Epoch 49/150\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.8511\n",
            "Epoch 50/150\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.8511\n",
            "Epoch 51/150\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4239 - accuracy: 0.8511\n",
            "Epoch 52/150\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.8511\n",
            "Epoch 53/150\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.8511\n",
            "Epoch 54/150\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.8511\n",
            "Epoch 55/150\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4239 - accuracy: 0.8511\n",
            "Epoch 56/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.8511\n",
            "Epoch 57/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.8511\n",
            "Epoch 58/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.8511\n",
            "Epoch 59/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.8511\n",
            "Epoch 60/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.8511\n",
            "Epoch 61/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.8511\n",
            "Epoch 62/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.8511\n",
            "Epoch 63/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.8511\n",
            "Epoch 64/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.8511\n",
            "Epoch 65/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.8511\n",
            "Epoch 66/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.8511\n",
            "Epoch 67/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.8511\n",
            "Epoch 68/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.8511\n",
            "Epoch 69/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.8511\n",
            "Epoch 70/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.8511\n",
            "Epoch 71/150\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4236 - accuracy: 0.8511\n",
            "Epoch 72/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.8511\n",
            "Epoch 73/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.8511\n",
            "Epoch 74/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.8511\n",
            "Epoch 75/150\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4236 - accuracy: 0.8511\n",
            "Epoch 76/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.8511\n",
            "Epoch 77/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.8511\n",
            "Epoch 78/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.8511\n",
            "Epoch 79/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.8511\n",
            "Epoch 80/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.8511\n",
            "Epoch 81/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.8511\n",
            "Epoch 82/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.8511\n",
            "Epoch 83/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.8511\n",
            "Epoch 84/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.8511\n",
            "Epoch 85/150\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.8511\n",
            "Epoch 86/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.8511\n",
            "Epoch 87/150\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.8511\n",
            "Epoch 88/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.8511\n",
            "Epoch 89/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.8511\n",
            "Epoch 90/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.8511\n",
            "Epoch 91/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.8511\n",
            "Epoch 92/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.8511\n",
            "Epoch 93/150\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.8511\n",
            "Epoch 94/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.8511\n",
            "Epoch 95/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.8511\n",
            "Epoch 96/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.8511\n",
            "Epoch 97/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.8511\n",
            "Epoch 98/150\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.8511\n",
            "Epoch 99/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.8511\n",
            "Epoch 100/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.8511\n",
            "Epoch 101/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.8511\n",
            "Epoch 102/150\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4227 - accuracy: 0.8511\n",
            "Epoch 103/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.8511\n",
            "Epoch 104/150\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.8511\n",
            "Epoch 105/150\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.8511\n",
            "Epoch 106/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.8511\n",
            "Epoch 107/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.8511\n",
            "Epoch 108/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.8511\n",
            "Epoch 109/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.8511\n",
            "Epoch 110/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.8511\n",
            "Epoch 111/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.8511\n",
            "Epoch 112/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.8511\n",
            "Epoch 113/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.8511\n",
            "Epoch 114/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.8511\n",
            "Epoch 115/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.8511\n",
            "Epoch 116/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.8511\n",
            "Epoch 117/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.8511\n",
            "Epoch 118/150\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.8511\n",
            "Epoch 119/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.8511\n",
            "Epoch 120/150\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.8511\n",
            "Epoch 121/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.8511\n",
            "Epoch 122/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.8511\n",
            "Epoch 123/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.8511\n",
            "Epoch 124/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.8511\n",
            "Epoch 125/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.8511\n",
            "Epoch 126/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.8511\n",
            "Epoch 127/150\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.8511\n",
            "Epoch 128/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.8511\n",
            "Epoch 129/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.8511\n",
            "Epoch 130/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.8511\n",
            "Epoch 131/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.8511\n",
            "Epoch 132/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.8511\n",
            "Epoch 133/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.8511\n",
            "Epoch 134/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.8511\n",
            "Epoch 135/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.8511\n",
            "Epoch 136/150\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.8511\n",
            "Epoch 137/150\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.8511\n",
            "Epoch 138/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.8511\n",
            "Epoch 139/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.8511\n",
            "Epoch 140/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.8511\n",
            "Epoch 141/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.8511\n",
            "Epoch 142/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.8511\n",
            "Epoch 143/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.8511\n",
            "Epoch 144/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.8511\n",
            "Epoch 145/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.8511\n",
            "Epoch 146/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.8511\n",
            "Epoch 147/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.8511\n",
            "Epoch 148/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.8511\n",
            "Epoch 149/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.8511\n",
            "Epoch 150/150\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.8511\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x788f8e1a5f00>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Functional\n",
        "\n",
        "# 입력 계층 및 첫 번째 Dense 계층 : 출력 10, activation='relu'\n",
        "# 두 번째 Dense 계층 : 출력 5, activation='relu'\n",
        "# 출력 계층 : 출력 1, activation='sigmoid' <- sigmoid이니 출력을 1로함\n",
        "# 모델 컴파일 : optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']\n",
        "# 모델 학습 : epochs=150, batch_size=10\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# 입력층 정의\n",
        "input_layer = Input(shape=(16,), name='input_layer')\n",
        "\n",
        "# 완전연결 층 추가\n",
        "hidden1 = Dense(10, activation='relu', name='hidden_layer_1')(input_layer)\n",
        "hidden2 = Dense(5, activation='relu', name='hidden_layer_2')(hidden1)\n",
        "\n",
        "# 출력층 추가\n",
        "output_layer = Dense(1, activation='sigmoid', name='output_layer')(hidden2)\n",
        "\n",
        "# 모델 정의\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 모델 요약 출력\n",
        "model.summary()\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(X, y, epochs=150, batch_size=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRxAAddN7hcu",
        "outputId": "a29ba101-a6f5-42fc-91ec-7b54aa32c822"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_layer (InputLayer)    [(None, 16)]              0         \n",
            "                                                                 \n",
            " hidden_layer_1 (Dense)      (None, 10)                170       \n",
            "                                                                 \n",
            " hidden_layer_2 (Dense)      (None, 5)                 55        \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 231 (924.00 Byte)\n",
            "Trainable params: 231 (924.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/150\n",
            "47/47 [==============================] - 2s 4ms/step - loss: 4.9730 - accuracy: 0.3553\n",
            "Epoch 2/150\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.8480 - accuracy: 0.8255\n",
            "Epoch 3/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.6170 - accuracy: 0.8255\n",
            "Epoch 4/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.8340\n",
            "Epoch 5/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.8511\n",
            "Epoch 6/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.8511\n",
            "Epoch 7/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.8511\n",
            "Epoch 8/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.8511\n",
            "Epoch 9/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.8511\n",
            "Epoch 10/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.8511\n",
            "Epoch 11/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.8511\n",
            "Epoch 12/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.8511\n",
            "Epoch 13/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.8511\n",
            "Epoch 14/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.8511\n",
            "Epoch 15/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.8511\n",
            "Epoch 16/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.8511\n",
            "Epoch 17/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.8511\n",
            "Epoch 18/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.8511\n",
            "Epoch 19/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4066 - accuracy: 0.8511\n",
            "Epoch 20/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.8511\n",
            "Epoch 21/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.8511\n",
            "Epoch 22/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.8511\n",
            "Epoch 23/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.8511\n",
            "Epoch 24/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.8511\n",
            "Epoch 25/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.8532\n",
            "Epoch 26/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.8511\n",
            "Epoch 27/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4043 - accuracy: 0.8532\n",
            "Epoch 28/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.8489\n",
            "Epoch 29/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4114 - accuracy: 0.8468\n",
            "Epoch 30/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4064 - accuracy: 0.8489\n",
            "Epoch 31/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4019 - accuracy: 0.8447\n",
            "Epoch 32/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.8489\n",
            "Epoch 33/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8447\n",
            "Epoch 34/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4057 - accuracy: 0.8468\n",
            "Epoch 35/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.8447\n",
            "Epoch 36/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.8553\n",
            "Epoch 37/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3972 - accuracy: 0.8511\n",
            "Epoch 38/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4039 - accuracy: 0.8489\n",
            "Epoch 39/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4087 - accuracy: 0.8511\n",
            "Epoch 40/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4018 - accuracy: 0.8468\n",
            "Epoch 41/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3982 - accuracy: 0.8511\n",
            "Epoch 42/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3959 - accuracy: 0.8511\n",
            "Epoch 43/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4003 - accuracy: 0.8468\n",
            "Epoch 44/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.8468\n",
            "Epoch 45/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4027 - accuracy: 0.8511\n",
            "Epoch 46/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3992 - accuracy: 0.8340\n",
            "Epoch 47/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4006 - accuracy: 0.8511\n",
            "Epoch 48/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3991 - accuracy: 0.8489\n",
            "Epoch 49/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.8426\n",
            "Epoch 50/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4047 - accuracy: 0.8511\n",
            "Epoch 51/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4045 - accuracy: 0.8468\n",
            "Epoch 52/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3925 - accuracy: 0.8532\n",
            "Epoch 53/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3936 - accuracy: 0.8532\n",
            "Epoch 54/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3914 - accuracy: 0.8489\n",
            "Epoch 55/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3917 - accuracy: 0.8447\n",
            "Epoch 56/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3922 - accuracy: 0.8532\n",
            "Epoch 57/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3950 - accuracy: 0.8511\n",
            "Epoch 58/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3983 - accuracy: 0.8468\n",
            "Epoch 59/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3923 - accuracy: 0.8468\n",
            "Epoch 60/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3932 - accuracy: 0.8447\n",
            "Epoch 61/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3882 - accuracy: 0.8511\n",
            "Epoch 62/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3858 - accuracy: 0.8574\n",
            "Epoch 63/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4045 - accuracy: 0.8447\n",
            "Epoch 64/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3970 - accuracy: 0.8447\n",
            "Epoch 65/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3874 - accuracy: 0.8489\n",
            "Epoch 66/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3894 - accuracy: 0.8447\n",
            "Epoch 67/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3933 - accuracy: 0.8468\n",
            "Epoch 68/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3933 - accuracy: 0.8489\n",
            "Epoch 69/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3912 - accuracy: 0.8468\n",
            "Epoch 70/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.8404\n",
            "Epoch 71/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3848 - accuracy: 0.8489\n",
            "Epoch 72/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3906 - accuracy: 0.8511\n",
            "Epoch 73/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3839 - accuracy: 0.8404\n",
            "Epoch 74/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3929 - accuracy: 0.8447\n",
            "Epoch 75/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3954 - accuracy: 0.8511\n",
            "Epoch 76/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4047 - accuracy: 0.8447\n",
            "Epoch 77/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3863 - accuracy: 0.8532\n",
            "Epoch 78/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3931 - accuracy: 0.8511\n",
            "Epoch 79/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3953 - accuracy: 0.8404\n",
            "Epoch 80/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3933 - accuracy: 0.8447\n",
            "Epoch 81/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3903 - accuracy: 0.8617\n",
            "Epoch 82/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3815 - accuracy: 0.8532\n",
            "Epoch 83/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3892 - accuracy: 0.8511\n",
            "Epoch 84/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3945 - accuracy: 0.8468\n",
            "Epoch 85/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3917 - accuracy: 0.8532\n",
            "Epoch 86/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3874 - accuracy: 0.8468\n",
            "Epoch 87/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3910 - accuracy: 0.8447\n",
            "Epoch 88/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4023 - accuracy: 0.8468\n",
            "Epoch 89/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.8489\n",
            "Epoch 90/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3839 - accuracy: 0.8511\n",
            "Epoch 91/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3909 - accuracy: 0.8426\n",
            "Epoch 92/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3888 - accuracy: 0.8426\n",
            "Epoch 93/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3932 - accuracy: 0.8447\n",
            "Epoch 94/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3847 - accuracy: 0.8511\n",
            "Epoch 95/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3913 - accuracy: 0.8447\n",
            "Epoch 96/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3831 - accuracy: 0.8574\n",
            "Epoch 97/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3880 - accuracy: 0.8553\n",
            "Epoch 98/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3904 - accuracy: 0.8468\n",
            "Epoch 99/150\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3860 - accuracy: 0.8489\n",
            "Epoch 100/150\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.4042 - accuracy: 0.8426\n",
            "Epoch 101/150\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3889 - accuracy: 0.8489\n",
            "Epoch 102/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3858 - accuracy: 0.8489\n",
            "Epoch 103/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3877 - accuracy: 0.8426\n",
            "Epoch 104/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3912 - accuracy: 0.8468\n",
            "Epoch 105/150\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3944 - accuracy: 0.8511\n",
            "Epoch 106/150\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3917 - accuracy: 0.8468\n",
            "Epoch 107/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3859 - accuracy: 0.8489\n",
            "Epoch 108/150\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.4053 - accuracy: 0.8489\n",
            "Epoch 109/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3872 - accuracy: 0.8404\n",
            "Epoch 110/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3936 - accuracy: 0.8574\n",
            "Epoch 111/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4059 - accuracy: 0.8447\n",
            "Epoch 112/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3892 - accuracy: 0.8468\n",
            "Epoch 113/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3975 - accuracy: 0.8447\n",
            "Epoch 114/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3863 - accuracy: 0.8532\n",
            "Epoch 115/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3878 - accuracy: 0.8468\n",
            "Epoch 116/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3872 - accuracy: 0.8447\n",
            "Epoch 117/150\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3906 - accuracy: 0.8574\n",
            "Epoch 118/150\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3853 - accuracy: 0.8511\n",
            "Epoch 119/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3994 - accuracy: 0.8468\n",
            "Epoch 120/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3836 - accuracy: 0.8574\n",
            "Epoch 121/150\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3892 - accuracy: 0.8489\n",
            "Epoch 122/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3941 - accuracy: 0.8553\n",
            "Epoch 123/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3929 - accuracy: 0.8511\n",
            "Epoch 124/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.8447\n",
            "Epoch 125/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4025 - accuracy: 0.8404\n",
            "Epoch 126/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8489\n",
            "Epoch 127/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 0.8489\n",
            "Epoch 128/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3836 - accuracy: 0.8447\n",
            "Epoch 129/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8468\n",
            "Epoch 130/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3858 - accuracy: 0.8489\n",
            "Epoch 131/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3867 - accuracy: 0.8468\n",
            "Epoch 132/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4090 - accuracy: 0.8447\n",
            "Epoch 133/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3858 - accuracy: 0.8489\n",
            "Epoch 134/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4042 - accuracy: 0.8468\n",
            "Epoch 135/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3981 - accuracy: 0.8362\n",
            "Epoch 136/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3842 - accuracy: 0.8532\n",
            "Epoch 137/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.8553\n",
            "Epoch 138/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3939 - accuracy: 0.8447\n",
            "Epoch 139/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3989 - accuracy: 0.8511\n",
            "Epoch 140/150\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3869 - accuracy: 0.8489\n",
            "Epoch 141/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3933 - accuracy: 0.8489\n",
            "Epoch 142/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3859 - accuracy: 0.8468\n",
            "Epoch 143/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3930 - accuracy: 0.8468\n",
            "Epoch 144/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3962 - accuracy: 0.8404\n",
            "Epoch 145/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3910 - accuracy: 0.8553\n",
            "Epoch 146/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3842 - accuracy: 0.8404\n",
            "Epoch 147/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3894 - accuracy: 0.8489\n",
            "Epoch 148/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3814 - accuracy: 0.8553\n",
            "Epoch 149/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3827 - accuracy: 0.8489\n",
            "Epoch 150/150\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.3847 - accuracy: 0.8489\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x788f7e920d30>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}